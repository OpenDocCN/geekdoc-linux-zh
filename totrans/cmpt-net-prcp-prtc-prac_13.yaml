- en: Sharing resources#
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 资源共享#
- en: 原文：[https://4ed.computer-networking.info/syllabus/default/networks/sharing.html](https://4ed.computer-networking.info/syllabus/default/networks/sharing.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://4ed.computer-networking.info/syllabus/default/networks/sharing.html](https://4ed.computer-networking.info/syllabus/default/networks/sharing.html)
- en: A network is designed to support a potentially large number of users that exchange
    information with each other. These users produce and consume information which
    is exchanged through the network. To support its users, a network uses several
    types of resources. It is important to keep in mind the different resources that
    are shared inside the network.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 网络被设计来支持大量潜在的用户，这些用户相互交换信息。这些用户产生和消费通过网络交换的信息。为了支持其用户，网络使用多种类型的资源。记住网络内部共享的不同资源是很重要的。
- en: The first and more important resource inside a network is the link bandwidth.
    There are two situations where link bandwidth needs to be shared between different
    users. The first situation is when several hosts are attached to the same physical
    link. This situation mainly occurs in Local Area Networks (LAN). A LAN is a network
    that efficiently interconnects several hosts (usually a few dozens to a few hundreds)
    in the same room, building or campus. Consider for example a network with five
    hosts. Any of these hosts needs to be able to exchange information with any of
    the other hosts. A first organization for this LAN is the full-mesh.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 网络内部最重要的资源是链路带宽。链路带宽需要在不同用户之间共享的两种情况是：第一种情况是当多个主机连接到同一个物理链路时。这种情况主要发生在局域网（LAN）中。局域网是一种高效地将同一房间、建筑或校园中的多个主机（通常为数十到数百台）相互连接的网络。例如，考虑一个有五个主机的网络。这些主机中的任何一个都需要能够与其他主机交换信息。这个局域网的第一种组织形式是全网状。
- en: '![Figure made with TikZ](../Images/4ef12a85b0fb083d06f7f0e6539c8f58.png)'
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用TikZ制作的图](../Images/4ef12a85b0fb083d06f7f0e6539c8f58.png)'
- en: ''
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 187 A full-mesh network
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图187 全网状网络
- en: The full-mesh is the most reliable and highest performing network to interconnect
    these five hosts. However, this network organization has two important drawbacks.
    First, if a network contains n hosts, then \(\frac{n\times(n-1)}{2}\) links are
    required. If the network contains more than a few hosts, it becomes impossible
    to lay down the required physical links. Second, if the network contains n hosts,
    then each host must have \(n-1\) interfaces to terminate \(n-1\) links. This is
    beyond the capabilities of most hosts. Furthermore, if a new host is added to
    the network, new links have to be laid down and one interface has to be added
    to each participating host. However, full-mesh has the advantage of providing
    the lowest delay between the hosts and the best resiliency against link failures.
    In practice, full-mesh networks are rarely used except when there are few network
    nodes and resiliency is key.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 全网状是连接这五个主机的最可靠和性能最高的网络组织形式。然而，这种网络组织有两个重要的缺点。首先，如果一个网络包含n个主机，则需要\(\frac{n\times(n-1)}{2}\)个链路。如果网络包含的主机数量超过几个，就难以铺设所需的物理链路。其次，如果一个网络包含n个主机，那么每个主机必须拥有\(n-1\)个接口来终止\(n-1\)个链路。这对于大多数主机来说是不可能的。此外，如果网络中添加了新的主机，就需要铺设新的链路，并且每个参与的主机都需要添加一个接口。然而，全网状的优势在于提供了主机之间最低的延迟和最佳的抗链路故障恢复能力。在实践中，全网状网络很少使用，除非网络节点很少且恢复能力至关重要。
- en: The second possible physical organization, which is also used inside computers
    to connect different extension cards, is the bus. In a bus network, all hosts
    are attached to a shared medium, usually a cable through a single interface. When
    one host sends an electrical signal on the bus, the signal is received by all
    hosts attached to the bus. A drawback of bus-based networks is that if the bus
    is physically cut, then the network is split into two isolated networks. For this
    reason, bus-based networks are sometimes considered to be difficult to operate
    and maintain, especially when the cable is long and there are many places where
    it can break. Such a bus-based topology was used in early Ethernet networks.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种可能的物理组织形式，也用于计算机内部连接不同的扩展卡，是总线。在总线网络中，所有主机都连接到一个共享介质上，通常是通过单个接口连接的电缆。当一个主机在总线上发送电信号时，该信号会被总线上的所有主机接收。基于总线的网络的缺点是，如果总线被物理切断，那么网络就会分裂成两个孤立的网络。因此，基于总线的网络有时被认为难以操作和维护，尤其是在电缆很长且有很多可能断裂的地方。这种基于总线的拓扑在早期的以太网网络中使用过。
- en: '![Figure made with TikZ](../Images/3a69ecd6632515f93fca7a7a4e043988.png)'
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用TikZ制作的图](../Images/3a69ecd6632515f93fca7a7a4e043988.png)'
- en: ''
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 188 A network organized as a bus
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图188 总线形结构的网络
- en: A third organization of a computer network is a star topology. In such networks,
    hosts have a single physical interface and there is one physical link between
    each host and the center of the star. The node at the center of the star can be
    either a piece of equipment that amplifies an electrical signal, or an active
    device, such as a piece of equipment that understands the format of the messages
    exchanged through the network. Of course, the failure of the central node implies
    the failure of the network. However, if one physical link fails (e.g. because
    the cable has been cut), then only one node is disconnected from the network.
    In practice, star-shaped networks are easier to operate and maintain than bus-shaped
    networks. Many network administrators also appreciate the fact that they can control
    the network from a central point. Administered from a Web interface, or through
    a console-like connection, the center of the star is a useful point of control
    (enabling or disabling devices) and an excellent observation point (usage statistics).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机网络的第三种组织形式是星形拓扑。在这种网络中，主机有一个单独的物理接口，每个主机与星形中心之间有一个物理链路。星形中心的节点可以是放大电信号的设备，或者是一个主动设备，例如理解通过网络交换的消息格式的设备。当然，中心节点的故障意味着网络的故障。然而，如果某个物理链路失效（例如，因为电缆被切断），那么只有一个节点会从网络中断开。实际上，星形网络比总线形网络更容易操作和维护。许多网络管理员也欣赏他们可以从一个中心点控制网络的事实。通过Web界面或通过类似控制台的联系进行管理，星形中心是一个有用的控制点（启用或禁用设备）和优秀的观察点（使用统计信息）。
- en: '![Figure made with TikZ](../Images/7716555a16a5fea52c47b90cf0272f73.png)'
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用TikZ制作的图](../Images/7716555a16a5fea52c47b90cf0272f73.png)'
- en: ''
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 189 A network organized as a star
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图189 星形结构的网络
- en: A fourth physical organization of a network is the ring topology. Like the bus
    organization, each host has a single physical interface connecting it to the ring.
    Any signal sent by a host on the ring will be received by all hosts attached to
    the ring. From a redundancy point of view, a single ring is not the best solution,
    as the signal only travels in one direction on the ring; thus if one of the links
    composing the ring is cut, the entire network fails. In practice, such rings have
    been used in local area networks, but are now often replaced by star-shaped networks.
    In metropolitan networks, rings are often used to interconnect multiple locations.
    In this case, two parallel links, composed of different cables, are often used
    for redundancy. With such a dual ring, when one ring fails all the traffic can
    be quickly switched to the other ring.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 网络的第四种物理组织形式是环形拓扑。与总线组织类似，每个主机都有一个单独的物理接口连接到环形。在环形上的任何主机发送的信号都将被连接到环上的所有主机接收。从冗余的角度来看，单个环形并不是最佳解决方案，因为信号只在环上单向传输；因此，如果组成环的某个链路被切断，整个网络将失效。在实际应用中，此类环形已在局域网中使用，但现在通常被星形网络所取代。在大都市网络中，环形常用于连接多个地点。在这种情况下，通常使用由不同电缆组成的两个并行链路来实现冗余。在这种双环中，当其中一个环形失效时，所有流量可以迅速切换到另一个环形。
- en: '![Figure made with TikZ](../Images/02439986e682d8116eb77f12b88154ac.png)'
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用TikZ制作的图](../Images/02439986e682d8116eb77f12b88154ac.png)'
- en: ''
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 190 A network organized as a ring
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图190 环形结构的网络
- en: A fifth physical organization of a network is the tree. Such networks are typically
    used when a large number of customers must be connected in a very cost-effective
    manner. Cable TV networks are often organized as trees.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 网络的第五种物理组织形式是树形结构。这种网络通常用于需要以非常经济的方式连接大量客户的情况。有线电视网络通常组织成树形结构。
- en: '![Figure made with TikZ](../Images/1ef1c6253ef9a140ed3a946c46df4dee.png)'
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用TikZ制作的图](../Images/1ef1c6253ef9a140ed3a946c46df4dee.png)'
- en: ''
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 191 A network organized as a tree
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图191 树形结构的网络
- en: Sharing bandwidth[#](#sharing-bandwidth "Link to this heading")
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分享带宽[#](#sharing-bandwidth "链接到本标题")
- en: In all these networks, except the full-mesh, the link bandwidth is shared among
    all connected hosts. Various algorithms have been proposed and are used to efficiently
    share the access to this resource. We explain several of them in the Medium Access
    Control section below.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有这些网络中，除了全连接网络外，链路带宽在所有连接的主机之间共享。已经提出了各种算法，并用于有效地共享对这一资源的访问。我们将在下面的介质访问控制部分解释其中的一些。
- en: Note
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Fairness in computer networks
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机网络的公平性
- en: Sharing resources is important to ensure that the network efficiently serves
    its user. In practice, there are many ways to share resources. Some resource sharing
    schemes consider that some users are more important than others and should obtain
    more resources. For example, on the roads, police cars and ambulances have priority.
    In some cities, traffic lanes are reserved for buses to promote public services,
    … In computer networks, the same problem arise. Given that resources are limited,
    the network needs to enable users to efficiently share them. Before designing
    an efficient resource sharing scheme, one needs to first formalize its objectives.
    In computer networks, the most popular objective for resource sharing schemes
    is that they must be fair. In a simple situation, for example two hosts using
    a shared 2 Mbps link, the sharing scheme should allocate the same bandwidth to
    each user, in this case 1 Mbps. However, in a large networks, simply dividing
    the available resources by the number of users is not sufficient. Consider the
    network shown in the figure below where A1 sends data to A2, B1 to B2, … In this
    network, how should we divide the bandwidth among the different flows ? A first
    approach would be to allocate the same bandwidth to each flow. In this case, each
    flow would obtain 5 Mbps and the link between R2 and R3 would not be fully loaded.
    Another approach would be to allocate 10 Mbps to A1-A2, 20 Mbps to C1-C2 and nothing
    to B1-B2. This is clearly unfair.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 分享资源对于确保网络高效地为用户提供服务非常重要。在实践中，有许多方式可以共享资源。一些资源共享方案认为某些用户比其他用户更重要，应该获得更多资源。例如，在道路上，警车和救护车有优先权。在一些城市，交通车道被保留给公交车以促进公共服务，……在计算机网络中，同样的问题也会出现。鉴于资源有限，网络需要使用户能够高效地共享资源。在设计一个有效的资源共享方案之前，首先需要形式化其目标。在计算机网络中，资源共享方案最流行的目标就是它们必须是公平的。在简单的情况下，例如两个主机使用一个共享的2
    Mbps链路，资源共享方案应该将相同的带宽分配给每个用户，在这种情况下是1 Mbps。然而，在大规模网络中，仅仅将可用资源除以用户数量是不够的。考虑下面图中所示的网络，其中A1向A2发送数据，B1向B2发送，……在这个网络中，我们应该如何在不同流之间分配带宽？一个初步的方法是将相同的带宽分配给每个流。在这种情况下，每个流都会获得5
    Mbps，R2和R3之间的链路将不会完全负载。另一种方法是将10 Mbps分配给A1-A2，20 Mbps分配给C1-C2，而B1-B2则不分配。这显然是不公平的。
- en: '![Figure made with TikZ](../Images/a92629ffc43cb0912e0548fff34a5038.png)'
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用TikZ制作的图](../Images/a92629ffc43cb0912e0548fff34a5038.png)'
- en: ''
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 192 A small network
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图192 小型网络
- en: In large networks, fairness is always a compromise. The most widely used definition
    of fairness is the max-min fairness. A bandwidth allocation in a network is said
    to be max-min fair if it is such that it is impossible to allocate more bandwidth
    to one of the flows without reducing the bandwidth of a flow that already has
    a smaller allocation than the flow that we want to increase. If the network is
    completely known, it is possible to derive a max-min fair allocation as follows.
    Initially, all flows have a null bandwidth and they are placed in the candidate
    set. The bandwidth allocation of all flows in the candidate set is increased until
    one link becomes congested. At this point, the flows that use the congested link
    have reached their maximum allocation. They are removed from the candidate set
    and the process continues until the candidate set becomes empty.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在大型网络中，公平性总是需要妥协。最广泛使用的公平性定义是最大最小公平性。如果一个网络中的带宽分配使得在不减少已经分配带宽小于我们想要增加的流量的带宽的情况下，无法将更多带宽分配给任何一个流，那么这种带宽分配就被认为是最大最小公平的。如果网络完全已知，可以推导出最大最小公平的分配如下。最初，所有流都有一个零带宽，并且它们被放置在候选集中。候选集中所有流的带宽分配都会增加，直到某个链路变得拥塞。在这个时候，使用拥塞链路的流已经达到了它们的最大分配。它们被从候选集中移除，这个过程会一直持续到候选集变为空。
- en: In the above network, the allocation of all flows would grow until A1-A2 and
    B1-B2 reach 5 Mbps. At this point, link R1-R2 becomes congested and these two
    flows have reached their maximum. The allocation for flow C1-C2 can increase until
    reaching 15 Mbps. At this point, link R2-R3 is congested. To increase the bandwidth
    allocated to C1-C2, one would need to reduce the allocation to flow B1-B2. Similarly,
    the only way to increase the allocation to flow B1-B2 would require a decrease
    of the allocation to A1-A2.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述网络中，所有流的分配会增长，直到A1-A2和B1-B2达到5 Mbps。在这个时候，R1-R2链路变得拥塞，这两个流已经达到了它们的最大分配。C1-C2流的分配可以增加到15
    Mbps。在这个时候，R2-R3链路变得拥塞。要增加分配给C1-C2的带宽，就需要减少分配给B1-B2的带宽。同样，唯一增加B1-B2分配的方法是减少A1-A2的分配。
- en: Network congestion[#](#network-congestion "Link to this heading")
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 网络拥塞[#](#network-congestion "链接到本标题")
- en: Sharing bandwidth among the hosts directly attached to a link is not the only
    sharing problem that occurs in computer networks. To understand the general problem,
    let us consider a very simple network which contains only point-to-point links.
    This network contains three hosts and two routers. All the links inside the network
    have the same capacity. For example, let us assume that all links have a bandwidth
    of 1000 bits per second and that the hosts send packets containing exactly one
    thousand bits.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在直接连接到链路的主机之间共享带宽并不是计算机网络中发生的唯一共享问题。为了理解一般问题，让我们考虑一个非常简单的网络，该网络仅包含点对点链路。这个网络包含三个主机和两个路由器。网络内部的所有链路都具有相同的容量。例如，让我们假设所有链路的带宽为每秒1000比特，并且主机发送包含恰好一千比特的数据包。
- en: '![Figure made with TikZ](../Images/f79da50c17973252bf5368a3df95f186.png)'
  id: totrans-36
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用TikZ制作的图](../Images/f79da50c17973252bf5368a3df95f186.png)'
- en: ''
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 193 A small network
  id: totrans-38
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图193 一个小网络
- en: In the network above, consider the case where host A is transmitting packets
    to destination C. A can send one packet per second and its packets will be delivered
    to C. Now, let us explore what happens when host B also starts to transmit a packet.
    Node R1 will receive two packets that must be forwarded to R2. Unfortunately,
    due to the limited bandwidth on the R1-R2 link, only one of these two packets
    can be transmitted. The outcome of the second packet will depend on the available
    buffers on R1. If R1 has one available buffer, it could store the packet that
    has not been transmitted on the R1-R2 link until the link becomes available. If
    R1 does not have available buffers, then the packet needs to be discarded.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述网络中，考虑主机A向目的地C传输数据包的情况。A可以每秒发送一个数据包，并且其数据包将被发送到C。现在，让我们探讨当主机B也开始传输数据包时会发生什么。节点R1将接收到两个必须转发到R2的数据包。不幸的是，由于R1-R2链路上的带宽有限，只能传输这两个数据包中的一个。第二个数据包的结果将取决于R1上可用的缓冲区。如果R1有一个可用的缓冲区，它可以存储在R1-R2链路上尚未传输的数据包，直到链路变得可用。如果R1没有可用的缓冲区，那么数据包需要被丢弃。
- en: Besides the link bandwidth, the buffers on the network nodes are the second
    type of resource that needs to be shared inside the network. The node buffers
    play an important role in the operation of the network because that can be used
    to absorb transient traffic peaks. Consider again the example above. Assume that
    on average host A and host B send a group of three packets every ten seconds.
    Their combined transmission rate (0.6 packets per second) is, on average, lower
    than the network capacity (1 packet per second). However, if they both start to
    transmit at the same time, node R1 will have to absorb a burst of packets. This
    burst of packets is a small network congestion. We will say that a network is
    congested, when the sum of the traffic demand from the hosts is larger than the
    network capacity \(\sum{demand}>capacity\). This network congestion problem is
    one of the most difficult resource sharing problem in computer networks. Congestion
    occurs in almost all networks. Minimizing the amount of congestion is a key objective
    for many network operators. In most cases, they will have to accept transient
    congestion, i.e. congestion lasting a few seconds or perhaps minutes, but will
    want to prevent congestion that lasts days or months. For this, they can rely
    on a wide range of solutions. We briefly present some of these in the paragraphs
    below.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 除了链路带宽之外，网络节点上的缓冲区是需要在网络内部共享的第二种资源。节点缓冲区在网络操作中起着重要作用，因为它们可以用来吸收瞬时的流量峰值。再次考虑上面的例子。假设主机A和主机B平均每十秒发送一组三个数据包。它们的组合传输速率（每秒0.6个数据包）平均低于网络容量（每秒1个数据包）。然而，如果它们同时开始传输，节点R1将不得不吸收一个数据包的突发。这种数据包的突发是一个小网络拥塞。当我们说网络拥塞时，是指来自主机的总流量需求大于网络容量
    \(\sum{需求}>容量\)。这个网络拥塞问题是计算机网络中最难的资源共享问题之一。拥塞几乎发生在所有网络中。最小化拥塞量是许多网络运营商的关键目标。在大多数情况下，他们必须接受短暂的拥塞，即持续几秒或几分钟的拥塞，但希望防止持续数天或数月的拥塞。为此，他们可以依赖一系列广泛的解决方案。以下段落中简要介绍了其中的一些。
- en: If R1 has enough buffers, it will be able to absorb the load without having
    to discard packets. The packets sent by hosts A and B will reach their final destination
    C, but will experience a longer delay than when they are transmitting alone. The
    amount of buffering on the network node is the first parameter that a network
    operator can tune to control congestion inside his network. Given the decreasing
    cost of memory, one could be tempted to put as many buffers [[1]](#fbufferbloat)
    as possible on the network nodes. Let us consider this case in the network above
    and assume that R1 has infinite buffers. Assume now that hosts A and B try to
    transmit a file that corresponds to one thousand packets each. Both are using
    a reliable protocol that relies on go-back-n to recover from transmission errors.
    The transmission starts and packets start to accumulate in R1’s buffers. The presence
    of these packets in the buffers increases the delay between the transmission of
    a packet by A and the return of the corresponding acknowledgment. Given the increasing
    delay, host A (and B as well) will consider that some of the packets that it sent
    have been lost. These packets will be retransmitted and will enter the buffers
    of R1. The occupancy of the buffers of R1 will continue to increase and the delays
    as well. This will cause new retransmissions, … In the end, only one file will
    be delivered (very slowly) to the destination, but the link R1-R2 will transfer
    much more bytes than the size of the file due to the multiple copies of the same
    packets. This is known as the congestion collapse problem [**RFC 896**](https://datatracker.ietf.org/doc/html/rfc896.html).
    Congestion collapse is the nightmare for network operators. When it happens, the
    network carries packets without delivering useful data to the end users.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 R1 有足够的缓冲区，它将能够吸收负载而无需丢弃数据包。主机 A 和 B 发送的数据包将到达它们的最终目的地 C，但将经历比单独传输时更长的延迟。网络节点上的缓冲区数量是网络运营商可以调整以控制其网络内部拥塞的第一个参数。鉴于内存成本的降低，人们可能会倾向于在网络节点上放置尽可能多的缓冲区
    [[1]](#fbufferbloat)。让我们考虑上述网络中的这种情况，并假设 R1 有无限的缓冲区。现在假设主机 A 和 B 尝试传输一个对应于一千个数据包的文件。它们都使用一种依赖于
    go-back-n 从传输错误中恢复的可靠协议。传输开始，数据包开始积累在 R1 的缓冲区中。这些数据包在缓冲区中的存在增加了 A（以及 B）发送数据包和接收相应确认之间的延迟。鉴于延迟的增加，主机
    A（以及 B）将认为它发送的一些数据包已经丢失。这些数据包将被重新传输并进入 R1 的缓冲区。R1 缓冲区的占用将继续增加，延迟也会增加。这将导致新的重传，……
    最后，只有一个文件（非常慢地）被发送到目的地，但由于相同数据包的多个副本，链路 R1-R2 将传输比文件大小更多的字节。这被称为拥塞崩溃问题 [**RFC
    896**](https://datatracker.ietf.org/doc/html/rfc896.html)。拥塞崩溃是网络运营商的噩梦。当它发生时，网络携带数据包而不向最终用户提供有用的数据。
- en: Note
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Congestion collapse on the Internet
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 互联网上的拥塞崩溃
- en: Congestion collapse is unfortunately not only an academic experience. Van Jacobson
    reports in [[Jacobson1988]](../bibliography.html#jacobson1988) one of these events
    that affected him while he was working at the Lawrence Berkeley Laboratory (LBL).
    LBL was two network nodes away from the University of California in Berkeley.
    At that time, the link between the two sites had a bandwidth of 32 Kbps, but some
    hosts were already attached to 10 Mbps LANs. “In October 1986, the data throughput
    from LBL to UC Berkeley … dropped from 32 Kbps to 40 bps. We were fascinated by
    this sudden factor-of-thousand drop in bandwidth and embarked on an investigation
    of why things had gotten so bad.” This work lead to the development of various
    congestion control techniques that have allowed the Internet to continue to grow
    without experiencing widespread congestion collapse events.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 拥塞崩溃（Congestion collapse）不幸地不仅仅是一种学术经验。Van Jacobson 在 [[Jacobson1988]](../bibliography.html#jacobson1988)
    中报告了这样一件事件，它在他担任劳伦斯伯克利实验室（LBL）工作时发生。LBL 距离加州大学伯克利分校有两个网络节点。当时，两个地点之间的链路带宽为 32
    Kbps，但一些主机已经连接到 10 Mbps 的局域网。 “1986 年 10 月，从 LBL 到加州大学的 … 数据吞吐量从 32 Kbps 降至 40
    bps。我们对这种带宽突然降低到千分之一的现象感到着迷，并开始调查为什么事情变得如此糟糕。” 这项工作导致了各种拥塞控制技术的开发，这些技术使得互联网能够在不经历广泛的拥塞崩溃事件的情况下继续增长。
- en: Besides bandwidth and memory, a third resource that needs to be shared inside
    a network is the (packet) processing capacity. To forward a packet, a router needs
    bandwidth on the outgoing link, but it also needs to analyze the packet header
    to perform a lookup inside its forwarding table. Performing these lookup operations
    require resources such as CPU cycles or memory accesses. Routers are usually designed
    to be able to sustain a given packet processing rate, measured in packets per
    second [[2]](#fpps).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 除了带宽和内存之外，网络内部需要共享的第三个资源是（数据包）处理能力。为了转发一个数据包，路由器需要在出链路上有带宽，但它还需要分析数据包头部以在其转发表中执行查找。执行这些查找操作需要资源，如CPU周期或内存访问。路由器通常设计为能够维持一定的数据包处理速率，以每秒数据包数（PPS）来衡量
    [[2]](#fpps)。
- en: Note
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Packets per second versus bits per second
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 每秒数据包数与每秒比特数
- en: 'The performance of network nodes (either routers or switches) can be characterized
    by two key metrics :'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 网络节点（无论是路由器还是交换机）的性能可以通过两个关键指标来描述：
- en: the node’s capacity measured in bits per second
  id: totrans-49
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以每秒比特数衡量的节点容量
- en: ''
  id: totrans-50
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-51
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: the node’s lookup performance measured in packets per second
  id: totrans-52
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以每秒数据包数衡量的节点查找性能
- en: The node’s capacity in bits per second mainly depends on the physical interfaces
    that it uses and also on the capacity of the internal interconnection (bus, crossbar
    switch, …) between the different interfaces inside the node. Many vendors, in
    particular for low-end devices will use the sum of the bandwidth of the nodes’
    interfaces as the node capacity in bits per second. Measurements do not always
    match this maximum theoretical capacity. A well designed network node will usually
    have a capacity in bits per second larger than the sum of its link capacities.
    Such nodes will usually reach this maximum capacity when forwarding large packets.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 节点的容量（以每秒比特数衡量）主要取决于它使用的物理接口，以及节点内部不同接口之间的内部互连（总线、交叉开关等）的容量。许多供应商，特别是对于低端设备，会将节点接口的带宽总和作为节点容量（以每秒比特数衡量）。测量结果并不总是与这个最大理论容量相匹配。一个设计良好的网络节点通常会有一个比其链路容量总和更大的比特每秒容量。这样的节点通常在转发大型数据包时达到这个最大容量。
- en: When a network node forwards small packets, its performance is usually limited
    by the number of lookup operations that it can perform every second. This lookup
    performance is measured in packets per second. The performance may depend on the
    length of the forwarded packets. The key performance factor is the number of minimal
    size packets that are forwarded by the node every second. This rate can lead to
    a capacity in bits per second which is much lower than the sum of the bandwidth
    of the node’s links.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当网络节点转发小型数据包时，其性能通常受限于它每秒可以执行查找操作的数量。这种查找性能以每秒数据包数来衡量。性能可能取决于转发数据包的长度。关键性能因素是节点每秒转发的最小尺寸数据包的数量。这个速率可能导致比特每秒的容量远低于节点链路带宽的总和。
- en: Let us now try to present a broad overview of the congestion problem in networks.
    We will assume that the network is composed of dedicated links having a fixed
    bandwidth [[3]](#fadjust). A network contains hosts that generate and receive
    packets and nodes (routers and switches) that forward packets. Assuming that each
    host is connected via a single link to the network, the largest demand is \(\sum{Access
    Links}\). In practice, this largest demand is never reached and the network will
    be engineered to sustain a much lower traffic demand. The difference between the
    worst-case traffic demand and the sustainable traffic demand can be large, up
    to several orders of magnitude. Fortunately, the hosts are not completely dumb
    and they can adapt their traffic demand to the current state of the network and
    the available bandwidth. For this, the hosts need to sense the current level of
    congestion and adjust their own traffic demand based on the estimated congestion.
    Network nodes can react in different ways to network congestion and hosts can
    sense the level of congestion in different ways.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们尝试对网络拥塞问题进行广泛的概述。我们将假设网络由具有固定带宽的专用链路组成[[3]](#fadjust)。网络包含生成和接收数据包的主机以及转发数据包的节点（路由器和交换机）。假设每个主机通过单个链路连接到网络，最大的需求是\(\sum{访问链路}\)。实际上，这个最大需求永远不会达到，网络将被设计成能够承受远低于最大交通需求。最坏情况下的交通需求与可持续交通需求之间的差异可能很大，高达几个数量级。幸运的是，主机并不完全愚蠢，它们可以根据网络的当前状态和可用带宽调整自己的交通需求。为此，主机需要感知当前的拥塞水平并根据估计的拥塞调整自己的交通需求。网络节点可以以不同的方式对网络拥塞做出反应，主机也可以以不同的方式感知拥塞水平。
- en: Let us first explore which mechanisms can be used inside a network to control
    congestion and how these mechanisms can influence the behavior of the end hosts.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先探索在网络上可以使用哪些机制来控制拥塞，以及这些机制如何影响终端主机的行为。
- en: As explained earlier, one of the first manifestation of congestion on network
    nodes is the saturation of the network links that leads to a growth in the occupancy
    of the buffers of the node. This growth of the buffer occupancy implies that some
    packets will spend more time in the buffer and thus in the network. If hosts measure
    the network delays (e.g. by measuring the round-trip-time between the transmission
    of a packet and the return of the corresponding acknowledgment) they could start
    to sense congestion. On low bandwidth links, a growth in the buffer occupancy
    can lead to an increase of the delays which can be easily measured by the end
    hosts. On high bandwidth links, a few packets inside the buffer will cause a small
    variation in the delay which may not necessarily be larger that the natural fluctuations
    of the delay measurements.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，网络节点上拥塞的第一个表现是网络链路的饱和，这导致节点缓冲区占用率的增长。缓冲区占用率的增长意味着一些数据包将在缓冲区中花费更多时间，从而在网络中停留更长时间。如果主机测量网络延迟（例如，通过测量数据包传输和相应的确认返回之间的往返时间），它们可以开始感知拥塞。在低带宽链路上，缓冲区占用率的增长可能导致延迟的增加，这可以通过终端主机轻松测量。在高带宽链路上，缓冲区内的几个数据包可能导致延迟的小幅变化，这不一定比延迟测量的自然波动更大。
- en: If the buffer’s occupancy continues to grow, it will overflow and packets will
    need to be discarded. Discarding packets during congestion is the second possible
    reaction of a network node to congestion. Before looking at how a node can discard
    packets, it is interesting to discuss qualitatively the impact of the buffer occupancy
    on the reliable delivery of data through a network. This is illustrated by figure
    [Fig. 194](#fig-congestion-jain), adapted from [[Jain1990]](../bibliography.html#jain1990).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果缓冲区的占用率持续增长，它将溢出，并且需要丢弃数据包。在拥塞期间丢弃数据包是网络节点对拥塞的第二种可能反应。在探讨节点如何丢弃数据包之前，讨论缓冲区占用对通过网络可靠传输数据的影响是有趣的。这可以通过图[图194](#fig-congestion-jain)，改编自[[Jain1990]](../bibliography.html#jain1990)来说明。
- en: '![../_images/jain.png](../Images/b9e0fdb8cefccc00202ebacd9b171691.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/jain.png](../Images/b9e0fdb8cefccc00202ebacd9b171691.png)'
- en: Fig. 194 Network congestion[#](#fig-congestion-jain "Link to this image")
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图194 网络拥塞[#](#fig-congestion-jain "链接到这张图片")
- en: When the network load is low, buffer occupancy and link utilization are low.
    The buffers on the network nodes are mainly used to absorb very short bursts of
    packets, but on average the traffic demand is lower than the network capacity.
    If the demand increases, the average buffer occupancy will increase as well. Measurements
    have shown that the total throughput increases as well. If the buffer occupancy
    is zero or very low, transmission opportunities on network links can be missed.
    This is not the case when the buffer occupancy is small but non zero. However,
    if the buffer occupancy continues to increase, the buffer becomes overloaded and
    the throughput does not increase anymore. When the buffer occupancy is close to
    the maximum, the throughput may decrease. This drop in throughput can be caused
    by excessive retransmissions of reliable protocols that incorrectly assume that
    previously sent packets have been lost while they are still waiting in the buffer.
    The network delay on the other hand increases with the buffer occupancy. In practice,
    a good operating point for a network buffer is a low occupancy to achieve high
    link utilization and also low delay for interactive applications.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 当网络负载较低时，缓冲区占用率和链路利用率都较低。网络节点的缓冲区主要用于吸收非常短的数据包突发，但平均而言，流量需求低于网络容量。如果需求增加，平均缓冲区占用率也会增加。测量表明，总吞吐量也会增加。如果缓冲区占用率为零或非常低，可能会错过网络链路上的传输机会。当缓冲区占用率较小但非零时，情况并非如此。然而，如果缓冲区占用率持续增加，缓冲区就会过载，吞吐量不再增加。当缓冲区占用率接近最大值时，吞吐量可能会下降。这种吞吐量下降可能是由于可靠协议的过度重传造成的，这些协议错误地假设之前发送的数据包已经丢失，而它们仍在缓冲区中等待。另一方面，网络延迟会随着缓冲区占用率的增加而增加。在实践中，网络缓冲区的一个良好工作点是低占用率，以实现高链路利用率和低延迟，这对于交互式应用来说也很重要。
- en: 'Discarding packets is one of the signals that the network nodes can use to
    inform the hosts of the current level of congestion. Buffers on network nodes
    are usually used as FIFO queues to preserve packet ordering. Several packet discard
    mechanisms have been proposed for network nodes. These techniques basically answer
    two different questions :'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 丢弃数据包是网络节点可以用来通知主机当前拥塞水平的信号之一。网络节点的缓冲区通常用作FIFO队列以保持数据包顺序。已经为网络节点提出了几种数据包丢弃机制。这些技术基本上回答了两个不同的问题：
- en: 'What triggers a packet to be discarded ? What are the conditions that lead
    a network node to decide to discard a packet? The simplest answer to this question
    is : When the buffer is full. Although this is a good congestion indication, it
    is probably not the best one from a performance viewpoint. An alternative is to
    discard packets when the buffer occupancy grows too much. In this case, it is
    likely that the buffer will become full shortly. Since packet discarding is an
    information that allows hosts to adapt their transmission rate, discarding packets
    early could allow hosts to react earlier and thus prevent congestion from happening.'
  id: totrans-63
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么触发数据包被丢弃？导致网络节点决定丢弃数据包的条件是什么？对这个问题的最简单回答是：当缓冲区满时。虽然这是一个很好的拥塞指示，但从性能角度来看，可能不是最好的。另一种选择是在缓冲区占用率增长过多时丢弃数据包。在这种情况下，缓冲区很快就会满。由于数据包丢弃是允许主机调整其传输速率的信息，因此提前丢弃数据包可以允许主机更早地做出反应，从而防止拥塞发生。
- en: ''
  id: totrans-64
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-65
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Which packet(s) should be discarded ? Once the network node has decided to discard
    packets, it needs to actually discard real packets.
  id: totrans-66
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应该丢弃哪些数据包？一旦网络节点决定丢弃数据包，它需要实际丢弃真实的数据包。
- en: By combining different answers to these questions, network researchers have
    developed different packet discard mechanisms.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 通过结合对这些问题的不同回答，网络研究人员已经开发出不同的数据包丢弃机制。
- en: Tail drop is the simplest packet discard technique. When a buffer is full, the
    arriving packet is discarded. Tail drop can be easily implemented. This is, by
    far, the most widely used packet discard mechanism. However, it suffers from two
    important drawbacks. First, since tail drop discards packets only when the buffer
    is full, buffers tend to be congested and real-time applications may suffer from
    increased delays. Second, tail drop is blind when it discards a packet. It may
    discard a packet from a low bandwidth interactive flow while most of the buffer
    is used by large file transfers.
  id: totrans-68
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尾丢弃是最简单的数据包丢弃技术。当缓冲区满时，到达的数据包将被丢弃。尾丢弃可以很容易地实现。到目前为止，这是最广泛使用的丢弃机制。然而，它有两个重要的缺点。首先，由于尾丢弃仅在缓冲区满时丢弃数据包，缓冲区往往会发生拥塞，实时应用可能会遭受增加的延迟。其次，尾丢弃在丢弃数据包时是盲目的。它可能会丢弃来自低带宽交互流的数据包，而此时缓冲区的大部分空间被大文件传输占用。
- en: ''
  id: totrans-69
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-70
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Drop from front is an alternative packet discard technique. Instead of removing
    the arriving packet, it removes the packet that was at the head of the queue.
    Discarding this packet instead of the arriving one can have two advantages. First,
    it already stayed a long time in the buffer. Second, hosts should be able to detect
    the loss (and thus the congestion) earlier.
  id: totrans-71
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 前端丢弃是另一种数据包丢弃技术。它不是移除到达的数据包，而是移除队列头部的数据包。丢弃这个数据包而不是到达的数据包可以有两个优点。首先，它已经在缓冲区中停留了很长时间。其次，主机应该能够更早地检测到丢失（以及拥塞）。
- en: ''
  id: totrans-72
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-73
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Probabilistic drop. Various random drop techniques have been proposed. A frequently
    cited technique is Random Early Discard (RED) [[FJ1993]](../bibliography.html#fj1993).
    RED measures the average buffer occupancy and discards packets with a given probability
    when this average occupancy is too high. Compared to tail drop and drop from front,
    an advantage of RED is that thanks to the probabilistic drops, packets should
    be discarded from different flows in proportion of their bandwidth.
  id: totrans-74
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 概率丢弃。已经提出了各种随机丢弃技术。经常引用的技术是随机早期丢弃（RED）[[FJ1993]](../bibliography.html#fj1993)。RED测量平均缓冲区占用率，并在平均占用率过高时以一定的概率丢弃数据包。与尾丢弃和前端丢弃相比，RED的一个优点是，由于概率丢弃，数据包应该按照它们带宽的比例从不同的流中丢弃。
- en: Discarding packets is a frequent reaction to network congestion. Unfortunately,
    discarding packets is not optimal since a packet which is discarded on a network
    node has already consumed resources on the upstream nodes. There are other ways
    for the network to inform the end hosts of the current congestion level. A first
    solution is to mark the packets when a node is congested. Several networking technologies
    have relied on this kind of packet marking.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 丢弃数据包是对网络拥塞的常见反应。遗憾的是，丢弃数据包并不是最优的，因为已经在网络节点上丢弃的数据包已经在上游节点上消耗了资源。网络还有其他方式来通知终端主机当前的拥塞水平。第一个解决方案是在节点拥塞时标记数据包。几种网络技术都依赖于这种类型的包标记。
- en: In datagram networks, Forward Explicit Congestion Notification (FECN) can be
    used. One field of the packet header, typically one bit, is used to indicate congestion.
    When a host sends a packet, the congestion bit is unset. If the packet passes
    through a congested node, the congestion bit is set. The destination can then
    determine the current congestion level by measuring the fraction of the packets
    that it received with the congestion bit set. It may then return this information
    to the sending host to allow it to adapt its retransmission rate. Compared to
    packet discarding, the main advantage of FECN is that hosts can detect congestion
    explicitly without having to rely on packet losses.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据报网络中，可以使用前向显式拥塞通知（FECN）。数据包头部的某个字段，通常是1位，用于指示拥塞。当主机发送数据包时，拥塞位被清除。如果数据包通过拥塞节点，拥塞位被设置。目的地可以通过测量收到拥塞位设置的数据包的比例来确定当前的拥塞水平。然后，它可以向发送主机返回此信息，以便它能够调整其重传速率。与数据包丢弃相比，FECN的主要优点是主机可以明确地检测到拥塞，而无需依赖于数据包丢失。
- en: In virtual circuit networks, packet marking can be improved if the return packets
    follow the reverse path of the forward packets. It this case, a network node can
    detect congestion on the forward path (e.g. due to the size of its buffer), but
    mark the packets on the return path. Marking the return packets (e.g. the acknowledgments
    used by reliable protocols) provides a faster feedback to the sending hosts compared
    to FECN. This technique is usually called Backward Explicit Congestion Notification
    (BECN).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在虚拟电路网络中，如果返回数据包遵循正向数据包的反向路径，则数据包标记可以得以改进。在这种情况下，网络节点可以检测到正向路径上的拥塞（例如，由于其缓冲区的大小），但在返回路径上标记数据包。与FECN相比，标记返回数据包（例如，可靠协议使用的确认）为发送主机提供了更快的反馈。这种技术通常被称为向后显式拥塞通知（BECN）。
- en: If the packet header does not contain any bit in the header to represent the
    current congestion level, an alternative is to allow the network nodes to send
    a control packet to the source to indicate the current congestion level. Some
    networking technologies use such control packets to explicitly regulate the transmission
    rate of sources. However, their usage is mainly restricted to small networks.
    In large networks, network nodes usually avoid using such control packets. These
    control packets are even considered to be dangerous in some networks. First, using
    them increases the network load when the network is congested. Second, while network
    nodes are optimized to forward packets, they are usually pretty slow at creating
    new packets.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据包头部不包含任何表示当前拥塞级别的位，则一种替代方案是允许网络节点向源发送控制数据包以指示当前拥塞级别。一些网络技术使用此类控制数据包来显式调节源传输速率。然而，它们的用途主要限于小型网络。在大规模网络中，网络节点通常避免使用此类控制数据包。在某些网络中，这些控制数据包甚至被认为是有危险的。首先，在拥塞时使用它们会增加网络负载。其次，虽然网络节点优化了转发数据包，但它们在创建新数据包方面通常相当慢。
- en: Dropping and marking packets is not the only possible reaction of a router that
    becomes congested. A router could also selectively delay packets belonging to
    some flows. There are different algorithms that can be used by a router to delay
    packets. If the objective of the router is to fairly distribute to bandwidth of
    an output link among competing flows, one possibility is to organize the buffers
    of the router as a set of queues. For simplicity, let us assume that the router
    is capable of supporting a fixed number of concurrent flows, say N. One of the
    queues of the router is associated to each flow and when a packet arrives, it
    is placed at the tail of the corresponding queue. All the queues are controlled
    by a scheduler. A scheduler is an algorithm that is run each time there is an
    opportunity to transmit a packet on the outgoing link. Various schedulers have
    been proposed in the scientific literature and some are used in real routers.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 丢弃和标记数据包不是拥塞的路由器可能采取的唯一反应。路由器还可以选择性地延迟属于某些流的数据包。路由器可以使用不同的算法来延迟数据包。如果路由器的目标是公平地在竞争流之间分配输出链路的带宽，那么一种可能性是将路由器的缓冲区组织成一组队列。为了简单起见，让我们假设路由器能够支持固定数量的并发流，比如说N。路由器的一个队列与每个流相关联，当数据包到达时，它被放置在相应队列的尾部。所有队列都由一个调度器控制。调度器是一种算法，每次有机会在出站链路上传输数据包时都会运行。科学文献中已经提出了各种调度器，其中一些被用于实际的路由器。
- en: '![Figure made with TikZ](../Images/e6916b3dd773fa746d317a93e0a077db.png)'
  id: totrans-80
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用TikZ制作的图](../Images/e6916b3dd773fa746d317a93e0a077db.png)'
- en: ''
  id: totrans-81
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 195 A round-robin scheduler, where N = 5
  id: totrans-82
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图195：循环调度器，其中N = 5
- en: A very simple scheduler is the round-robin scheduler. This scheduler serves
    all the queues in a round-robin fashion. If all flows send packets of the same
    size, then the round-robin scheduler fairly allocates the bandwidth among the
    different flows. Otherwise, it favors flows that are using larger packets. Extensions
    to the round-robin scheduler have been proposed to provide a fair distribution
    of the bandwidth with variable-length packets [[SV1995]](../bibliography.html#sv1995)
    but these are outside the scope of this chapter.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 一个非常简单的调度器是循环调度器。这种调度器以循环方式服务所有队列。如果所有流发送相同大小的数据包，那么循环调度器将公平地在不同流之间分配带宽。否则，它优先考虑使用较大数据包的流。已经提出了循环调度器的扩展，以提供可变长度数据包的公平带宽分配
    [[SV1995]](../bibliography.html#sv1995)，但这些超出了本章的范围。
- en: '[PRE0]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Distributing the load across the network[#](#distributing-the-load-across-the-network
    "Link to this heading")
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在网络中分配负载[#](#distributing-the-load-across-the-network "链接到本标题")
- en: Delays, packet discards, packet markings and control packets are the main types
    of information that the network can exchange with the end hosts. Discarding packets
    is the main action that a network node can perform if the congestion is too severe.
    Besides tackling congestion at each node, it is also possible to divert some traffic
    flows from heavily loaded links to reduce congestion. Early routing algorithms
    [[MRR1980]](../bibliography.html#mrr1980) have used delay measurements to detect
    congestion between network nodes and update the link weights dynamically. By reflecting
    the delay perceived by applications in the link weights used for the shortest
    paths computation, these routing algorithms managed to dynamically change the
    forwarding paths in reaction to congestion. However, deployment experience showed
    that these dynamic routing algorithms could cause oscillations and did not necessarily
    lower congestion. Deployed datagram networks rarely use dynamic routing algorithms,
    except in some wireless networks. In datagram networks, the state of the art reaction
    to long term congestion, i.e. congestion lasting hours, days or more, is to measure
    the traffic demand and then select the link weights [[FRT2002]](../bibliography.html#frt2002)
    that allow minimizing the maximum link loads. If the congestion lasts longer,
    changing the weights is not sufficient anymore and the network needs to be upgraded
    with additional or faster links. However, in Wide Area Networks, adding new links
    can take months.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 延迟、数据包丢弃、数据包标记和控制数据包是网络可以与终端主机交换的主要信息类型。如果拥塞过于严重，丢弃数据包是网络节点可以执行的主要操作。除了在每个节点解决拥塞外，还可以将一些流量从负载过重的链路中转移出来以减少拥塞。早期的路由算法
    [[MRR1980]](../bibliography.html#mrr1980) 使用延迟测量来检测网络节点之间的拥塞并动态更新链路权重。通过将应用程序感知到的延迟反映在用于最短路径计算的链路权重中，这些路由算法能够动态地改变转发路径以应对拥塞。然而，部署经验表明，这些动态路由算法可能会引起振荡，并不一定能够降低拥塞。部署的数据报网络很少使用动态路由算法，除了在某些无线网络中。在数据报网络中，对长期拥塞（即持续数小时、数天或更长时间的拥塞）的最佳反应是测量流量需求，然后选择允许最小化最大链路负载的链路权重
    [[FRT2002]](../bibliography.html#frt2002)。如果拥塞持续更长时间，改变权重就不再足够，网络需要通过添加额外的或更快的链路进行升级。然而，在广域网络中，添加新链路可能需要数月时间。
- en: In virtual circuit networks, another way to manage or prevent congestion is
    to limit the number of circuits that use the network at any time. This technique
    is usually called connection admission control. When a host requests the creation
    of a new circuit in the network, it specifies the destination and in some networking
    technologies the required bandwidth. With this information, the network can check
    whether there are enough resources available to reach this particular destination.
    If yes, the circuit is established. If not, the request is denied and the host
    will have to defer the creation of its virtual circuit. Connection admission control
    schemes are widely used in the telephone networks. In these networks, a busy tone
    corresponds to an unavailable destination or a congested network.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在虚拟电路网络中，管理或防止拥塞的另一种方法是限制在任何时候使用网络的电路数量。这种技术通常被称为连接接入控制。当主机请求在网络中创建新的电路时，它会指定目的地，在某些网络技术中还需要指定所需的带宽。有了这些信息，网络可以检查是否有足够的资源可用以到达这个特定的目的地。如果是的话，电路就会建立。如果不是，请求将被拒绝，主机将不得不推迟其虚拟电路的创建。连接接入控制方案在电话网络中得到广泛应用。在这些网络中，忙音表示不可用的目的地或拥塞的网络。
- en: In datagram networks, this technique cannot be easily used since the basic assumption
    of such a network is that a host can send any packet towards any destination at
    any time. A host does not need to request the authorization of the network to
    send packets towards a particular destination.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据报网络中，这种技术不能轻易使用，因为这种网络的基本假设是主机可以在任何时候向任何目的地发送任何数据包。主机不需要请求网络授权以向特定目的地发送数据包。
- en: Based on the feedback received from the network, the hosts can adjust their
    transmission rate. We discuss in section Congestion control some techniques that
    allow hosts to react to congestion.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 根据从网络收到的反馈，主机可以调整它们的传输速率。我们在“拥塞控制”一节中讨论了一些允许主机对拥塞做出反应的技术。
- en: Another way to share the network resources is to distribute the load across
    multiple links. Many techniques have been designed to spread the load over the
    network. As an illustration, let us briefly consider how the load can be shared
    when accessing some content. Consider a large and popular file such as the image
    of a Linux distribution or the upgrade of a commercial operating system that will
    be downloaded by many users. There are many ways to distribute this large file.
    A naive solution is to place one copy of the file on a server and allow all users
    to download this file from the server. If the file is popular and millions of
    users want to download it, the server will quickly become overloaded. There are
    two classes of solutions that can be used to serve a large number of users. A
    first approach is to store the file on servers whose name is known by the clients.
    Before retrieving the file, each client will query the name service to obtain
    the address of the server. If the file is available from many servers, the name
    service can provide different addresses to different clients. This will automatically
    spread the load since different clients will download the file from different
    servers. Most large content providers use such a solution to distribute large
    files or videos.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种共享网络资源的方法是将负载分配到多个链路上。已经设计了许多技术来在网络中分散负载。作为一个例子，让我们简要地考虑在访问某些内容时如何共享负载。考虑一个大型且受欢迎的文件，例如Linux发行版的镜像或商业操作系统的升级，许多用户将下载这些文件。有许多方法可以分发这个大文件。一个简单的方法是将文件的副本放在服务器上，并允许所有用户从服务器下载这个文件。如果文件很受欢迎，并且有数百万用户想要下载它，服务器将很快过载。有两种类型的解决方案可以用来服务大量的用户。第一种方法是将文件存储在客户端已知名称的服务器上。在检索文件之前，每个客户端都会查询名称服务以获取服务器的地址。如果文件可以从多个服务器获取，名称服务可以为不同的客户端提供不同的地址。这将自动分散负载，因为不同的客户端将从不同的服务器下载文件。大多数大型内容提供商使用这种解决方案来分发大文件或视频。
- en: There is another solution that allows spreading the load among many sources
    without relying on the name service. The popular [bittorent](https://www.bittorrent.com)
    service is an example of this approach. With this solution, each file is divided
    in blocks of fixed size. To retrieve a file, a client needs to retrieve all the
    blocks that compose the file. However, nothing forces the client to retrieve all
    the blocks in sequence and from the same server. Each file is associated with
    metadata that indicates for each block a list of addresses of hosts that store
    this block. To retrieve a complete file, a client first downloads the metadata.
    Then, it tries to retrieve each block from one of the hosts that store the block.
    In practice, implementations often try to download several blocks in parallel.
    Once one block has been successfully downloaded, the next block can be requested.
    If a host is slow to provide one block or becomes unavailable, the client can
    contact another host listed in the metadata. Most deployments of bittorrent allow
    the clients to participate to the distribution of blocks. Once a client has downloaded
    one block, it contacts the server which stores the metadata to indicate that it
    can also provide this block. With this scheme, when a file is popular, its blocks
    are downloaded by many hosts that automatically participate in the distribution
    of the blocks. Thus, the number of servers that are capable of providing blocks
    from a popular file automatically increases with the file’s popularity.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种解决方案允许在不依赖名称服务的情况下，将负载分散到多个来源。流行的[bittorent](https://www.bittorrent.com)服务就是这种方法的例子。使用这种解决方案，每个文件被分成固定大小的块。为了检索一个文件，客户端需要检索组成该文件的所有块。然而，没有任何东西强迫客户端按顺序从同一服务器检索所有块。每个文件都与元数据相关联，该元数据为每个块列出了一个存储该块的宿主机的地址列表。为了检索完整的文件，客户端首先下载元数据。然后，它尝试从存储该块的宿主机之一检索每个块。在实践中，实现通常尝试并行下载多个块。一旦成功下载了一个块，就可以请求下一个块。如果一个宿主机在提供某个块时速度较慢或变得不可用，客户端可以联系元数据中列出的另一个宿主机。大多数bittorrent部署允许客户端参与块的分发。一旦客户端下载了一个块，它就会联系存储元数据的服务器，表明它也可以提供这个块。使用这种方案，当一个文件很受欢迎时，它的块会被许多自动参与块分发的宿主机下载。因此，能够提供流行文件块的宿主机数量会随着文件受欢迎程度的增加而自动增加。
- en: 'Now that we have provided a broad overview of the techniques that can be used
    to spread the load and allocate resources in the network, let us analyze two techniques
    in more details : Medium Access Control and Congestion control.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经提供了关于如何在网络中分配资源的技术概述，让我们更详细地分析两种技术：介质访问控制和拥塞控制。
- en: Medium Access Control algorithms[#](#medium-access-control-algorithms "Link
    to this heading")
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介质访问控制算法[#](#medium-access-control-algorithms "链接到本标题")
- en: The common problem among Local Area Networks is how to efficiently share the
    available bandwidth. If two devices send a frame at the same time, the two electrical,
    optical or radio signals that correspond to these frames will appear at the same
    time on the transmission medium and a receiver will not be able to decode either
    frame. Such simultaneous transmissions are called collisions. A collision may
    involve frames transmitted by two or more devices attached to the Local Area Network.
    Collisions are the main cause of errors in wired Local Area Networks.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 局域网中普遍存在的问题是如何有效地共享可用带宽。如果两个设备同时发送一个帧，对应这些帧的两个电、光或无线电信号将同时出现在传输介质上，接收器将无法解码任何一个帧。这种同时传输称为冲突。冲突可能涉及局域网中连接的两个或多个设备的帧。冲突是有线局域网中错误的主要原因。
- en: 'All Local Area Network technologies rely on a Medium Access Control algorithm
    to regulate the transmissions to either minimize or avoid collisions. There are
    two broad families of Medium Access Control algorithms :'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 所有局域网技术都依赖于介质访问控制算法来调节传输，以最小化或避免冲突。介质访问控制算法主要分为两大类：
- en: Deterministic or pessimistic MAC algorithms. These algorithms assume that collisions
    are a very severe problem and that they must be completely avoided. These algorithms
    ensure that at any time, at most one device is allowed to send a frame on the
    LAN. This is usually achieved by using a distributed protocol which elects one
    device that is allowed to transmit at each time. A deterministic MAC algorithm
    ensures that no collision will happen, but there is some overhead in regulating
    the transmission of all the devices attached to the LAN.
  id: totrans-96
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定性或悲观的MAC算法。这些算法假设冲突是一个非常严重的问题，必须完全避免。这些算法确保在任何时候，最多只有一个设备被允许在局域网上发送帧。这通常是通过使用分布式协议来实现的，该协议在每个时间选择一个允许传输的设备。确定性MAC算法确保不会发生冲突，但调节局域网中所有设备的传输会有一些开销。
- en: ''
  id: totrans-97
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-98
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Stochastic or optimistic MAC algorithms. These algorithms assume that collisions
    are part of the normal operation of a Local Area Network. They aim to minimize
    the number of collisions, but they do not try to avoid all collisions. Stochastic
    algorithms are usually easier to implement than deterministic ones.
  id: totrans-99
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机或乐观的MAC算法。这些算法假设冲突是局域网正常操作的一部分。它们的目的是最小化冲突的数量，但它们并不试图避免所有冲突。随机算法通常比确定性算法更容易实现。
- en: We first discuss a simple deterministic MAC algorithm and then we describe several
    important optimistic algorithms, before coming back to a distributed and deterministic
    MAC algorithm.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先讨论一个简单的确定性MAC算法，然后描述几个重要的乐观算法，最后回到分布式和确定性MAC算法。
- en: Static allocation methods[#](#static-allocation-methods "Link to this heading")
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 静态分配方法[#](#static-allocation-methods "链接到本标题")
- en: A first solution to share the available resources among all the devices attached
    to one Local Area Network is to define, a priori, the distribution of the transmission
    resources among the different devices. If N devices need to share the transmission
    capacities of a LAN operating at b Mbps, each device could be allocated a bandwidth
    of \(\frac{b}{N}\) Mbps.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个局域网中，将可用资源在所有连接的设备之间共享的第一个解决方案是在事先定义不同设备之间的传输资源分配。如果N个设备需要共享一个以b Mbps运行的局域网的传输容量，每个设备可以分配到\(\frac{b}{N}\)
    Mbps的带宽。
- en: Limited resources need to be shared in other environments than Local Area Networks.
    Since the first radio transmissions by [Marconi](http://en.wikipedia.org/wiki/Guglielmo_Marconi)
    more than one century ago, many applications that exchange information through
    radio signals have been developed. Each radio signal is an electromagnetic wave
    whose power is centered around a given frequency. The radio spectrum corresponds
    to frequencies ranging between roughly 3 KHz and 300 GHz. Frequency allocation
    plans negotiated among governments reserve most frequency ranges for specific
    applications such as broadcast radio, broadcast television, mobile communications,
    aeronautical radio navigation, amateur radio, satellite, etc. Each frequency range
    is then subdivided into channels and each channel can be reserved for a given
    application, e.g. a radio broadcaster in a given region.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在局域网以外的其他环境中需要共享有限资源。自从一个多世纪前[马可尼](http://en.wikipedia.org/wiki/Guglielmo_Marconi)进行第一次无线电传输以来，已经开发了许多通过无线电信号交换信息的应用。每个无线电信号都是一个以给定频率为中心的电磁波。无线电频谱对应于大约3
    KHz到300 GHz之间的频率。政府之间协商的频率分配计划为广播无线电、广播电视、移动通信、航空无线电导航、业余无线电、卫星等特定应用保留了大多数频率范围。然后，每个频率范围被细分为频道，每个频道可以保留给特定的应用，例如某个地区的广播电台。
- en: Frequency Division Multiplexing (FDM) is a static allocation scheme in which
    a frequency is allocated to each device attached to the shared medium. As each
    device uses a different transmission frequency, collisions cannot occur. In optical
    networks, a variant of FDM called Wavelength Division Multiplexing (WDM) can be
    used. An optical fiber can transport light at different wavelengths without interference.
    With WDM, a different wavelength is allocated to each of the devices that share
    the same optical fiber.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 频分复用（FDM）是一种静态分配方案，其中为连接到共享介质的每个设备分配一个频率。由于每个设备使用不同的传输频率，因此不会发生冲突。在光网络中，可以使用FDM的一种变体，称为波分复用（WDM）。光纤可以在不同的波长上传输光而不发生干扰。使用WDM，为共享同一光纤的每个设备分配不同的波长。
- en: Time Division Multiplexing (TDM) is a static bandwidth allocation method that
    was initially defined for the telephone network. In the fixed telephone network,
    a voice conversation is usually transmitted as a 64 Kbps signal. Thus, a telephone
    conservation generates 8 KBytes per second or one byte every 125 microseconds.
    Telephone conversations often need to be multiplexed together on a single line.
    For example, in Europe, thirty 64 Kbps voice signals are multiplexed over a single
    2 Mbps (E1) line. This is done by using Time Division Multiplexing (TDM). TDM
    divides the transmission opportunities into slots. In the telephone network, a
    slot corresponds to 125 microseconds. A position inside each slot is reserved
    for each voice signal. The figure below illustrates TDM on a link that is used
    to carry four voice conversations. The vertical lines represent the slot boundaries
    and the letters the different voice conversations. One byte from each voice conversation
    is sent during each 125 microseconds slot. The byte corresponding to a given conversation
    is always sent at the same position in each slot.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 时间分复用（TDM）是一种最初为电话网络定义的静态带宽分配方法。在固定电话网络中，语音对话通常以64 Kbps的信号传输。因此，电话对话每秒生成8 KBytes或每125微秒一个字节。电话对话通常需要在一个单独的线路上复用在一起。例如，在欧洲，三十个64
    Kbps的语音信号通过一个2 Mbps（E1）的单独线路复用。这是通过使用时间分复用（TDM）实现的。TDM将传输机会划分为时隙。在电话网络中，一个时隙对应于125微秒。每个时隙内的一个位置为每个语音信号预留。下面的图示说明了用于携带四个语音对话的链路上的TDM。垂直线代表时隙边界，字母代表不同的语音对话。每个语音对话的字节在每个125微秒的时隙中发送。对应于给定对话的字节总是在每个时隙中的相同位置发送。
- en: '![Figure made with TikZ](../Images/a5ce7017001779fb85df0a821c9dfa33.png)'
  id: totrans-106
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用TikZ制作的图](../Images/a5ce7017001779fb85df0a821c9dfa33.png)'
- en: ''
  id: totrans-107
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 196 Time-division multiplexing
  id: totrans-108
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图196 时间分复用
- en: TDM as shown above can be completely static, i.e. the same conversations always
    share the link, or dynamic. In the latter case, the two endpoints of the link
    must exchange messages specifying which conversation uses which byte inside each
    slot. Thanks to these control messages, it is possible to dynamically add and
    remove voice conversations from a given link.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 如上图所示，TDM可以是完全静态的，即相同的对话始终共享链路，也可以是动态的。在后一种情况下，链路的两个端点必须交换消息，指定每个对话在每个时隙中使用哪个字节。得益于这些控制消息，可以动态地向给定链路添加和删除语音对话。
- en: TDM and FDM are widely used in telephone networks to support fixed bandwidth
    conversations. Using them in Local Area Networks that support computers would
    probably be inefficient. Computers usually do not send information at a fixed
    rate. Instead, they often have an on-off behavior. During the on period, the computer
    tries to send at the highest possible rate, e.g. to transfer a file. During the
    off period, which is often much longer than the on period, the computer does not
    transmit any packet. Using a static allocation scheme for computers attached to
    a LAN would lead to huge inefficiencies, as they would only be able to transmit
    at \(\frac{1}{N}\) of the total bandwidth during their on period, despite the
    fact that the other computers are in their off period and thus do not need to
    transmit any information. The dynamic MAC algorithms discussed in the remainder
    of this chapter aim to solve this problem.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: TDM和FDM在电话网络中被广泛用于支持固定带宽的通话。在支持计算机的局域网中使用它们可能会效率低下。计算机通常不会以固定速率发送信息。相反，它们往往具有开/关的行为。在开启期间，计算机试图以尽可能高的速率发送信息，例如传输文件。在关闭期间，这个期间通常比开启期间长得多，计算机不发送任何数据包。为连接到局域网的计算机使用静态分配方案会导致巨大的低效率，因为它们在开启期间只能以\(\frac{1}{N}\)的总带宽进行传输，尽管其他计算机处于关闭期间，因此不需要传输任何信息。本章余下的部分讨论的动态MAC算法旨在解决这个问题。
- en: ALOHA[#](#aloha "Link to this heading")
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ALOHA[#](#aloha "链接到这个标题")
- en: In the 1960s, computers were mainly mainframes with a few dozen terminals attached
    to them. These terminals were usually in the same building as the mainframe and
    were directly connected to it. In some cases, the terminals were installed in
    remote locations and connected through a [modem](../glossary.html#term-modem)
    attached to a [dial-up line](../glossary.html#term-dial-up-line). The university
    of Hawaii chose a different organization. Instead of using telephone lines to
    connect the distant terminals, they developed the first packet radio technology
    [[Abramson1970]](../bibliography.html#abramson1970). Until then, computer networks
    were built on top of either the telephone network or physical cables. ALOHANet
    showed that it is possible to use radio signals to interconnect computers.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在20世纪60年代，计算机主要是大型机，连接了几十个终端。这些终端通常位于主机的同一栋大楼内，并直接连接到它。在某些情况下，终端被安装在远程位置，并通过连接到[拨号线路](../glossary.html#term-dial-up-line)的[调制解调器](../glossary.html#term-modem)进行连接。夏威夷大学选择了不同的组织方式。他们没有使用电话线来连接远程终端，而是开发了第一种分组无线电技术[[Abramson1970]](../bibliography.html#abramson1970)。在此之前，计算机网络要么建立在电话网络之上，要么建立在物理电缆之上。ALOHA网络表明，可以使用无线电信号来互联计算机。
- en: The first version of ALOHANet, described in [[Abramson1970]](../bibliography.html#abramson1970),
    operated as follows. First, the terminals and the mainframe exchanged fixed-length
    frames composed of 704 bits. Each frame contained 80 8-bit characters, some control
    bits and parity information to detect transmission errors. Two channels in the
    400 MHz range were reserved for the operation of ALOHANet. The first channel was
    used by the mainframe to send frames to all terminals. The second channel was
    shared among all terminals to send frames to the mainframe. As all terminals share
    the same transmission channel, there is a risk of collision. To deal with this
    problem as well as transmission errors, the mainframe verified the parity bits
    of the received frame and sent an acknowledgment on its channel for each correctly
    received frame. The terminals on the other hand had to retransmit the unacknowledged
    frames. As for TCP, retransmitting these frames immediately upon expiration of
    a fixed timeout is not a good approach as several terminals may retransmit their
    frames at the same time leading to a network collapse. A better approach, but
    still far from perfect, is for each terminal to wait a random amount of time after
    the expiration of its retransmission timeout. This avoids synchronization among
    multiple retransmitting terminals.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ALOHANet的第一个版本，如[[Abramson1970]](../bibliography.html#abramson1970)所述，其工作方式如下。首先，终端和主机交换由704位组成的固定长度帧。每个帧包含80个8位字符，一些控制位和奇偶校验信息以检测传输错误。400
    MHz范围内的两个信道被保留用于ALOHANet的操作。第一个信道由主机用于向所有终端发送帧。第二个信道由所有终端共享，用于向主机发送帧。由于所有终端共享相同的传输信道，因此存在碰撞的风险。为了处理这个问题以及传输错误，主机验证接收到的帧的奇偶校验位，并为每个正确接收到的帧在其信道上发送确认。另一方面，终端必须重新传输未确认的帧。对于TCP来说，在固定超时到期后立即重新传输这些帧并不是一个好的方法，因为多个终端可能会同时重新传输它们的帧，从而导致网络崩溃。一个更好的方法，尽管还远非完美，是每个终端在它的重新传输超时到期后等待一个随机的时间。这避免了多个重新传输终端之间的同步。
- en: The pseudo-code below shows the operation of an ALOHANet terminal. We use this
    python syntax for all Medium Access Control algorithms described in this chapter.
    The algorithm is applied to each new frame that needs to be transmitted. It attempts
    to transmit a frame at most max times (while loop). Each transmission attempt
    is performed as follows. First, the frame is sent. Each frame is protected by
    a timeout. Then, the terminal waits for either a valid acknowledgment frame or
    the expiration of its timeout. If the terminal receives an acknowledgment, the
    frame has been delivered correctly and the algorithm terminates. Otherwise, the
    terminal waits for a random time and attempts to retransmit the frame.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的伪代码显示了ALOHANet终端的操作。我们使用这种Python语法来描述本章中描述的所有介质访问控制算法。该算法应用于需要传输的每个新帧。它尝试最多max次（while循环）传输一个帧。每次传输尝试如下进行。首先，发送帧。每个帧都有一个超时保护。然后，终端等待有效的确认帧或其超时的到期。如果终端收到确认，则帧已正确交付，算法终止。否则，终端等待随机时间并尝试重新传输帧。
- en: '[PRE1]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[[Abramson1970]](../bibliography.html#abramson1970) analyzed the performance
    of ALOHANet under particular assumptions and found that ALOHANet worked well when
    the channel was lightly loaded. In this case, the frames are rarely retransmitted
    and the channel traffic, i.e. the total number of (correct and retransmitted)
    frames transmitted per unit of time is close to the channel utilization, i.e.
    the number of correctly transmitted frames per unit of time. Unfortunately, the
    analysis also reveals that the channel utilization reaches its maximum at \(\frac{1}{2
    \times e}=0.186\) times the channel bandwidth. At higher utilization, ALOHANet
    becomes unstable and the network collapses due to collided retransmissions.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '[[Abramson1970]](../bibliography.html#abramson1970)在特定假设下分析了ALOHANet的性能，并发现当信道负载较轻时，ALOHANet工作得很好。在这种情况下，帧很少重新传输，信道流量，即单位时间内传输的（正确和重新传输的）帧的总数接近信道利用率，即单位时间内正确传输的帧的数量。不幸的是，分析还显示，信道利用率在达到其最大值时为信道带宽的\(\frac{1}{2
    \times e}=0.186\)倍。在更高的利用率下，ALOHANet变得不稳定，网络由于碰撞的重新传输而崩溃。'
- en: Note
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Amateur packet radio
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 业余分组无线电
- en: Packet radio technologies have evolved in various directions since the first
    experiments performed at the University of Hawaii. The Amateur packet radio service
    developed by amateur radio operators is one of the descendants ALOHANet. Many
    amateur radio operators are very interested in new technologies and they often
    spend countless hours developing new antennas or transceivers. When the first
    personal computers appeared, several amateur radio operators designed radio modems
    and their own datalink layer protocols [[KPD1985]](../bibliography.html#kpd1985)
    [[BNT1997]](../bibliography.html#bnt1997). This network grew and it was possible
    to connect to servers in several European countries by only using packet radio
    relays. Some amateur radio operators also developed TCP/IP protocol stacks that
    were used over the packet radio service. Some parts of the [amateur packet radio
    network](http://www.ampr.org/) are connected to the global Internet and use the
    44.0.0.0/8 IPv4 prefix.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 自从在夏威夷大学进行首次实验以来，包无线电技术已经向多个方向发展。由业余无线电操作员开发的业余包无线电服务是ALOHANet的后裔之一。许多业余无线电操作员对新技术非常感兴趣，他们经常花费无数小时开发新的天线或收发器。当第一台个人计算机出现时，几位业余无线电操作员设计了无线电调制解调器和他们自己的数据链路层协议[[KPD1985]](../bibliography.html#kpd1985)
    [[BNT1997]](../bibliography.html#bnt1997)。这个网络不断发展，仅使用包无线电中继就可以连接到几个欧洲国家的服务器。一些业余无线电操作员还开发了在包无线电服务上使用的TCP/IP协议栈。[业余包无线电网络](http://www.ampr.org/)的一些部分连接到全球互联网，并使用44.0.0.0/8
    IPv4前缀。
- en: Many improvements to ALOHANet have been proposed since the publication of [[Abramson1970]](../bibliography.html#abramson1970),
    and this technique, or some of its variants, are still found in wireless networks
    today. The slotted technique proposed in [[Roberts1975]](../bibliography.html#roberts1975)
    is important because it shows that a simple modification can significantly improve
    channel utilization. Instead of allowing all terminals to transmit at any time,
    [[Roberts1975]](../bibliography.html#roberts1975) proposed to divide time into
    slots and allow terminals to transmit only at the beginning of each slot. Each
    slot corresponds to the time required to transmit one fixed size frame. In practice,
    these slots can be imposed by a single clock that is received by all terminals.
    In ALOHANet, it could have been located on the central mainframe. The analysis
    in [[Roberts1975]](../bibliography.html#roberts1975) reveals that this simple
    modification improves the channel utilization by a factor of two.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 自从[[Abramson1970]](../bibliography.html#abramson1970)发表以来，针对ALOHANet的许多改进方案被提出，并且这种技术或其某些变体至今仍存在于无线网络中。[[Roberts1975]](../bibliography.html#roberts1975)提出的时隙技术非常重要，因为它表明简单的修改可以显著提高信道利用率。不是允许所有终端在任何时间传输，[[Roberts1975]](../bibliography.html#roberts1975)提出将时间划分为时隙，并允许终端只在每个时隙的开始传输。每个时隙对应于传输一个固定大小帧所需的时间。在实践中，这些时隙可以通过一个所有终端都能接收到的单一时钟来强制实施。在ALOHANet中，它可能位于中央主框上。[[Roberts1975]](../bibliography.html#roberts1975)的分析表明，这种简单的修改可以将信道利用率提高两倍。
- en: '### Carrier Sense Multiple Access[#](#carrier-sense-multiple-access "Link to
    this heading")'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '### 载波侦听多路访问[#](#carrier-sense-multiple-access "链接到这个标题")'
- en: ALOHA and slotted ALOHA can easily be implemented, but unfortunately, they can
    only be used in networks that are very lightly loaded. Designing a network for
    a very low utilization is possible, but it clearly increases the cost of the network.
    To overcome the problems of ALOHA, many Medium Access Control mechanisms have
    been proposed which improve channel utilization. Carrier Sense Multiple Access
    (CSMA) is a significant improvement compared to ALOHA. CSMA requires all nodes
    to listen to the transmission channel to verify that it is free before transmitting
    a frame [[KT1975]](../bibliography.html#kt1975). When a node senses the channel
    to be busy, it defers its transmission until the channel becomes free again. The
    pseudo-code below provides a more detailed description of the operation of CSMA.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: ALOHA和时隙ALOHA可以很容易地实现，但不幸的是，它们只能用于非常轻载的网络。为非常低利用率设计网络是可能的，但它显然会增加网络的成本。为了克服ALOHA的问题，已经提出了许多介质访问控制机制，这些机制提高了信道利用率。与ALOHA相比，载波侦听多路访问（CSMA）是一个显著的改进。CSMA要求所有节点在发送帧之前侦听传输信道以验证其是否空闲[[KT1975]](../bibliography.html#kt1975)。当一个节点侦测到信道繁忙时，它将推迟其传输，直到信道再次空闲。下面的伪代码提供了CSMA操作的更详细描述。
- en: '[PRE2]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The above pseudo-code is often called persistent CSMA [[KT1975]](../bibliography.html#kt1975)
    as the terminal will continuously listen to the channel and transmit its frame
    as soon as the channel becomes free. Another important variant of CSMA is the
    non-persistent CSMA [[KT1975]](../bibliography.html#kt1975). The main difference
    between persistent and non-persistent CSMA described in the pseudo-code below
    is that a non-persistent CSMA node does not continuously listen to the channel
    to determine when it becomes free. When a non-persistent CSMA terminal senses
    the transmission channel to be busy, it waits for a random time before sensing
    the channel again. This improves channel utilization compared to persistent CSMA.
    With persistent CSMA, when two terminals sense the channel to be busy, they will
    both transmit (and thus cause a collision) as soon as the channel becomes free.
    With non-persistent CSMA, this synchronization does not occur, as the terminals
    wait a random time after having sensed the transmission channel. However, the
    higher channel utilization achieved by non-persistent CSMA comes at the expense
    of a slightly higher waiting time in the terminals when the network is lightly
    loaded.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 上述伪代码通常被称为持续载波监听多路访问（CSMA）[[KT1975]](../bibliography.html#kt1975)，因为终端会持续监听信道，一旦信道空闲，就会立即发送其帧。CSMA的另一个重要变体是非持续CSMA
    [[KT1975]](../bibliography.html#kt1975)。以下伪代码中描述的持续和非持续CSMA之间的主要区别是，非持续CSMA节点不会持续监听信道以确定何时空闲。当一个非持续CSMA终端检测到传输信道忙碌时，它会在再次检测信道之前等待一个随机时间。这比持续CSMA提高了信道利用率。在持续CSMA中，当两个终端检测到信道忙碌时，它们会在信道空闲的瞬间同时发送（从而引起冲突）。而在非持续CSMA中，这种同步不会发生，因为终端在检测到传输信道后等待一个随机时间。然而，非持续CSMA通过提高信道利用率所实现的，是以网络轻载时终端稍微增加的等待时间为代价的。
- en: '[PRE3]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[[KT1975]](../bibliography.html#kt1975) analyzes in detail the performance
    of several CSMA variants. Under some assumptions about the transmission channel
    and the traffic, the analysis compares ALOHA, slotted ALOHA, persistent and non-persistent
    CSMA. Under these assumptions, ALOHA achieves a channel utilization of only 18.4%
    of the channel capacity. Slotted ALOHA is able to use 36.6% of this capacity.
    Persistent CSMA improves the utilization by reaching 52.9% of the capacity while
    non-persistent CSMA achieves 81.5% of the channel capacity.  ### Carrier Sense
    Multiple Access with Collision Detection[#](#carrier-sense-multiple-access-with-collision-detection
    "Link to this heading")'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '[[KT1975]](../bibliography.html#kt1975) 详细分析了几个CSMA变体的性能。在关于传输信道和流量的某些假设下，该分析比较了ALOHA、时隙ALOHA、持续和非持续CSMA。在这些假设下，ALOHA的信道利用率仅为信道容量的18.4%。时隙ALOHA能够使用36.6%的容量。持续CSMA通过达到52.9%的容量来提高利用率，而非持续CSMA实现了信道容量的81.5%。  ###
    带冲突检测的载波监听多路访问[#](#carrier-sense-multiple-access-with-collision-detection "链接到本标题")'
- en: CSMA improves channel utilization compared to ALOHA. However, the performance
    can still be improved, especially in wired networks. Consider the situation of
    two terminals that are connected to the same cable. This cable could, for example,
    be a coaxial cable as in the early days of Ethernet [[Metcalfe1976]](../bibliography.html#metcalfe1976).
    It could also be built with twisted pairs. Before extending CSMA, it is useful
    to understand, more intuitively, how frames are transmitted in such a network
    and how collisions can occur. The figure below illustrates the physical transmission
    of a frame on such a cable. To transmit its frame, host A must send an electrical
    signal on the shared medium. The first step is thus to begin the transmission
    of the electrical signal. This is point (1) in the figure below. This electrical
    signal will travel along the cable. Although electrical signals travel fast, we
    know that information cannot travel faster than the speed of light (i.e. 300.000
    kilometers/second). On a coaxial cable, an electrical signal is slightly slower
    than the speed of light and 200.000 kilometers per second is a reasonable estimation.
    This implies that if the cable has a length of one kilometer, the electrical signal
    will need 5 microseconds to travel from one end of the cable to the other. The
    ends of coaxial cables are equipped with termination points that ensure that the
    electrical signal is not reflected back to its source. This is illustrated at
    point (3) in the figure, where the electrical signal has reached the left endpoint
    and host B. At this point, B starts to receive the frame being transmitted by
    A. Notice that there is a delay between the transmission of a bit on host A and
    its reception by host B. If there were other hosts attached to the cable, they
    would receive the first bit of the frame at slightly different times. As we will
    see later, this timing difference is a key problem for MAC algorithms. At point
    (4), the electrical signal has reached both ends of the cable and occupies it
    completely. Host A continues to transmit the electrical signal until the end of
    the frame. As shown at point (5), when the sending host stops its transmission,
    the electrical signal corresponding to the end of the frame leaves the coaxial
    cable. The channel becomes empty again once the entire electrical signal has been
    removed from the cable.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 与ALOHA相比，CSMA提高了信道利用率。然而，性能仍然可以进一步提高，尤其是在有线网络中。考虑两个终端连接到同一电缆的情况。例如，这条电缆可以是早期以太网中的同轴电缆
    [[Metcalfe1976]](../bibliography.html#metcalfe1976)。它也可以由双绞线构建。在扩展CSMA之前，了解这样一个网络中帧的传输方式和碰撞如何发生是有用的。下面的图示说明了这样一个电缆上帧的物理传输。为了传输其帧，主机A必须在共享介质上发送一个电信号。因此，第一步是开始传输电信号。这在下面的图中表示为点（1）。这个电信号将沿着电缆传播。尽管电信号传播得很快，但我们知道信息不能比光速传播得更快（即每秒300,000公里）。在同轴电缆上，电信号略慢于光速，每秒200,000公里是一个合理的估计。这意味着如果电缆长度为一公里，电信号需要5微秒才能从电缆的一端传播到另一端。同轴电缆的末端装有终止点，以确保电信号不会反射回其源头。这在图中的点（3）中得到了说明，其中电信号已经到达左端点和主机B。在这个时候，B开始接收A正在传输的帧。请注意，在主机A上传输一个比特和主机B接收它之间存在延迟。如果有其他主机连接到电缆上，它们会在不同时间接收到帧的第一个比特。正如我们稍后将会看到的，这种时间差异是MAC算法的一个关键问题。在点（4）时，电信号已经到达电缆的两端并完全占据它。主机A继续传输电信号，直到帧的结束。如图（5）所示，当发送主机停止传输时，对应于帧结束的电信号离开同轴电缆。一旦整个电信号从电缆中移除，信道再次变为空闲。
- en: '[![../_images/frame-bus.png](../Images/ab89b8b4019e54d32dc8e8a85f104ba1.png)](../_images/frame-bus.png)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/frame-bus.png](../Images/ab89b8b4019e54d32dc8e8a85f104ba1.png)(../_images/frame-bus.png)'
- en: Fig. 197 Frame transmission on a shared bus[#](#id85 "Link to this image")
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图197 共享总线上的帧传输[#](#id85 "链接到这张图片")
- en: Now that we have looked at how a frame is actually transmitted as an electrical
    signal on a shared bus, it is interesting to look in more detail at what happens
    when two hosts transmit a frame at almost the same time. This is illustrated in
    the figure below, where hosts A and B start their transmission at the same time
    (point (1)). At this time, if host C senses the channel, it will consider it to
    be free. This will not last a long time and at point (2) the electrical signals
    from both host A and host B reach host C. The combined electrical signal (shown
    graphically as the superposition of the two curves in the figure) cannot be decoded
    by host C. Host C detects a collision, as it receives a signal that it cannot
    decode. Since host C cannot decode the frames, it cannot determine which hosts
    are sending the colliding frames. Note that host A (and host B) will detect the
    collision after host C (point (3) in figure [Fig. 198](#fig-collision-bus)).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了帧实际上是如何作为一个电信号在共享总线上传输的，那么更详细地看看当两个主机几乎同时发送一个帧时会发生什么，这很有趣。这在上面的图中得到了说明，其中主机A和主机B同时开始传输（点（1））。此时，如果主机C检测到信道，它会认为它是空闲的。但这不会持续太久，在点（2）处，主机A和主机B的电信号都到达了主机C。组合电信号（在图中以两个曲线的叠加形式图形化表示）无法被主机C解码。主机C检测到冲突，因为它接收到了一个无法解码的信号。由于主机C无法解码帧，它无法确定哪些主机正在发送冲突帧。请注意，主机A（以及主机B）将在主机C之后检测到冲突（图[图198](#fig-collision-bus)中的点（3））。
- en: '[![../_images/frame-collision.png](../Images/7b88fb2c9cc28c5857f616b145a56cb6.png)](../_images/frame-collision.png)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '![![../_images/frame-collision.png](../Images/7b88fb2c9cc28c5857f616b145a56cb6.png)](../_images/frame-collision.png)'
- en: Fig. 198 Frame collision on a shared bus[#](#fig-collision-bus "Link to this
    image")
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图198 共享总线上的帧冲突[#](#fig-collision-bus "链接到这张图片")
- en: As shown above, hosts detect collisions when they receive an electrical signal
    that they cannot decode. In a wired network, a host is able to detect such a collision
    both while it is listening (e.g. like host C in the figure above) and also while
    it is sending its own frame. When a host transmits a frame, it can compare the
    electrical signal that it transmits with the electrical signal that it senses
    on the wire. At points (1) and (2) in the figure above, host A senses only its
    own signal. At point (3), it senses an electrical signal that differs from its
    own signal and can thus detects the collision. At this point, its frame is corrupted
    and it can stop its transmission. The ability to detect collisions while transmitting
    is the starting point for the Carrier Sense Multiple Access with Collision Detection
    (CSMA/CD) Medium Access Control algorithm, which is used in Ethernet networks
    [[Metcalfe1976]](../bibliography.html#metcalfe1976) [[IEEE802.3]](../bibliography.html#ieee802-3)
    . When an Ethernet host detects a collision while it is transmitting, it immediately
    stops its transmission. Compared with pure CSMA, CSMA/CD is an important improvement
    since when collisions occur, they only last until colliding hosts have detected
    it and stopped their transmission. In practice, when a host detects a collision,
    it sends a special jamming signal on the cable to ensure that all hosts have detected
    the collision.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 如上图所示，当主机接收到无法解码的电信号时，会检测到冲突。在有线的网络中，主机在监听时（例如上图中的主机C）以及发送自己的帧时，都能够检测到这种冲突。当主机发送一个帧时，它可以比较自己发送的电信号与在电缆上感知到的电信号。在上图中的点（1）和（2）处，主机A只能感知到自己的信号。在点（3）处，它感知到一个与自己的信号不同的电信号，因此可以检测到冲突。在此点，它的帧被损坏，它可以停止传输。在传输过程中检测到冲突的能力是载波侦听多路访问与冲突检测（CSMA/CD）介质访问控制算法的起点，该算法用于以太网网络
    [[Metcalfe1976]](../bibliography.html#metcalfe1976) [[IEEE802.3]](../bibliography.html#ieee802-3)
    。当以太网主机在传输过程中检测到冲突时，它会立即停止传输。与纯CSMA相比，CSMA/CD是一个重要的改进，因为当发生冲突时，它们只会持续到发生冲突的主机检测到并停止传输。在实践中，当主机检测到冲突时，它会在电缆上发送一个特殊的干扰信号，以确保所有主机都检测到冲突。
- en: To better understand these collisions, it is useful to analyze what would be
    the worst collision on a shared bus network. Let us consider a wire with two hosts
    attached at both ends, as shown in the figure below. Host A starts to transmit
    its frame and its electrical signal is propagated on the cable. Its propagation
    time depends on the physical length of the cable and the speed of the electrical
    signal. Let us use \(\tau\) to represent this propagation delay in seconds. Slightly
    less than \(\tau\) seconds after the beginning of the transmission of A’s frame,
    B decides to start transmitting its own frame. After \(\epsilon\) seconds, B senses
    A’s frame, detects the collision and stops transmitting. The beginning of B’s
    frame travels on the cable until it reaches host A. Host A can thus detect the
    collision at time \(\tau-\epsilon+\tau \approx 2\times\tau\). An important point
    to note is that a collision can only occur during the first \(2\times\tau\) seconds
    of its transmission. If a collision did not occur during this period, it cannot
    occur afterwards since the transmission channel is busy after \(\tau\) seconds
    and CSMA/CD hosts sense the transmission channel before transmitting their frame.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解这些碰撞，分析在共享总线网络中最糟糕的碰撞情况是有用的。让我们考虑一个两端连接有两个主机的电线，如图所示。主机A开始传输其帧，其电信号在电缆上传播。其传播时间取决于电缆的物理长度和电信号的速度。让我们用
    \(\tau\) 来表示这种传播延迟（以秒为单位）。在A的帧传输开始后略少于 \(\tau\) 秒，B决定开始传输自己的帧。经过 \(\epsilon\)
    秒后，B检测到A的帧，检测到碰撞并停止传输。B的帧的开始在电缆上传播，直到它到达主机A。因此，主机A可以在 \(\tau-\epsilon+\tau \approx
    2\times\tau\) 时刻检测到碰撞。需要注意的是，碰撞只能在传输的前 \(2\times\tau\) 秒内发生。如果在这一时期内没有发生碰撞，那么之后也不会发生，因为传输通道在
    \(\tau\) 秒后变得繁忙，并且 CSMA/CD 主机在传输帧之前会检测传输通道。
- en: '[![../_images/frame-collision-worst.png](../Images/cb963f4bef31245667608aad2e590553.png)](../_images/frame-collision-worst.png)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/frame-collision-worst.png](../Images/cb963f4bef31245667608aad2e590553.png)'
- en: Fig. 199 The worst collision on a shared bus[#](#id86 "Link to this image")
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 图199 共享总线上的最糟糕的碰撞[#](#id86 "链接到这张图片")
- en: Furthermore, on the wired networks where CSMA/CD is used, collisions are almost
    the only cause of transmission errors that affect frames. Transmission errors
    that only affect a few bits inside a frame seldom occur in these wired networks.
    For this reason, the designers of CSMA/CD chose to completely remove the acknowledgment
    frames in the datalink layer. When a host transmits a frame, it verifies whether
    its transmission has been affected by a collision. If not, given the negligible
    Bit Error Ratio of the underlying network, it assumes that the frame was received
    correctly by its destination. Otherwise the frame is retransmitted after some
    delay.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在采用 CSMA/CD 的有线网络中，碰撞几乎是影响帧的传输错误的唯一原因。仅影响帧内少数比特的传输错误在这些有线网络中很少发生。因此，CSMA/CD的设计者选择在数据链路层完全删除确认帧。当主机传输一个帧时，它会验证其传输是否受到碰撞的影响。如果没有，考虑到底层网络的几乎可以忽略的比特错误率，它假设帧已被正确接收。否则，帧将在一段时间后重新传输。
- en: Removing acknowledgments is an interesting optimization as it reduces the number
    of frames that are exchanged on the network and the number of frames that need
    to be processed by the hosts. However, to use this optimization, we must ensure
    that all hosts will be able to detect all the collisions that affect their frames.
    The problem is important for short frames. Let us consider two hosts, A and B,
    that are sending a small frame to host C as illustrated in the figure below. If
    the frames sent by A and B are very short, the situation illustrated below may
    occur. Hosts A and B send their frame and stop transmitting (point (1)). When
    the two short frames arrive at the location of host C, they collide and host C
    cannot decode them (point (2)). The two frames are absorbed by the ends of the
    wire. Neither host A nor host B have detected the collision. They both consider
    their frame to have been received correctly by its destination.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 移除确认是一种有趣的优化，因为它减少了网络交换的帧数以及主机需要处理的帧数。然而，为了使用这种优化，我们必须确保所有主机都能检测到影响其帧的所有冲突。对于短帧来说，这是一个重要的问题。让我们考虑两个主机，A
    和 B，它们正在向主机 C 发送一个小帧，如图所示。如果 A 和 B 发送的帧非常短，可能会出现以下情况。主机 A 和 B 发送它们的帧并停止传输（点（1））。当两个短帧到达主机
    C 的位置时，它们发生冲突，主机 C 无法解码它们（点（2））。两个帧被线缆的末端吸收。主机 A 和主机 B 都没有检测到冲突。它们都认为它们的帧已经正确地被目的地接收。
- en: '[![../_images/frame-collision-short.png](../Images/9a5d6d727ec45fd15b48e2c3fdc820d7.png)](../_images/frame-collision-short.png)'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/frame-collision-short.png](../Images/9a5d6d727ec45fd15b48e2c3fdc820d7.png)(../_images/frame-collision-short.png)'
- en: Fig. 200 The short-frame collision problem[#](#id87 "Link to this image")
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图 200 短帧冲突问题[#](#id87 "链接到这张图片")
- en: To solve this problem, networks using CSMA/CD require hosts to transmit for
    at least \(2\times\tau\) seconds. Since the network transmission speed is fixed
    for a given network technology, this implies that a technology that uses CSMA/CD
    enforces a minimum frame size. In the most popular CSMA/CD technology, Ethernet,
    \(2\times\tau\) is called the slot time [[4]](#fslottime).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，使用 CSMA/CD 的网络要求主机至少传输 \(2\times\tau\) 秒。由于网络传输速度对于给定的网络技术是固定的，这意味着使用
    CSMA/CD 的技术强制执行最小帧大小。在最受欢迎的 CSMA/CD 技术，以太网中，\(2\times\tau\) 被称为时隙时间 [[4]](#fslottime)。
- en: The last innovation introduced by CSMA/CD is the computation of the retransmission
    timeout. As for ALOHA, this timeout cannot be fixed, otherwise hosts could become
    synchronized and always retransmit at the same time. Setting such a timeout is
    always a compromise between the network access delay and the amount of collisions.
    A short timeout would lead to a low network access delay but with a higher risk
    of collisions. On the other hand, a long timeout would cause a long network access
    delay but a lower risk of collisions. The binary exponential back-off algorithm
    was introduced in CSMA/CD networks to solve this problem.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: CSMA/CD 引入的最后一个创新是重传超时的计算。与 ALOHA 一样，这个超时不能是固定的，否则主机可能会同步并总是在同一时间重传。设置这样的超时总是在网络访问延迟和冲突数量之间做出妥协。超时短会导致网络访问延迟低，但碰撞风险高。另一方面，超时长会导致网络访问延迟长，但碰撞风险低。二进制指数退避算法被引入
    CSMA/CD 网络以解决这个问题。
- en: 'To understand binary exponential back-off, let us consider a collision caused
    by exactly two hosts. Once it has detected the collision, a host can either retransmit
    its frame immediately or defer its transmission for some time. If each colliding
    host flips a coin to decide whether to retransmit immediately or to defer its
    retransmission, four cases are possible :'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解二进制指数退避，让我们考虑由恰好两个主机引起的冲突。一旦检测到冲突，主机可以立即重传其帧或延迟一段时间后重传。如果每个冲突的主机抛硬币来决定是否立即重传或延迟重传，可能出现四种情况：
- en: Both hosts retransmit immediately and a new collision occurs
  id: totrans-144
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 两个主机立即重传，并发生新的冲突
- en: ''
  id: totrans-145
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-146
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: The first host retransmits immediately and the second defers its retransmission
  id: totrans-147
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一个主机立即重传，第二个主机延迟重传
- en: ''
  id: totrans-148
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-149
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: The second host retransmits immediately and the first defers its retransmission
  id: totrans-150
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二个主机立即重传，第一个主机延迟重传
- en: ''
  id: totrans-151
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-152
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Both hosts defer their retransmission and a new collision occurs
  id: totrans-153
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 两个主机都延迟重传，并发生新的冲突
- en: In the second and third cases, both hosts have flipped different coins. The
    delay chosen by the host that defers its retransmission should be long enough
    to ensure that its retransmission will not collide with the immediate retransmission
    of the other host. However the delay should not be longer than the time necessary
    to avoid the collision, because if both hosts decide to defer their transmission,
    the network will be idle during this delay. The slot time is the optimal delay
    since it is the shortest delay that ensures that the first host will be able to
    retransmit its frame completely without any collision.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二种和第三种情况下，两个主机都掷了不同的硬币。延迟选择推迟其重传的主机应该足够长，以确保其重传不会与另一个主机的即时重传冲突。然而，延迟不应超过避免冲突所需的时间，因为如果两个主机都决定推迟它们的传输，网络将在这段时间内空闲。时隙时间是最佳延迟，因为它是最短的延迟，可以确保第一个主机能够完全重传其帧而不会发生任何冲突。
- en: If two hosts are competing, the algorithm above will avoid a second collision
    50% of the time. However, if the network is heavily loaded, several hosts may
    be competing at the same time. In this case, the hosts should be able to automatically
    adapt their retransmission delay. The binary exponential back-off performs this
    adaptation based on the number of collisions that have affected a frame. After
    the first collision, the host flips a coin and waits 0 or 1 slot time. After the
    second collision, it generates a random number and waits 0, 1, 2 or 3 slot times,
    etc. The duration of the waiting time is doubled after each collision. The complete
    pseudo-code for the CSMA/CD algorithm is shown in the figure below.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 如果两个主机正在竞争，上述算法将避免50%的第二次冲突。然而，如果网络负载很重，可能同时有几个主机在竞争。在这种情况下，主机应该能够自动调整其重传延迟。二进制指数退避根据影响帧的冲突次数进行这种调整。第一次冲突后，主机掷硬币并等待0或1个时隙时间。第二次冲突后，它生成一个随机数并等待0、1、2或3个时隙时间，等等。每次冲突后，等待时间翻倍。CSMA/CD算法的完整伪代码如图所示。
- en: '[PRE4]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The inter-frame delay used in this pseudo-code is a short delay corresponding
    to the time required by a network adapter to switch from transmit to receive mode.
    It is also used to prevent a host from sending a continuous stream of frames without
    leaving any transmission opportunities for other hosts on the network. This contributes
    to the fairness of CSMA/CD. Despite this delay, there are still conditions where
    CSMA/CD is not completely fair [[RY1994]](../bibliography.html#ry1994). Consider
    for example a network with two hosts : a server sending long frames and a client
    sending acknowledgments. Measurements reported in [[RY1994]](../bibliography.html#ry1994)
    have shown that there are situations where the client could suffer from repeated
    collisions that lead it to wait for long periods of time due to the exponential
    back-off algorithm.  ### Carrier Sense Multiple Access with Collision Avoidance[#](#carrier-sense-multiple-access-with-collision-avoidance
    "Link to this heading")'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在此伪代码中使用的帧间延迟是一个短暂的延迟，对应于网络适配器从发送模式切换到接收模式所需的时间。它还用于防止主机发送连续的帧流，而不给网络上的其他主机留下任何传输机会。这有助于CSMA/CD的公平性。尽管有这个延迟，仍然存在CSMA/CD不完全公平的情况[[RY1994]](../bibliography.html#ry1994)。例如，考虑一个有两个主机的网络：一个服务器发送长帧，一个客户端发送确认。[[RY1994]](../bibliography.html#ry1994)中报告的测量结果表明，客户端可能会遭受重复的冲突，这导致它因指数退避算法而长时间等待。###
    带有冲突避免的载波侦听多路访问[#](#carrier-sense-multiple-access-with-collision-avoidance "链接到这个标题")
- en: The Carrier Sense Multiple Access with Collision Avoidance (CSMA/CA) Medium
    Access Control algorithm was designed for the popular WiFi wireless network technology
    [[IEEE802.11]](../bibliography.html#ieee802-11). CSMA/CA also senses the transmission
    channel before transmitting a frame. Furthermore, CSMA/CA tries to avoid collisions
    by carefully tuning the timers used by CSMA/CA devices.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 带有冲突避免的载波侦听多路访问（CSMA/CA）介质访问控制算法是为流行的WiFi无线网络技术[[IEEE802.11]](../bibliography.html#ieee802-11)设计的。CSMA/CA在发送帧之前也会侦听传输通道。此外，CSMA/CA通过仔细调整CSMA/CA设备使用的计时器来尝试避免冲突。
- en: CSMA/CA uses acknowledgments like CSMA. Each frame contains a sequence number
    and a CRC. The CRC is used to detect transmission errors while the sequence number
    is used to avoid frame duplication. When a device receives a correct frame, it
    returns a special acknowledgment frame to the sender. CSMA/CA introduces a small
    delay, named Short Inter Frame Spacing (SIFS), between the reception of a frame
    and the transmission of the acknowledgment frame. This delay corresponds to the
    time that is required to switch the radio of a device between the reception and
    transmission modes.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: CSMA/CA 使用类似于 CSMA 的确认机制。每个帧包含一个序列号和一个 CRC。CRC 用于检测传输错误，而序列号用于避免帧重复。当一个设备接收到正确的帧时，它会向发送者返回一个特殊的确认帧。CSMA/CA
    在接收帧和发送确认帧之间引入了一个小的延迟，称为短帧间间隔（SIFS）。这个延迟对应于设备在接收和传输模式之间切换无线电所需的时间。
- en: 'Compared to CSMA, CSMA/CA defines more precisely when a device is allowed to
    send a frame. First, CSMA/CA defines two delays : DIFS and EIFS. To send a frame,
    a device must first wait until the channel has been idle for at least the Distributed
    Coordination Function Inter Frame Space (DIFS) if the previous frame was received
    correctly. However, if the previously received frame was corrupted, this indicates
    that there are collisions and the device must sense the channel idle for at least
    the Extended Inter Frame Space (EIFS), with \(SIFS<DIFS<EIFS\). The exact values
    for SIFS, DIFS and EIFS depend on the underlying physical layer [[IEEE802.11]](../bibliography.html#ieee802-11).'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 与 CSMA 相比，CSMA/CA 更精确地定义了设备何时可以发送帧。首先，CSMA/CA 定义了两个延迟：DIFS 和 EIFS。为了发送帧，设备必须首先等待信道空闲至少
    Distributed Coordination Function Inter Frame Space (DIFS) 的时间，如果之前接收到的帧是正确的。然而，如果之前接收到的帧已损坏，这表明存在冲突，设备必须检测信道空闲至少
    Extended Inter Frame Space (EIFS) 的时间，其中 \(SIFS<DIFS<EIFS\)。SIFS、DIFS 和 EIFS 的确切值取决于底层物理层
    [[IEEE802.11]](../bibliography.html#ieee802-11)。
- en: The figure below shows the basic operation of CSMA/CA devices. Before transmitting,
    host A verifies that the channel is empty for a long enough period. Then, its
    sends its data frame. After checking the validity of the received frame, the recipient
    sends an acknowledgment frame after a short SIFS delay. Host C, which does not
    participate in the frame exchange, senses the channel to be busy at the beginning
    of the data frame. Host C can use this information to determine how long the channel
    will be busy for. Note that as \(SIFS<DIFS<EIFS\), even a device that would start
    to sense the channel immediately after the last bit of the data frame could not
    decide to transmit its own frame during the transmission of the acknowledgment
    frame.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了 CSMA/CA 设备的基本操作。在传输之前，主机 A 验证信道是否在足够长的时间内空闲。然后，它发送其数据帧。在检查接收到的帧的有效性后，接收者在短暂的
    SIFS 延迟后发送一个确认帧。不参与帧交换的主机 C 在数据帧的开始时检测到信道忙。主机 C 可以使用此信息来确定信道将忙多久。请注意，由于 \(SIFS<DIFS<EIFS\)，即使在数据帧的最后一位之后立即开始检测信道的设备也无法在确认帧传输期间决定发送自己的帧。
- en: '[![../_images/csmaca-1.png](../Images/a384b3211b0772e04aaf1c46baf44b77.png)](../_images/csmaca-1.png)'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/csmaca-1.png](../Images/a384b3211b0772e04aaf1c46baf44b77.png)'
- en: Fig. 201 Operation of a CSMA/CA device[#](#id88 "Link to this image")
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图 201 CSMA/CA 设备的操作[#](#id88 "链接到这张图片")
- en: The main difficulty with CSMA/CA is when two or more devices transmit at the
    same time and cause collisions. This is illustrated in the figure below, assuming
    a fixed timeout after the transmission of a data frame. With CSMA/CA, the timeout
    after the transmission of a data frame is very small, since it corresponds to
    the SIFS plus the time required to transmit the acknowledgment frame.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: CSMA/CA 的主要困难在于两个或更多设备同时传输并引起冲突的情况。这在下图中得到说明，假设在数据帧传输后有一个固定的超时时间。由于 CSMA/CA，数据帧传输后的超时时间非常小，因为它对应于
    SIFS 加上发送确认帧所需的时间。
- en: '[![../_images/csmaca-2.png](../Images/0dbf88b43018a324dcb149e4a1fe2cae.png)](../_images/csmaca-2.png)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/csmaca-2.png](../Images/0dbf88b43018a324dcb149e4a1fe2cae.png)'
- en: Fig. 202 Collisions with CSMA/CA[#](#id89 "Link to this image")
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图 202 CSMA/CA 中的冲突[#](#id89 "链接到这张图片")
- en: To deal with this problem, CSMA/CA relies on a backoff timer. This backoff timer
    is a random delay that is chosen by each device in a range that depends on the
    number of retransmissions for the current frame. The range grows exponentially
    with the retransmissions as in CSMA/CD. The minimum range for the backoff timer
    is \([0,7*slotTime]\) where the slotTime is a parameter that depends on the underlying
    physical layer. Compared to CSMA/CD’s exponential backoff, there are two important
    differences to notice. First, the initial range for the backoff timer is seven
    times larger. This is because it is impossible in CSMA/CA to detect collisions
    as they happen. With CSMA/CA, a collision may affect the entire frame while with
    CSMA/CD it can only affect the beginning of the frame. Second, a CSMA/CA device
    must regularly sense the transmission channel during its back off timer. If the
    channel becomes busy (i.e. because another device is transmitting), then the back
    off timer must be frozen until the channel becomes free again. Once the channel
    becomes free, the back off timer is restarted. This is in contrast with CSMA/CD
    where the back off is recomputed after each collision. This is illustrated in
    the figure below. Host A chooses a smaller backoff than host C. When C senses
    the channel to be busy, it freezes its backoff timer and only restarts it once
    the channel is free again.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，CSMA/CA依赖于一个退避定时器。这个退避定时器是一个随机延迟，由每个设备在一个依赖于当前帧重传次数的范围中选择。范围随着重传次数呈指数增长，就像CSMA/CD一样。退避定时器的最小范围是\([0,7*slotTime]\)，其中slotTime是一个取决于底层物理层的参数。与CSMA/CD的指数退避相比，有两个重要的不同之处需要注意。首先，退避定时器的初始范围是七倍大。这是因为CSMA/CA无法检测到发生的碰撞。与CSMA/CA相比，一个碰撞可能影响整个帧，而与CSMA/CD相比，它只能影响帧的开始部分。其次，一个CSMA/CA设备必须在退避定时器期间定期检测传输通道。如果通道变得繁忙（即因为另一个设备正在传输），那么退避定时器必须冻结，直到通道再次空闲。一旦通道空闲，退避定时器重新启动。这与CSMA/CD不同，在CSMA/CD中，每次碰撞后都会重新计算退避。这在下图中得到了说明。主机A选择的退避时间比主机C小。当C检测到通道繁忙时，它会冻结其退避定时器，并且只有在通道再次空闲时才会重新启动。
- en: '[![../_images/csmaca-3.png](../Images/9634d388481fa8d42a5b4b7de8b205c0.png)](../_images/csmaca-3.png)'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/csmaca-3.png](../Images/9634d388481fa8d42a5b4b7de8b205c0.png)'
- en: Fig. 203 Detailed example with CSMA/CA[#](#id90 "Link to this image")
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 图203：带有CSMA/CA的详细示例[#](#id90 "链接到这张图片")
- en: The pseudo-code below summarizes the operation of a CSMA/CA device. The values
    of the SIFS, DIFS, EIFS and \(slotTime\) depend on the underlying physical layer
    technology [[IEEE802.11]](../bibliography.html#ieee802-11)
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的伪代码总结了CSMA/CA设备的工作原理。SIFS、DIFS、EIFS和\(slotTime\)的值取决于底层物理层技术[[IEEE802.11]](../bibliography.html#ieee802-11)
- en: '[PRE5]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Another problem faced by wireless networks is often called the hidden station
    problem. In a wireless network, radio signals are not always propagated same way
    in all directions. For example, two devices separated by a wall may not be able
    to receive each other’s signal while they could both be receiving the signal produced
    by a third host. This is illustrated in the figure below, but it can happen in
    other environments. For example, two devices that are on different sides of a
    hill may not be able to receive each other’s signal while they are both able to
    receive the signal sent by a station at the top of the hill. Furthermore, the
    radio propagation conditions may change with time. For example, a truck may temporarily
    block the communication between two nearby devices.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 无线网络面临的一个常见问题通常被称为隐藏站问题。在无线网络中，无线电信号并不总是以相同的方式向所有方向传播。例如，被墙壁隔开的两个设备可能无法接收到对方的信号，尽管它们都能接收到由第三个主机产生的信号。这在下图中得到了说明，但这种情况也可能发生在其他环境中。例如，位于山的不同侧的两个设备可能无法接收到对方的信号，尽管它们都能接收到山顶上站点发送的信号。此外，无线电传播条件可能会随时间变化。例如，一辆卡车可能会暂时阻断两个附近设备之间的通信。
- en: '[![../_images/csmaca-hidden.png](../Images/1dd2db4f7a4f3df51403915d42254672.png)](../_images/csmaca-hidden.png)'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/csmaca-hidden.png](../Images/1dd2db4f7a4f3df51403915d42254672.png)'
- en: Fig. 204 The hidden station problem[#](#id91 "Link to this image")
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图204：隐藏站问题[#](#id91 "链接到这张图片")
- en: 'To avoid collisions in these situations, CSMA/CA allows devices to reserve
    the transmission channel for some time. This is done by using two control frames
    : Request To Send (RTS) and Clear To Send (CTS). Both are very short frames to
    minimize the risk of collisions. To reserve the transmission channel, a device
    sends a RTS frame to the intended recipient of the data frame. The RTS frame contains
    the duration of the requested reservation. The recipient replies, after a SIFS
    delay, with a CTS frame which also contains the duration of the reservation. As
    the duration of the reservation has been sent in both RTS and CTS, all hosts that
    could collide with either the sender or the reception of the data frame are informed
    of the reservation. They can compute the total duration of the transmission and
    defer their access to the transmission channel until then. This is illustrated
    in the figure below where host A reserves the transmission channel to send a data
    frame to host B. Host C notices the reservation and defers its transmission.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免在这些情况下发生冲突，CSMA/CA允许设备预留传输信道一段时间。这是通过使用两个控制帧来完成的：请求发送（RTS）和清除发送（CTS）。这两个帧都非常短，以最大限度地减少冲突的风险。为了预留传输信道，设备向数据帧的预期接收者发送一个RTS帧。RTS帧包含请求预留的持续时间。接收者在SIFS延迟后回复一个CTS帧，该帧也包含预留的持续时间。由于预留的持续时间已经在RTS和CTS中发送，所有可能与其他发送者或接收数据帧发生冲突的主机都会被告知预留情况。它们可以计算传输的总持续时间，并在那时推迟对传输信道的访问。这在下图中得到了说明，其中主机A预留传输信道以向主机B发送数据帧。主机C注意到预留并推迟了其传输。
- en: '[![../_images/csmaca-reserv.png](../Images/d32c0a1c69694ffdbad7f26e535e2135.png)](../_images/csmaca-reserv.png)'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/csmaca-reserv.png](../Images/d32c0a1c69694ffdbad7f26e535e2135.png)(../_images/csmaca-reserv.png)'
- en: Fig. 205 Reservations with CSMA/CA[#](#id92 "Link to this image")
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 图205 CSMA/CA中的预留[#](#id92 "链接到此图像")
- en: The utilization of the reservations with CSMA/CA is an optimization that is
    useful when collisions are frequent. If there are few collisions, the time required
    to transmit the RTS and CTS frames can become significant and in particular when
    short frames are exchanged. Some devices only turn on RTS/CTS after transmission
    errors.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在冲突频繁的情况下，使用带有CSMA/CA的预留是一种有用的优化。如果冲突很少，传输RTS和CTS帧所需的时间可能会变得显著，尤其是在交换短帧时。一些设备仅在传输错误后开启RTS/CTS。
- en: Deterministic Medium Access Control algorithms[#](#deterministic-medium-access-control-algorithms
    "Link to this heading")
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 确定性介质访问控制算法[#](#deterministic-medium-access-control-algorithms "链接到本标题")
- en: During the 1970s and 1980s, there were huge debates in the networking community
    about the best suited Medium Access Control algorithms for Local Area Networks.
    The optimistic algorithms that we have described until now were relatively easy
    to implement when they were designed. From a performance perspective, mathematical
    models and simulations showed the ability of these optimistic techniques to sustain
    load. However, none of the optimistic techniques are able to guarantee that a
    frame will be delivered within a given delay bound and some applications require
    predictable transmission delays. The deterministic MAC algorithms were considered
    by a fraction of the networking community as the best solution to fulfill the
    needs of Local Area Networks.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在20世纪70年代和80年代，网络社区就最适合局域网的介质访问控制算法进行了激烈的辩论。我们之前描述的乐观算法在它们设计时相对容易实现。从性能角度来看，数学模型和模拟显示了这些乐观技术维持负载的能力。然而，没有任何乐观技术能够保证在给定的延迟界限内交付帧，而某些应用程序需要可预测的传输延迟。确定性MAC算法被网络社区的一部分人视为满足局域网需求的最佳解决方案。
- en: Both the proponents of the deterministic and the opportunistic techniques lobbied
    to develop standards for Local Area networks that would incorporate their solution.
    Instead of trying to find an impossible compromise between these diverging views,
    the IEEE 802 committee that was chartered to develop Local Area Network standards
    chose to work in parallel on three different LAN technologies and created three
    working groups. The [IEEE 802.3 working group](http://www.ieee802.org/3/) became
    responsible for CSMA/CD. The proponents of deterministic MAC algorithms agreed
    on the basic principle of exchanging special frames called tokens between devices
    to regulate the access to the transmission medium. However, they did not agree
    on the most suitable physical layout for the network. IBM argued in favor of Ring-shaped
    networks while the manufacturing industry, led by General Motors, argued in favor
    of a bus-shaped network. This led to the creation of the [IEEE 802.4 working group](http://www.ieee802.org/4/)
    to standardize Token Bus networks and the [IEEE 802.5 working group](http://www.ieee802.org/5/)
    to standardize Token Ring networks. Although these techniques are not widely used
    anymore today, the principles behind a token-based protocol are still important.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 确定性技术和机会主义技术的支持者都游说制定标准，以将他们的解决方案纳入局域网。而不是试图在这两种相互矛盾的观点之间找到一个不可能的折中方案，负责制定局域网标准的
    IEEE 802 委员会决定并行工作在三种不同的局域网技术上，并创建了三个工作组。[IEEE 802.3 工作组](http://www.ieee802.org/3/)
    负责CSMA/CD。确定性 MAC 算法的支持者就交换称为令牌的特殊帧以调节对传输介质访问的基本原则达成一致。然而，他们并没有就网络最合适的物理布局达成一致。IBM
    支持环形网络，而由通用汽车领导的制造业则支持总线形网络。这导致了[IEEE 802.4 工作组](http://www.ieee802.org/4/)的创建，以标准化令牌总线网络，以及[IEEE
    802.5 工作组](http://www.ieee802.org/5/)的创建，以标准化令牌环网络。尽管这些技术今天不再广泛使用，但基于令牌的协议背后的原理仍然很重要。
- en: The IEEE 802.5 Token Ring technology is defined in [[IEEE802.5]](../bibliography.html#ieee802-5).
    We use Token Ring as an example to explain the principles of the token-based MAC
    algorithms in ring-shaped networks. Other ring-shaped networks include the defunct
    FDDI [[Ross1989]](../bibliography.html#ross1989) or Resilient Pack Ring [[DYGU2004]](../bibliography.html#dygu2004)
    . A good survey of the early token ring networks may be found in [[Bux1989]](../bibliography.html#bux1989)
    .
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: IEEE 802.5 令牌环技术定义在 [[IEEE802.5]](../bibliography.html#ieee802-5)。我们以令牌环为例来解释环形网络中基于令牌的
    MAC 算法原理。其他环形网络包括已废弃的 FDDI [[Ross1989]](../bibliography.html#ross1989) 或弹性包环 [[DYGU2004]](../bibliography.html#dygu2004)。早期令牌环网络的良好综述可以在
    [[Bux1989]](../bibliography.html#bux1989) 中找到。
- en: 'A Token Ring network is composed of a set of stations that are attached to
    a unidirectional ring. The basic principle of the Token Ring MAC algorithm is
    that two types of frames travel on the ring : tokens and data frames. When the
    Token Ring starts, one of the stations sends the token. The token is a small frame
    that represents the authorization to transmit data frames on the ring. To transmit
    a data frame on the ring, a station must first capture the token by removing it
    from the ring. As only one station can capture the token at a time, the station
    that owns the token can safely transmit a data frame on the ring without risking
    collisions. After having transmitted its frame, the station must remove it from
    the ring and resend the token so that other stations can transmit their own frames.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 令牌环网络由一组连接到单向环上的站点组成。令牌环 MAC 算法的基本原理是，两种类型的帧在环上传输：令牌和数据帧。当令牌环启动时，其中一个站点发送令牌。令牌是一个表示在环上传输数据帧的授权的小帧。要传输数据帧到环上，一个站点必须首先通过从环上移除令牌来捕获它。由于一次只能有一个站点捕获令牌，因此拥有令牌的站点可以在不冒风险发生冲突的情况下安全地在环上传输数据帧。在传输完其帧后，该站点必须将其从环上移除并重新发送令牌，以便其他站点可以传输它们自己的帧。
- en: '[![../_images/token-ring.png](../Images/204991c6fea7862f915a3396c1578736.png)](../_images/token-ring.png)'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '[![../_images/token-ring.png](../Images/204991c6fea7862f915a3396c1578736.png)](../_images/token-ring.png)'
- en: Fig. 206 A Token Ring network[#](#id93 "Link to this image")
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图 206 一个令牌环网络[#](#id93 "链接到这张图片")
- en: While the basic principles of the Token Ring are simple, there are several subtle
    implementation details that add complexity to Token Ring networks. To understand
    these details let us analyze the operation of a Token Ring interface on a station.
    A Token Ring interface serves three different purposes. Like other LAN interfaces,
    it must be able to send and receive frames. In addition, a Token Ring interface
    is part of the ring, and as such, it must be able to forward the electrical signal
    that passes on the ring even when its station is powered off.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然令牌环的基本原理很简单，但有几个细微的实现细节增加了令牌环网络的复杂性。为了理解这些细节，让我们分析一个站点上令牌环接口的操作。令牌环接口有三个不同的用途。像其他局域网接口一样，它必须能够发送和接收帧。此外，令牌环接口是环的一部分，因此它必须能够在其站点断电时转发环上传递的电信号。
- en: 'When powered-on, Token Ring interfaces operate in two different modes : listen
    and transmit. When operating in listen mode, a Token Ring interface receives an
    electrical signal from its upstream neighbor on the ring, introduces a delay equal
    to the transmission time of one bit on the ring and regenerates the signal before
    sending it to its downstream neighbor on the ring.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 当启动时，令牌环接口以两种不同的模式运行：监听和传输。在监听模式下，令牌环接口从环上的上游邻居接收一个电信号，在环上引入一个等于一个比特传输时间的延迟，并在将其发送到环上的下游邻居之前再生该信号。
- en: The first problem faced by a Token Ring network is that as the token represents
    the authorization to transmit, it must continuously travel on the ring when no
    data frame is being transmitted. Let us assume that a token has been produced
    and sent on the ring by one station. In Token Ring networks, the token is a 24
    bits frame whose structure is shown below.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 令牌环网络面临的第一问题是，作为传输授权的令牌，在没有数据帧传输时，它必须持续在环上传输。让我们假设一个令牌已经被一个站点产生并发送到环上。在令牌环网络中，令牌是一个
    24 比特帧，其结构如下所示。
- en: '[![../_images/token-ring.svg](../Images/d3fd5c0099436c887eea9ad8ae351d82.png)](../_images/token-ring.svg)'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '[![../_images/token-ring.svg](../Images/d3fd5c0099436c887eea9ad8ae351d82.png)](../_images/token-ring.svg)'
- en: Fig. 207 802.5 token format[#](#id94 "Link to this image")
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 图. 207 802.5 令牌格式[#](#id94 "链接到这张图片")
- en: The token is composed of three fields. First, the Starting Delimiter is the
    marker that indicates the beginning of a frame. The first Token Ring networks
    used Manchester coding and the Starting Delimiter contained both symbols representing
    0 and symbols that do not represent bits. The last field is the Ending Delimiter
    which marks the end of the token. The Access Control field is present in all frames,
    and contains several flags. The most important is the Token bit that is set in
    token frames and reset in other frames.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 令牌由三个字段组成。首先，起始定界符是表示帧开始的标记。最初的令牌环网络使用曼彻斯特编码，起始定界符包含表示 0 的符号和不表示比特的符号。最后一个字段是结束定界符，它标记令牌的结束。访问控制字段存在于所有帧中，并包含几个标志。最重要的是令牌比特，它在令牌帧中设置，在其他帧中重置。
- en: Let us consider the five station network depicted in figure [A Token Ring network](#fig-tokenring)
    above and assume that station S1 sends a token. If we neglect the propagation
    delay on the inter-station links, as each station introduces a one bit delay,
    the first bit of the frame would return to S1 while it sends the fifth bit of
    the token. If station S1 is powered off at that time, only the first five bits
    of the token will travel on the ring. To avoid this problem, there is a special
    station called the Monitor on each Token Ring. To ensure that the token can travel
    forever on the ring, this Monitor inserts a delay that is equal to at least 24
    bit transmission times. If station S3 was the Monitor in figure [A Token Ring
    network](#fig-tokenring), S1 would have been able to transmit the entire token
    before receiving the first bit of the token from its upstream neighbor.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑上面图 [A Token Ring network](#fig-tokenring) 所示的五个站点网络，并假设站点 S1 发送一个令牌。如果我们忽略站点间链路上的传播延迟，因为每个站点引入一个比特延迟，帧的第一个比特会在发送令牌的第五比特时返回到
    S1。如果那时站点 S1 断电，只有令牌的前五个比特会在环上传输。为了避免这个问题，每个令牌环上都有一个特殊的站点，称为监控器。为了确保令牌可以在环上永远传输，这个监控器插入一个等于至少
    24 比特传输时间的延迟。如果图 [A Token Ring network](#fig-tokenring) 中的监控器是站点 S3，S1 就能在收到上游邻居的第一个令牌比特之前发送整个令牌。
- en: Now that we have explained how the token can be forwarded on the ring, let us
    analyze how a station can capture a token to transmit a data frame. For this,
    we need some information about the format of the data frames. An 802.5 data frame
    begins with the Starting Delimiter followed by the Access Control field whose
    Token bit is reset, a Frame Control field that enables the definition of several
    types of frames, destination and source address, a payload, a CRC, the Ending
    Delimiter and a Frame Status field. The format of the Token Ring data frames is
    illustrated below.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经解释了如何在环上转发令牌，让我们分析一下站点如何捕获令牌以传输数据帧。为此，我们需要一些关于数据帧格式的信息。802.5数据帧以起始定界符开头，后跟令牌位被重置的访问控制字段，一个帧控制字段，它允许定义多种类型的帧，目标地址和源地址，有效载荷，CRC，结束定界符和一个帧状态字段。令牌环数据帧的格式如下所示。
- en: '[![../_images/8025.svg](../Images/9f175bb0486e691ee2c9018db5a42d22.png)](../_images/8025.svg)'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '[![../_images/8025.svg](../Images/9f175bb0486e691ee2c9018db5a42d22.png)](../_images/8025.svg)'
- en: Fig. 208 802.5 data frame format[#](#id95 "Link to this image")
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 图208 802.5数据帧格式[#](#id95 "链接到这张图片")
- en: To capture a token, a station must operate in Listen mode. In this mode, the
    station receives bits from its upstream neighbor. If the bits correspond to a
    data frame, they must be forwarded to the downstream neighbor. If they correspond
    to a token, the station can capture it and transmit its data frame. Both the data
    frame and the token are encoded as a bit string beginning with the Starting Delimiter
    followed by the Access Control field. When the station receives the first bit
    of a Starting Delimiter, it cannot know whether this is a data frame or a token
    and must forward the entire delimiter to its downstream neighbor. It is only when
    it receives the fourth bit of the Access Control field (i.e. the Token bit) that
    the station knows whether the frame is a data frame or a token. If the Token bit
    is reset, it indicates a data frame and the remaining bits of the data frame must
    be forwarded to the downstream station. Otherwise (Token bit is set), this is
    a token and the station can capture it by resetting the bit that is currently
    in its buffer. Thanks to this modification, the beginning of the token is now
    the beginning of a data frame and the station can switch to Transmit mode and
    send its data frame starting at the fifth bit of the Access Control field. Thus,
    the one-bit delay introduced by each Token Ring station plays a key role in enabling
    the stations to efficiently capture the token.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 要捕获一个令牌，站点必须在监听模式下操作。在此模式下，站点从其上游邻居接收位。如果这些位对应于数据帧，它们必须转发给下游邻居。如果它们对应于令牌，站点可以捕获它并传输其数据帧。数据帧和令牌都编码为以起始定界符开头，后跟访问控制字段的位字符串。当站点接收到起始定界符的第一个位时，它无法知道这是一个数据帧还是一个令牌，必须将整个定界符转发给其下游邻居。只有当它接收到访问控制字段的第四位（即令牌位）时，站点才知道帧是数据帧还是令牌。如果令牌位被重置，它表示这是一个数据帧，数据帧的剩余位必须转发到下游站点。否则（令牌位被设置），这是一个令牌，站点可以通过重置其缓冲区中当前位的位来捕获它。多亏了这个修改，令牌的开始现在就是数据帧的开始，站点可以切换到传输模式，并从访问控制字段的第五位开始发送其数据帧。因此，每个令牌环站点引入的一个位延迟在使站点能够有效地捕获令牌方面发挥着关键作用。
- en: After having transmitted its data frame, the station must remain in Transmit
    mode until it has received the last bit of its own data frame. This ensures that
    the bits sent by a station do not remain in the network forever. A data frame
    sent by a station in a Token Ring network passes in front of all stations attached
    to the network. Each station can detect the data frame and analyze the destination
    address to possibly capture the frame.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在发送完其数据帧后，站点必须保持在传输模式下，直到它接收到其自身数据帧的最后一位。这确保了站点发送的位不会永远留在网络中。在令牌环网络中，由站点发送的数据帧会经过网络中连接的所有站点。每个站点都可以检测到数据帧并分析目标地址，以可能捕获该帧。
- en: The text above describes the basic operation of a Token Ring network when all
    stations work correctly. Unfortunately, a real Token Ring network must be able
    to handle various types of anomalies and this increases the complexity of Token
    Ring stations. We briefly list the problems and outline their solutions below.
    A detailed description of the operation of Token Ring stations may be found in
    [[IEEE802.5]](../bibliography.html#ieee802-5). The first problem is when all the
    stations attached to the network start. One of them must bootstrap the network
    by sending the first token. For this, all stations implement a distributed election
    mechanism that is used to select the Monitor. Any station can become a Monitor.
    The Monitor manages the Token Ring network and ensures that it operates correctly.
    Its first role is to introduce a delay of 24 bit transmission times to ensure
    that the token can travel smoothly on the ring. Second, the Monitor sends the
    first token on the ring. It must also verify that the token passes regularly.
    According to the Token Ring standard [[IEEE802.5]](../bibliography.html#ieee802-5),
    a station cannot retain the token to transmit data frames for a duration longer
    than the Token Holding Time (THT) (slightly less than 10 milliseconds). On a network
    containing N stations, the Monitor must receive the token at least every \(N \times
    THT\) seconds. If the Monitor does not receive a token during such a period, it
    cuts the ring for some time and then re-initializes the ring and sends a token.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 上文描述了当所有站点都正常工作时令牌环网络的基本操作。不幸的是，一个真实的令牌环网络必须能够处理各种类型的异常，这增加了令牌环站点的复杂性。我们简要列出问题及其解决方案如下。有关令牌环站点的详细操作描述，请参阅
    [[IEEE802.5]](../bibliography.html#ieee802-5)。第一个问题是当所有连接到网络的站点启动时。其中之一必须通过发送第一个令牌来引导网络。为此，所有站点都实现了一种分布式选举机制，用于选择监控器。任何站点都可以成为监控器。监控器管理令牌环网络并确保其正确运行。它的第一个角色是引入24比特传输时间的延迟，以确保令牌可以在环上平稳地传输。其次，监控器在环上发送第一个令牌。它还必须验证令牌是否定期通过。根据令牌环标准
    [[IEEE802.5]](../bibliography.html#ieee802-5)，一个站点不能保留令牌以传输数据帧的时间超过令牌保持时间（THT）（略小于10毫秒）。在一个包含N个站点的网络中，监控器必须至少每
    \(N \times THT\) 秒接收令牌。如果在这样一个期间内监控器没有收到令牌，它将切断环一段时间，然后重新初始化环并发送令牌。
- en: Several other anomalies may occur in a Token Ring network. For example, a station
    could capture a token and be powered off before having resent the token. Another
    station could have captured the token, sent its data frame and be powered off
    before receiving all of its data frame. In this case, the bit string corresponding
    to the end of a frame would remain in the ring without being removed by its sender.
    Several techniques are defined in [[IEEE802.5]](../bibliography.html#ieee802-5)
    to allow the Monitor to handle all these problems. If unfortunately, the Monitor
    fails, another station will be elected to become the new Monitor.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在令牌环网络中可能发生几种其他异常。例如，一个站点可能在重新发送令牌之前捕获令牌并关闭电源。另一个站点可能在收到所有数据帧之前捕获令牌、发送其数据帧并关闭电源。在这种情况下，对应于帧末尾的比特串将保留在环中，而不会被其发送者移除。在
    [[IEEE802.5]](../bibliography.html#ieee802-5) 中定义了多种技术，以允许监控器处理所有这些问题。如果不幸的是监控器失败，另一个站点将被选为新的监控器。
- en: Congestion control[#](#congestion-control "Link to this heading")
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**拥塞控制**[#](#congestion-control "链接到本标题")'
- en: Most networks contain links having different bandwidth. Some hosts can use low
    bandwidth wireless networks. Some servers are attached via 10 Gbps interfaces
    and inter-router links may vary from a few tens of kilobits per second up to hundred
    Gbps. Despite these huge differences in performance, any host should be able to
    efficiently exchange segments with a high-end server.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数网络包含具有不同带宽的链接。一些主机可以使用低带宽无线网络。一些服务器通过10 Gbps接口连接，而路由器之间的链接可能从每秒几十千比特到百吉比特不等。尽管这些性能差异巨大，但任何主机都应该能够高效地与高端服务器交换段。
- en: To understand this problem better, let us consider the scenario shown in the
    figure below, where a server (A) attached to a 10 Mbps link needs to reliably
    transfer segments to another computer (C) through a path that contains a 2 Mbps
    link.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解这个问题，让我们考虑以下图示的场景，其中一台连接到10 Mbps链路的服务器（A）需要通过包含2 Mbps链路的路径可靠地传输段到另一台计算机（C）。
- en: '![Figure made with TikZ](../Images/437492f9ed4cdc7e563973c918bb6989.png)'
  id: totrans-203
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用TikZ制作的图](../Images/437492f9ed4cdc7e563973c918bb6989.png)'
- en: ''
  id: totrans-204
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 209 Reliable transport with heterogeneous links
  id: totrans-205
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图209. 具有异构链接的可靠传输
- en: In this network, the segments sent by the server reach router R1. R1 forwards
    the segments towards router R2. Router R1 can potentially receive segments at
    10 Mbps, but it can only forward them at 2 Mbps to router R2 and then to host
    C. Router R1 includes buffers that allow it to store the packets that cannot immediately
    be forwarded to their destination. To understand the operation of a reliable transport
    protocol in this environment, let us consider a simplified model of this network
    where host A is attached to a 10 Mbps link to a queue that represents the buffers
    of router R1. This queue is emptied at a rate of 2 Mbps.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个网络中，服务器发送的段到达路由器R1。R1将段转发到路由器R2。路由器R1理论上可以以10 Mbps的速度接收段，但它只能以2 Mbps的速度将段转发到路由器R2，然后转发到主机C。路由器R1包含缓冲区，允许它存储那些不能立即转发到目的地的数据包。为了理解在这个环境中可靠传输协议的操作，让我们考虑一个简化的网络模型，其中主机A连接到一个10
    Mbps的链路，该链路代表路由器R1的缓冲区队列。这个队列以2 Mbps的速度清空。
- en: '[![../_images/tcp-self-clocking.png](../Images/84e88a885a2921ce9a2b332adc09db01.png)](../_images/tcp-self-clocking.png)'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '![tcp-self-clocking.png](../Images/84e88a885a2921ce9a2b332adc09db01.png)'
- en: Fig. 210 Self clocking[#](#id97 "Link to this image")
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 图. 210 自时钟[#](#id97 "链接到这张图片")
- en: Let us consider that host A uses a window of three segments. It thus sends three
    back-to-back segments at 10 Mbps and then waits for an acknowledgment. Host A
    stops sending segments when its window is full. These segments reach the buffers
    of router R1. The first segment stored in this buffer is sent by router R1 at
    a rate of 2 Mbps to the destination host. Upon reception of this segment, the
    destination sends an acknowledgment. This acknowledgment allows host A to transmit
    a new segment. This segment is stored in the buffers of router R1 while it is
    transmitting the second segment that was sent by host A… Thus, after the transmission
    of the first window of segments, the reliable transport protocol sends one data
    segment after the reception of each acknowledgment returned by the destination.
    In practice, the acknowledgments sent by the destination serve as a kind of clock
    that allows the sending host to adapt its transmission rate to the rate at which
    segments are received by the destination. This self-clocking is the first mechanism
    that allows a window-based reliable transport protocol to adapt to heterogeneous
    networks [[Jacobson1988]](../bibliography.html#jacobson1988). It depends on the
    availability of buffers to store the segments that have been sent by the sender
    but have not yet been transmitted to the destination.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑主机A使用三个段的窗口。因此，它以10 Mbps的速度连续发送三个段，然后等待确认。当窗口满时，主机A停止发送段。这些段到达路由器R1的缓冲区。在这个缓冲区中存储的第一个段以2
    Mbps的速度由路由器R1发送到目标主机。在接收到这个段后，目标发送一个确认。这个确认允许主机A传输一个新的段。这个段在传输由主机A发送的第二个段时存储在路由器R1的缓冲区中……因此，在第一个窗口段的传输之后，可靠传输协议在接收到来自目标每个返回的确认后发送一个数据段。在实践中，目标发送的确认充当一种时钟，允许发送主机根据目标接收段的速度调整其传输速率。这种自时钟是允许基于窗口的可靠传输协议适应异构网络的第一种机制
    [[Jacobson1988]](../bibliography.html#jacobson1988)。它依赖于缓冲区的可用性来存储已由发送方发送但尚未传输到目标的数据段。
- en: However, transport protocols are not only used in this environment. In the global
    Internet, a large number of hosts send segments to a large number of receivers.
    For example, let us consider the network depicted below which is similar to the
    one discussed in [[Jacobson1988]](../bibliography.html#jacobson1988) and [**RFC
    896**](https://datatracker.ietf.org/doc/html/rfc896.html). In this network, we
    assume that the buffers of the router are infinite to ensure that no packet is
    lost.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，传输协议不仅用于这个环境。在全球互联网中，大量主机向大量接收者发送段。例如，让我们考虑下面所示的网络，该网络类似于[[Jacobson1988]](../bibliography.html#jacobson1988)和[**RFC
    896**](https://datatracker.ietf.org/doc/html/rfc896.html)中讨论的网络。在这个网络中，我们假设路由器的缓冲区是无限的，以确保没有数据包丢失。
- en: '![Figure made with TikZ](../Images/0f464428bb4f3f9bf9d9d1dbaafd389d.png)'
  id: totrans-211
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用TikZ制作的图](../Images/0f464428bb4f3f9bf9d9d1dbaafd389d.png)'
- en: ''
  id: totrans-212
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 211 The congestion collapse problem
  id: totrans-213
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图. 211 拥塞崩溃问题
- en: If many senders are attached to the left part of the network above, they all
    send a window full of segments. These segments are stored in the buffers of the
    router before being transmitted towards their destination. If there are many senders
    on the left part of the network, the occupancy of the buffers quickly grows. A
    consequence of the buffer occupancy is that the round-trip-time, measured by the
    transport protocol, between the sender and the receiver increases. Consider a
    network where 10,000 bits segments are sent. When the buffer is empty, such a
    segment requires 1 millisecond to be transmitted on the 10 Mbps link and 5 milliseconds
    to be the transmitted on the 2 Mbps link. Thus, the measured round-trip-time measured
    is roughly 6 milliseconds if we ignore the propagation delay on the links. If
    the buffer contains 100 segments, the round-trip-time becomes \(1+100 \times 5+
    5\) milliseconds as new segments are only transmitted on the 2 Mbps link once
    all previous segments have been transmitted. Unfortunately, if the reliable transport
    protocol uses a retransmission timer and performs go-back-n to recover from transmission
    errors it will retransmit a full window of segments. This increases the occupancy
    of the buffer and the delay through the buffer… Furthermore, the buffer may store
    and send on the low bandwidth links several retransmissions of the same segment.
    This problem is called congestion collapse. It occurred several times during the
    late 1980s on the Internet [[Jacobson1988]](../bibliography.html#jacobson1988).
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 如果许多发送器连接到上述网络的左侧部分，它们都会发送一个满窗口的段。这些段在传输到目的地之前被存储在路由器的缓冲区中。如果网络左侧有多个发送器，缓冲区的占用率会迅速增长。缓冲区占用的一个后果是，由传输协议测量的发送器和接收器之间的往返时间增加。考虑一个发送10,000比特段的网络。当缓冲区为空时，这样的段在10
    Mbps链路上传输需要1毫秒，在2 Mbps链路上传输需要5毫秒。因此，如果我们忽略链路上的传播延迟，测量的往返时间大约是6毫秒。如果缓冲区包含100个段，往返时间变为
    \(1+100 \times 5+ 5\) 毫秒，因为只有在所有之前的段都传输完毕后，新的段才会通过2 Mbps链路传输。不幸的是，如果可靠的传输协议使用重传计时器并执行回退-n来从传输错误中恢复，它将重传一个完整的窗口段。这增加了缓冲区的占用率和通过缓冲区的延迟……此外，缓冲区可能在低带宽链路上存储和发送相同段的多个重传。这个问题被称为拥塞崩溃。在20世纪80年代末的互联网上发生了几次
    [[Jacobson1988]](../bibliography.html#jacobson1988)。
- en: The congestion collapse is a problem that all heterogeneous networks face. Different
    mechanisms have been proposed in the scientific literature to avoid or control
    network congestion. Some of them have been implemented and deployed in real networks.
    To understand this problem in more detail, let us first consider a simple network
    with two hosts attached to a high bandwidth link that are sending segments to
    destination C attached to a low bandwidth link as depicted below.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 拥塞崩溃是所有异构网络面临的问题。科学文献中已经提出了不同的机制来避免或控制网络拥塞。其中一些已经在实际网络中得到实现和部署。为了更详细地了解这个问题，让我们首先考虑一个简单的网络，其中两个主机连接到高速链路，并向连接到低速链路的C目的地发送段，如下所示。
- en: '![Figure made with TikZ](../Images/81b044c15b073243b51b376b5d57bf3d.png)'
  id: totrans-216
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用TikZ制作的图](../Images/81b044c15b073243b51b376b5d57bf3d.png)'
- en: ''
  id: totrans-217
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 212 The congestion problem
  id: totrans-218
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图212 拥塞问题
- en: To avoid congestion collapse, the hosts must regulate their transmission rate
    [[5]](#fcredit) by using a congestion control mechanism. Such a mechanism can
    be implemented in the transport layer or in the network layer. In TCP/IP networks,
    it is implemented in the transport layer, but other technologies such as Asynchronous
    Transfer Mode (ATM) or Frame Relay include congestion control mechanisms in lower
    layers.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免拥塞崩溃，主机必须通过使用拥塞控制机制来调节它们的传输速率 [[5]](#fcredit)。这样的机制可以在传输层或网络层实现。在TCP/IP网络中，它在传输层实现，但其他技术如异步传输模式（ATM）或帧中继在较低层包含拥塞控制机制。
- en: 'Let us first consider the simple problem of a set of \(i\) hosts that share
    a single bottleneck link as shown in the example above. In this network, the congestion
    control scheme must achieve the following objectives [[CJ1989]](../bibliography.html#cj1989)
    :'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '让我们先考虑一个简单的例子，其中一组 \(i\) 个主机共享一个瓶颈链路，如上例所示。在这个网络中，拥塞控制方案必须实现以下目标 [[CJ1989]](../bibliography.html#cj1989)
    :'
- en: The congestion control scheme must avoid congestion. In practice, this means
    that the bottleneck link cannot be overloaded. If \(r_i(t)\) is the transmission
    rate allocated to host \(i\) at time \(t\) and \(R\) the bandwidth of the bottleneck
    link, then the congestion control scheme should ensure that, on average, \(\forall{t}
    \sum{r_i(t)} \le R\).
  id: totrans-221
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 网络拥塞控制方案必须避免拥塞。在实践中，这意味着瓶颈链路不能过载。如果 \(r_i(t)\) 是在时间 \(t\) 分配给主机 \(i\) 的传输速率，而
    \(R\) 是瓶颈链路的带宽，那么拥塞控制方案应确保，平均而言，\(\forall{t} \sum{r_i(t)} \le R\)。
- en: ''
  id: totrans-222
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-223
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: The congestion control scheme must be efficient. The bottleneck link is usually
    both a shared and an expensive resource. Usually, bottleneck links are wide area
    links that are much more expensive to upgrade than the local area networks. The
    congestion control scheme should ensure that such links are efficiently used.
    Mathematically, the control scheme should ensure that \(\forall{t} \sum{r_i(t)}
    \approx R\).
  id: totrans-224
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 网络拥塞控制方案必须高效。瓶颈链路通常是共享且昂贵的资源。通常，瓶颈链路是广域链路，其升级成本远高于局域网。拥塞控制方案应确保这些链路得到有效利用。从数学上讲，控制方案应确保
    \(\forall{t} \sum{r_i(t)} \approx R\)。
- en: ''
  id: totrans-225
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-226
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The congestion control scheme should be fair. Most congestion schemes aim at
    achieving max-min fairness. An allocation of transmission rates to sources is
    said to be max-min fair if :'
  id: totrans-227
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 网络拥塞控制方案应该是公平的。大多数拥塞方案旨在实现最大最小公平性。如果将传输速率分配给源头的分配被认为是最大最小公平的，那么：
- en: ''
  id: totrans-228
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-229
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-230
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: no link in the network is congested
  id: totrans-231
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络中的任何链路都没有拥塞
- en: ''
  id: totrans-232
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-233
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: the rate allocated to source \(j\) cannot be increased without decreasing the
    rate allocated to a source \(i\) whose allocation is smaller than the rate allocated
    to source \(j\) [[Leboudec2008]](../bibliography.html#leboudec2008) .
  id: totrans-234
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分配给源 \(j\) 的速率不能增加，而不减少分配给源 \(i\) 的速率，其中 \(i\) 的分配小于源 \(j\) 的分配 [[Leboudec2008]](../bibliography.html#leboudec2008)
    。
- en: Depending on the network, a max-min fair allocation may not always exist. In
    practice, max-min fairness is an ideal objective that cannot necessarily be achieved.
    When there is a single bottleneck link as in the example above, max-min fairness
    implies that each source should be allocated the same transmission rate.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 根据网络的不同，最大最小公平的分配可能并不总是存在。在实践中，最大最小公平是一个理想的目标，不一定能够实现。当存在单个瓶颈链路，如上述示例中那样时，最大最小公平意味着每个源头应分配相同的传输速率。
- en: To visualize the different rate allocations, it is useful to consider the graph
    shown below. In this graph, we plot on the x-axis (resp. y-axis) the rate allocated
    to host B (resp. A). A point in the graph \((r_B,r_A)\) corresponds to a possible
    allocation of the transmission rates. Since there is a 2 Mbps bottleneck link
    in this network, the graph can be divided into two regions. The lower left part
    of the graph contains all allocations \((r_B,r_A)\) such that the bottleneck link
    is not congested (\(r_A+r_B<2\)). The right border of this region is the efficiency
    line, i.e. the set of allocations that completely utilize the bottleneck link
    (\(r_A+r_B=2\)). Finally, the fairness line is the set of fair allocations.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可视化不同的速率分配，考虑下面的图表是有用的。在这个图表中，我们在x轴（分别y轴）上绘制了分配给主机B（分别A）的速率。图中的点 \((r_B,r_A)\)
    对应于可能的传输速率分配。由于这个网络中有一个2 Mbps的瓶颈链路，因此图表可以分为两个区域。图表的左下部分包含所有不拥塞的分配 \((r_B,r_A)\)，即
    \(r_A+r_B<2\)。这个区域的右边是效率线，即完全利用瓶颈链路的分配集合（\(r_A+r_B=2\)）。最后，公平线是公平分配的集合。
- en: '[![../_images/congestion-rates.png](../Images/9ccea874ced3496fad9f847266e5e96a.png)](../_images/congestion-rates.png)'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/congestion-rates.png](../Images/9ccea874ced3496fad9f847266e5e96a.png)'
- en: Fig. 213 Possible allocated transmission rates[#](#id100 "Link to this image")
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 图. 213 可能的分配传输速率[#](#id100 "链接到这张图片")
- en: As shown in the graph above, a rate allocation may be fair but not efficient
    (e.g. \(r_A=0.7,r_B=0.7\)), fair and efficient ( e.g. \(r_A=1,r_B=1\)) or efficient
    but not fair (e.g. \(r_A=1.5,r_B=0.5\)). Ideally, the allocation should be both
    fair and efficient. Unfortunately, maintaining such an allocation with fluctuations
    in the number of flows that use the network is a challenging problem. Furthermore,
    there might be several thousands flows that pass through the same link [[6]](#fflowslink).
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 如上图所示，速率分配可能是公平但不高效的（例如 \(r_A=0.7,r_B=0.7\)），公平且高效的（例如 \(r_A=1,r_B=1\)）或高效但不公平的（例如
    \(r_A=1.5,r_B=0.5\)）。理想情况下，分配应该是公平且高效的。不幸的是，在流量的数量波动中使用网络时保持这样的分配是一个具有挑战性的问题。此外，可能有数千个流量通过相同的链路
    [[6]](#fflowslink)。
- en: To deal with these fluctuations in demand, which result in fluctuations in the
    available bandwidth, computer networks use a congestion control scheme. This congestion
    control scheme should achieve the three objectives listed above. Some congestion
    control schemes rely on a close cooperation between the end hosts and the routers,
    while others are mainly implemented on the end hosts with limited support from
    the routers.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理这些需求波动，这些波动导致可用带宽波动，计算机网络使用拥塞控制方案。这个拥塞控制方案应该实现上述三个目标。一些拥塞控制方案依赖于终端主机和路由器之间的紧密合作，而其他方案主要在终端主机上实现，并从路由器获得有限的支持。
- en: A congestion control scheme can be modeled as an algorithm that adapts the transmission
    rate (\(r_i(t)\)) of host \(i\) based on the feedback received from the network.
    Different types of feedback are possible. The simplest scheme is a binary feedback
    [[CJ1989]](../bibliography.html#cj1989) [[Jacobson1988]](../bibliography.html#jacobson1988)
    where the hosts simply learn whether the network is congested or not. Some congestion
    control schemes allow the network to regularly send an allocated transmission
    rate in Mbps to each host [[BF1995]](../bibliography.html#bf1995).
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 拥塞控制方案可以建模为一个根据从网络接收到的反馈调整主机 \(i\) 的传输速率 (\(r_i(t)\)) 的算法。可能存在不同类型的反馈。最简单的方案是二进制反馈
    [[CJ1989]](../bibliography.html#cj1989) [[Jacobson1988]](../bibliography.html#jacobson1988)，其中主机简单地学习网络是否拥塞。一些拥塞控制方案允许网络定期向每个主机发送分配的传输速率，单位为
    Mbps [[BF1995]](../bibliography.html#bf1995)。
- en: Let us focus on the binary feedback scheme which is the most widely used today.
    Intuitively, the congestion control scheme should decrease the transmission rate
    of a host when congestion has been detected in the network, in order to avoid
    congestion collapse. Furthermore, the hosts should increase their transmission
    rate when the network is not congested. Otherwise, the hosts would not be able
    to efficiently utilize the network. The rate allocated to each host fluctuates
    with time, depending on the feedback received from the network. Figure [Fig. 214](#fig-congestion-rates)
    illustrates the evolution of the transmission rates allocated to two hosts in
    our simple network. Initially, two hosts have a low allocation, but this is not
    efficient. The allocations increase until the network becomes congested. At this
    point, the hosts decrease their transmission rate to avoid congestion collapse.
    If the congestion control scheme works well, after some time the allocations should
    become both fair and efficient.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们关注目前最广泛使用的二进制反馈方案。直观上，当检测到网络拥塞时，拥塞控制方案应该降低主机的传输速率，以避免拥塞崩溃。此外，当网络未拥塞时，主机应增加其传输速率。否则，主机将无法高效利用网络。分配给每个主机的速率会随着时间波动，取决于从网络接收到的反馈。图
    [图 214](#fig-congestion-rates) 展示了我们简单网络中分配给两个主机的传输速率的演变。最初，两个主机有较低的分配，但这并不高效。分配增加，直到网络变得拥塞。在此点，主机降低其传输速率以避免拥塞崩溃。如果拥塞控制方案工作良好，经过一段时间后，分配应该既公平又高效。
- en: '[![../_images/congestion-rates-evolution.png](../Images/26c6fbe274fb53fd9009bee48fcdb53e.png)](../_images/congestion-rates-evolution.png)'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/congestion-rates-evolution.png](../Images/26c6fbe274fb53fd9009bee48fcdb53e.png)'
- en: Fig. 214 Evolution of the transmission rates[#](#fig-congestion-rates "Link
    to this image")
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 图 214 传输速率的演变[#](#fig-congestion-rates "链接到这张图片")
- en: Various types of rate adaption algorithms are possible. [Dah Ming Chiu](https://home.ie.cuhk.edu.hk/~dmchiu/)
    and [Raj Jain](https://www.cse.wustl.edu/~jain/) have analyzed, in [[CJ1989]](../bibliography.html#cj1989),
    different types of algorithms that can be used by a source to adapt its transmission
    rate to the feedback received from the network. Intuitively, such a rate adaptation
    algorithm increases the transmission rate when the network is not congested (ensure
    that the network is efficiently used) and decrease the transmission rate when
    the network is congested (to avoid congestion collapse).
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 可能存在多种类型的速率自适应算法。[Dah Ming Chiu](https://home.ie.cuhk.edu.hk/~dmchiu/) 和 [Raj
    Jain](https://www.cse.wustl.edu/~jain/) 在 [[CJ1989]](../bibliography.html#cj1989)
    中分析了源可以使用以适应从网络接收到的反馈的不同类型的算法。直观上，这种速率自适应算法在网络未拥塞时增加传输速率（确保网络高效使用），在网络拥塞时降低传输速率（以避免拥塞崩溃）。
- en: 'The simplest form of feedback that the network can send to a source is a binary
    feedback (the network is congested or not congested). In this case, a linear rate
    adaptation algorithm can be expressed as :'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 网络可以向源发送的最简单形式的反馈是二进制反馈（网络是否拥塞）。在这种情况下，线性速率自适应算法可以表示为：
- en: \(rate(t+1)=\alpha_C + \beta_C rate(t)\) when the network is congested
  id: totrans-247
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当网络拥塞时，\(rate(t+1)=\alpha_C + \beta_C rate(t)\)
- en: ''
  id: totrans-248
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-249
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: \(rate(t+1)=\alpha_N + \beta_N rate(t)\) when the network is *not* congested
  id: totrans-250
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当网络**不**拥塞时，\(rate(t+1)=\alpha_N + \beta_N rate(t)\)
- en: With a linear adaption algorithm, \(\alpha_C,\alpha_N, \beta_C\) and \(\beta_N\)
    are constants. The analysis of [[CJ1989]](../bibliography.html#cj1989) shows that
    to be fair and efficient, such a binary rate adaption mechanism must rely on Additive
    Increase and Multiplicative Decrease. When the network is not congested, the hosts
    should slowly increase their transmission rate (\(\beta_N=1~and~\alpha_N>0\)).
    When the network is congested, the hosts must multiplicatively decrease their
    transmission rate (\(\beta_C < 1~and~\alpha_C = 0\)). Such an AIMD rate adaptation
    algorithm can be implemented by the pseudo-code below.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 使用线性自适应算法时，\(\alpha_C,\alpha_N, \beta_C\) 和 \(\beta_N\) 是常数。[[CJ1989]](../bibliography.html#cj1989)
    的分析表明，为了公平和高效，这种二进制速率自适应机制必须依赖于加性增加和乘性减少。当网络不拥塞时，主机应缓慢增加它们的传输速率（\(\beta_N=1~and~\alpha_N>0\)）。当网络拥塞时，主机必须乘性减少它们的传输速率（\(\beta_C
    < 1~and~\alpha_C = 0\)）。这样的 AIMD 速率自适应算法可以通过以下伪代码实现。
- en: '[PRE6]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Note
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Which binary feedback ?
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 哪种二进制反馈？
- en: Two types of binary feedback are possible in computer networks. A first solution
    is to rely on implicit feedback. This is the solution chosen for TCP. TCP’s congestion
    control scheme [[Jacobson1988]](../bibliography.html#jacobson1988) does not require
    any cooperation from the router. It only assumes that they use buffers and that
    they discard packets when there is congestion. TCP uses the segment losses as
    an indication of congestion. When there are no losses, the network is assumed
    to be not congested. This implies that congestion is the main cause of packet
    losses. This is true in wired networks, but unfortunately not always true in wireless
    networks. Another solution is to rely on explicit feedback. This is the solution
    proposed in the DECBit congestion control scheme [[RJ1995]](../bibliography.html#rj1995)
    and used in Frame Relay and ATM networks. This explicit feedback can be implemented
    in two ways. A first solution would be to define a special message that could
    be sent by routers to hosts when they are congested. Unfortunately, generating
    such messages may increase the amount of congestion in the network. Such a congestion
    indication packet is thus discouraged [**RFC 1812**](https://datatracker.ietf.org/doc/html/rfc1812.html).
    A better approach is to allow the intermediate routers to indicate, in the packets
    that they forward, their current congestion status. Binary feedback can be encoded
    by using one bit in the packet header. With such a scheme, congested routers set
    a special bit in the packets that they forward while non-congested routers leave
    this bit unmodified. The destination host returns the congestion status of the
    network in the acknowledgments that it sends. Details about such a solution in
    IP networks may be found in [**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html).
    Unfortunately, as of this writing, this solution is still not deployed despite
    its potential benefits.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机网络中可能存在两种类型的二进制反馈。第一种解决方案是依赖于隐式反馈。这是 TCP 所选择的解决方案。TCP 的拥塞控制方案 [[Jacobson1988]](../bibliography.html#jacobson1988)
    不需要来自路由器的任何合作。它只假设它们使用缓冲区，并在拥塞时丢弃数据包。TCP 使用段丢失作为拥塞的指示。当没有丢失时，假定网络不拥塞。这意味着拥塞是数据包丢失的主要原因。这在有线网络中是正确的，但不幸的是，在无线网络中并不总是如此。另一种解决方案是依赖于显式反馈。这是
    DECBit 拥塞控制方案 [[RJ1995]](../bibliography.html#rj1995) 提出的解决方案，并在帧中继和 ATM 网络中使用。这种显式反馈可以通过两种方式实现。第一种解决方案是定义一种特殊消息，当路由器拥塞时可以发送给主机。不幸的是，生成此类消息可能会增加网络中的拥塞量。因此，这种拥塞指示数据包是不被鼓励的
    [**RFC 1812**](https://datatracker.ietf.org/doc/html/rfc1812.html)。更好的方法是允许中间路由器在它们转发的数据包中指示它们当前的拥塞状态。二进制反馈可以通过在数据包头部使用一个比特来编码。在这种方案中，拥塞路由器在它们转发的数据包中设置一个特殊的比特，而非拥塞路由器则不修改此比特。目标主机在其发送的确认中返回网络的拥塞状态。有关
    IP 网络中此类解决方案的详细信息，请参阅 [**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)。不幸的是，截至本文撰写时，尽管这种解决方案具有潜在的好处，但它仍未部署。
- en: Congestion control with a window-based transport protocol[#](#congestion-control-with-a-window-based-transport-protocol
    "Link to this heading")
  id: totrans-256
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于窗口的传输协议的拥塞控制[#](#congestion-control-with-a-window-based-transport-protocol
    "链接到本标题")
- en: AIMD controls congestion by adjusting the transmission rate of the sources in
    reaction to the current congestion level. If the network is not congested, the
    transmission rate increases. If congestion is detected, the transmission rate
    is multiplicatively decreased. In practice, directly adjusting the transmission
    rate can be difficult since it requires the utilization of fine grained timers.
    In reliable transport protocols, an alternative is to dynamically adjust the sending
    window. This is the solution chosen for protocols like TCP and SCTP that will
    be described in more details later. To understand how window-based protocols can
    adjust their transmission rate, let us consider the very simple scenario of a
    reliable transport protocol that uses go-back-n. Consider the very simple scenario
    shown in figure [Fig. 215](#fig-bottleneck).
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: AIMD 通过对当前拥塞水平做出反应来调整源头的传输速率以控制拥塞。如果网络没有拥塞，传输速率会增加。如果检测到拥塞，传输速率会乘性减少。在实践中，直接调整传输速率可能很困难，因为它需要使用细粒度计时器。在可靠的传输协议中，一个替代方案是动态调整发送窗口。这是
    TCP 和 SCTP 等协议所选择的解决方案，这些协议将在稍后更详细地描述。为了了解基于窗口的协议如何调整它们的传输速率，让我们考虑一个非常简单的可靠传输协议场景，该协议使用
    go-back-n。考虑图 [图 215](#fig-bottleneck) 中显示的非常简单的场景。
- en: '![Figure made with TikZ](../Images/fba8d6b7380280ee70f3550fb599fb9f.png)'
  id: totrans-258
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用 TikZ 制作的图](../Images/fba8d6b7380280ee70f3550fb599fb9f.png)'
- en: ''
  id: totrans-259
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 215 A simple network with hosts sharing a bottleneck link
  id: totrans-260
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图 215 一个简单的网络，主机共享瓶颈链路
- en: The links between the hosts and the routers have a bandwidth of 1 Mbps while
    the link between the two routers has a bandwidth of 500 Kbps. There is no significant
    propagation delay in this network. For simplicity, assume that hosts A and B send
    1000 bits packets. The transmission of such a packet on a host-router (resp. router-router
    ) link requires 1 msec (resp. 2 msec). If there is no traffic in the network,
    the round-trip-time measured by host A to reach D is slightly larger than 4 msec.
    Let us observe the flow of packets with different window sizes to understand the
    relationship between sending window and transmission rate.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 主机与路由器之间的链路带宽为 1 Mbps，而两个路由器之间的链路带宽为 500 Kbps。在这个网络中没有显著的传播延迟。为了简单起见，假设主机 A
    和 B 发送 1000 比特的包。在主机-路由器（分别。路由器-路由器）链路上传输这样的包需要 1 毫秒（分别。2 毫秒）。如果没有网络流量，主机 A 到达
    D 的往返时间略大于 4 毫秒。让我们观察不同窗口大小的数据包流，以了解发送窗口和传输速率之间的关系。
- en: Consider first a window of one segment. This segment takes 4 msec to reach host
    D. The destination replies with an acknowledgment and the next segment can be
    transmitted. With such a sending window, the transmission rate is roughly 250
    segments per second or 250 Kbps. This is illustrated in figure [Fig. 216](#fig-gbn-win-1)
    where each square of the grid corresponds to one millisecond.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 首先考虑一个段窗口。这个段需要 4 毫秒才能到达主机 D。目的地用一个确认回复，然后可以传输下一个段。在这样的发送窗口下，传输速率大约是每秒 250 个段或
    250 Kbps。这如图 [图 216](#fig-gbn-win-1) 所示，其中网格的每个方格对应于一毫秒。
- en: '![Figure made with TikZ](../Images/fb17e125cf960286b8258b6251471572.png)'
  id: totrans-263
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用 TikZ 制作的图](../Images/fb17e125cf960286b8258b6251471572.png)'
- en: ''
  id: totrans-264
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 216 Go-back-n transfer from A to D, window of one segment
  id: totrans-265
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图 216 从 A 到 D 的 Go-back-n 传输，一个段窗口
- en: Consider now a window of two segments. Host A can send two segments within 2
    msec on its 1 Mbps link. If the first segment is sent at time \(t_{0}\), it reaches
    host D at \(t_{0}+4\). Host D replies with an acknowledgment that opens the sending
    window on host A and enables it to transmit a new segment. In the meantime, the
    second segment was buffered by router R1. It reaches host D at \(t_{0}+6\) and
    an acknowledgment is returned. With a window of two segments, host A transmits
    at roughly 500 Kbps, i.e. the transmission rate of the bottleneck link.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 现在考虑一个两个段的窗口。主机 A 可以在其 1 Mbps 链路上在 2 毫秒内发送两个段。如果第一个段在时间 \(t_{0}\) 发送，它将在 \(t_{0}+4\)
    时到达主机 D。主机 D 用一个确认回复打开主机 A 的发送窗口，并允许它传输一个新的段。与此同时，第二个段被路由器 R1 缓冲。它将在 \(t_{0}+6\)
    时到达主机 D，并返回一个确认。在两个段窗口的情况下，主机 A 以大约 500 Kbps 的速度传输，即瓶颈链路的传输速率。
- en: '![Figure made with TikZ](../Images/972780cbffde5435003f04c4edfabc56.png)'
  id: totrans-267
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用 TikZ 制作的图](../Images/972780cbffde5435003f04c4edfabc56.png)'
- en: ''
  id: totrans-268
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 217 Go-back-n transfer from A to D, window of two segments
  id: totrans-269
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图 217 从 A 到 D 的 Go-back-n 传输，两个段窗口
- en: Our last example is a window of four segments. These segments are sent at \(t_{0}\),
    \(t_{0}+1\), \(t_{0}+2\) and \(t_{0}+3\). The first segment reaches host D at
    \(t_{0}+4\). Host D replies to this segment by sending an acknowledgment that
    enables host A to transmit its fifth segment. This segment reaches router R1 at
    \(t_{0}+5\). At that time, router R1 is transmitting the third segment to router
    R2 and the fourth segment is still in its buffers. At time \(t_{0}+6\), host D
    receives the second segment and returns the corresponding acknowledgment. This
    acknowledgment enables host A to send its sixth segment. This segment reaches
    router R1 at roughly \(t_{0}+7\). At that time, the router starts to transmit
    the fourth segment to router R2. Since link R1-R2 can only sustain 500 Kbps, packets
    will accumulate in the buffers of R1. On average, there will be two packets waiting
    in the buffers of R1. The presence of these two packets will induce an increase
    of the round-trip-time as measured by the transport protocol. While the first
    segment was acknowledged within 4 msec, the fifth segment (data(4)) that was transmitted
    at time \(t_{0}+4\) is only acknowledged at time \(t_{0}+11\). On average, the
    sender transmits at 500 Kbps, but the utilization of a large window induces a
    longer delay through the network.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最后的例子是一个由四个部分组成的窗口。这些部分分别在 \(t_{0}\), \(t_{0}+1\), \(t_{0}+2\) 和 \(t_{0}+3\)
    时刻发送。第一个部分在 \(t_{0}+4\) 时刻到达主机 D。主机 D 通过发送一个确认信息来回复这个部分，这个确认信息使得主机 A 能够发送其第五个部分。这个部分在
    \(t_{0}+5\) 时刻到达路由器 R1。那时，路由器 R1 正在将第三个部分发送到路由器 R2，而第四个部分仍然在其缓冲区中。在 \(t_{0}+6\)
    时刻，主机 D 接收到第二个部分并返回相应的确认信息。这个确认信息使得主机 A 能够发送其第六个部分。这个部分大约在 \(t_{0}+7\) 时刻到达路由器
    R1。那时，路由器开始将第四个部分发送到路由器 R2。由于 R1-R2 链路只能支持 500 Kbps，数据包将会在 R1 的缓冲区中积累。平均来说，将有两个数据包在
    R1 的缓冲区中等待。这两个数据包的存在将导致传输协议测量的往返时间的增加。虽然第一个部分在 4 毫秒内得到了确认，但在 \(t_{0}+4\) 时刻发送的第五个部分（数据(4)）直到
    \(t_{0}+11\) 时刻才得到确认。平均来说，发送方的发送速率为 500 Kbps，但大窗口的使用通过网络引入了更长的延迟。
- en: '![Figure made with TikZ](../Images/6fac88cb38e8b98800e49c18ffa34a0c.png)'
  id: totrans-271
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用 TikZ 制作的图](../Images/6fac88cb38e8b98800e49c18ffa34a0c.png)'
- en: ''
  id: totrans-272
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 218 Go-back-n transfer from A to D, window of four segments
  id: totrans-273
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图 218 从 A 到 D 的回退-n 传输，四个部分的窗口
- en: From the above example, we can adjust the transmission rate by adjusting the
    sending window of a reliable transport protocol. A reliable transport protocol
    cannot send data faster than \(\frac{window}{rtt}\) segments per second where
    \(window\) is the current sending window. To control the transmission rate, we
    introduce a congestion window. This congestion window limits the sending window.
    At any time, the sending window is restricted to \(\min(swin,cwin)\), where swin
    is the sending window and cwin the current congestion window. Of course, the window
    is further constrained by the receive window advertised by the remote peer. With
    the utilization of a congestion window, a simple reliable transport protocol that
    uses fixed size segments could implement AIMD as follows.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面的例子中，我们可以通过调整可靠传输协议的发送窗口来调整传输速率。一个可靠的传输协议不能以每秒 \(\frac{window}{rtt}\) 个部分的速度发送数据，其中
    \(window\) 是当前的发送窗口。为了控制传输速率，我们引入了拥塞窗口。这个拥塞窗口限制了发送窗口。在任何时候，发送窗口都被限制在 \(\min(swin,cwin)\)，其中
    swin 是发送窗口，cwin 是当前的拥塞窗口。当然，窗口还受到远程对端宣布的接收窗口的限制。通过使用拥塞窗口，一个使用固定大小数据包的简单可靠传输协议可以实现如下
    AIMD。
- en: For the Additive Increase part our simple protocol would simply increase its
    congestion window by one segment every round-trip-time. The Multiplicative Decrease
    part of AIMD could be implemented by halving the congestion window when congestion
    is detected. For simplicity, we assume that congestion is detected thanks to a
    binary feedback and that no segments are lost. We will discuss in more details
    how losses affect a real transport protocol like TCP in later sections.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 AIMD 的加性增加部分，我们的简单协议将每往返时间增加一个部分来增加其拥塞窗口。当检测到拥塞时，AIMD 的乘性减少部分可以通过将拥塞窗口减半来实现。为了简单起见，我们假设拥塞是通过二进制反馈检测到的，并且没有数据包丢失。我们将在后面的章节中更详细地讨论损失如何影响像
    TCP 这样的实际传输协议。
- en: A congestion control scheme for our simple transport protocol could be implemented
    as follows.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 我们简单传输协议的拥塞控制方案可以实施如下。
- en: '[PRE7]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In the above pseudocode, cwin contains the congestion window stored as a real
    number of segments. This congestion window is updated upon the arrival of each
    acknowledgment and when congestion is detected. For simplicity, we assume that
    cwin is stored as a floating point number but only full segments can be transmitted.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述伪代码中，cwin 包含以段数为实数存储的拥塞窗口。该拥塞窗口在收到每个确认以及检测到拥塞时更新。为了简化，我们假设 cwin 以浮点数存储，但只能传输完整的段。
- en: As an illustration, let us consider the network scenario above and assume that
    the router implements the DECBit binary feedback scheme [[RJ1995]](../bibliography.html#rj1995).
    This scheme uses a form of Forward Explicit Congestion Notification and a router
    marks the congestion bit in arriving packets when its buffer contains one or more
    packets. In figure [Fig. 219](#fig-gbn-decbit), we use a * to indicate a marked
    packet.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 作为说明，让我们考虑上述网络场景，并假设路由器实现了 DECBit 二进制反馈方案 [[RJ1995]](../bibliography.html#rj1995)。该方案使用一种前向显式拥塞通知，当路由器的缓冲区包含一个或多个数据包时，路由器会在到达的数据包中标记拥塞位。在图
    [图 219](#fig-gbn-decbit) 中，我们用 * 来表示标记的数据包。
- en: '![Figure made with TikZ](../Images/2b9761249f9ab8572a0fc4b3416b6752.png)'
  id: totrans-280
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用 TikZ 制作的图](../Images/2b9761249f9ab8572a0fc4b3416b6752.png)'
- en: ''
  id: totrans-281
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 219 Go-back-n transfer from A to D, with AIMD congestion control and DecBit
    binary feedback scheme
  id: totrans-282
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图 219 从 A 到 D 的回退-n 传输，带有 AIMD 拥塞控制和 DecBit 二进制反馈方案
- en: When the connection starts, its congestion window is set to one segment. Segment
    S0 is sent an acknowledgment at roughly \(t_{0}+4\). The congestion window is
    increased by one segment and S1 and S2 are transmitted at time \(t_{0}+4\) and
    \(t_{0}+5\). The corresponding acknowledgments are received at times \(t_{0}+8\)
    and \(t_{0}+10\). Upon reception of this last acknowledgment, the congestion window
    reaches 3 and segments can be sent (S4 and S5). When segment S6 reaches router
    R1, its buffers already contain S5. The packet containing S6 is thus marked to
    inform the sender of the congestion. Note that the sender will only notice the
    congestion once it receives the corresponding acknowledgment at \(t_{0}+18\).
    In the meantime, the congestion window continues to increase. At \(t_{0}+16\),
    upon reception of the acknowledgment for S5, it reaches 4. When congestion is
    detected, the congestion window is decreased down to 2. This explains the idle
    time between the reception of the acknowledgment for S*6 and the transmission
    of S10.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 当连接开始时，其拥塞窗口设置为一段。段 S0 在大约 \(t_{0}+4\) 时发送确认。拥塞窗口增加一段，S1 和 S2 在时间 \(t_{0}+4\)
    和 \(t_{0}+5\) 时传输。相应的确认在时间 \(t_{0}+8\) 和 \(t_{0}+10\) 时收到。在收到最后一个确认后，拥塞窗口达到 3，可以发送段（S4
    和 S5）。当段 S6 到达路由器 R1 时，其缓冲区已包含 S5。包含 S6 的数据包因此被标记，以通知发送者拥塞。请注意，发送者只有在收到时间 \(t_{0}+18\)
    的相应确认后才会注意到拥塞。在此期间，拥塞窗口继续增加。在 \(t_{0}+16\)，在收到 S5 的确认后，它达到 4。当检测到拥塞时，拥塞窗口降低到 2。这解释了从收到
    S*6 的确认到发送 S10 之间的空闲时间。
- en: In practice, a router is connected to multiple input links. Figure [Fig. 220](#fig-2hosts-bottleneck)
    shows an example with two hosts.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，路由器连接到多个输入链路。图 [图 220](#fig-2hosts-bottleneck) 展示了两个主机的示例。
- en: '![Figure made with TikZ](../Images/54044b2beb542c9ff304fe654e7cbe2e.png)'
  id: totrans-285
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用 TikZ 制作的图](../Images/54044b2beb542c9ff304fe654e7cbe2e.png)'
- en: ''
  id: totrans-286
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 220 A simple network with hosts sharing a bottleneck
  id: totrans-287
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图 220 具有主机共享瓶颈的简单网络
- en: ''
  id: totrans-288
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Figure made with TikZ](../Images/14805061572e2ea7a08e10338a022ff8.png)'
  id: totrans-289
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用 TikZ 制作的图](../Images/14805061572e2ea7a08e10338a022ff8.png)'
- en: ''
  id: totrans-290
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 221 Sharing the bottleneck link between different inputs
  id: totrans-291
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图 221 不同输入之间共享瓶颈链路
- en: In general, the links have a non-zero delay. This is illustrated in the figure
    below where a delay has been added on the link between R and C.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，链路具有非零延迟。这在下图中得到了说明，其中在 R 和 C 之间的链路上添加了延迟。
- en: '![Figure made with TikZ](../Images/515eaae674689b5424d8fbcf3dfe9c0e.png)'
  id: totrans-293
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用 TikZ 制作的图](../Images/515eaae674689b5424d8fbcf3dfe9c0e.png)'
- en: ''
  id: totrans-294
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 222 Sharing the bottleneck link between different inputs
  id: totrans-295
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图 222 不同输入之间共享瓶颈链路
- en: '### Congestion control[#](#tcpcongestion "Link to this heading")'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '### 拥塞控制[#](#tcpcongestion "链接到本标题")'
- en: In an internetwork, i.e. a networking composed of different types of networks
    (such as the Internet), congestion control could be implemented either in the
    network layer or the transport layer. The congestion problem was clearly identified
    in the later 1980s and the researchers who developed techniques to solve the problem
    opted for a solution in the transport layer. Adding congestion control to the
    transport layer makes sense since this layer provides a reliable data transfer
    and avoiding congestion is a factor in this reliable delivery. The transport layer
    already deals with heterogeneous networks thanks to its self-clocking property
    that we have already described. In this section, we explain how congestion control
    has been added to TCP and how this mechanism could be improved in the future.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个互联网中，即由不同类型的网络（如互联网）组成的网络，拥塞控制可以在网络层或传输层实现。拥塞问题在20世纪80年代末得到明确识别，开发了解决该问题技术的研究人员选择了传输层的解决方案。在传输层添加拥塞控制是有意义的，因为这一层提供可靠的数据传输，避免拥塞是这种可靠交付的一个因素。由于我们已经描述的自时钟特性，传输层已经处理了异构网络。在本节中，我们解释了如何将拥塞控制添加到TCP，以及如何在未来改进这种机制。
- en: The TCP congestion control scheme was initially proposed by [Van Jacobson](https://en.wikipedia.org/wiki/Van_Jacobson)
    in [[Jacobson1988]](../bibliography.html#jacobson1988). The current specification
    may be found in [**RFC 5681**](https://datatracker.ietf.org/doc/html/rfc5681.html).
    TCP relies on Additive Increase and Multiplicative Decrease (AIMD). To implement
    [AIMD](../glossary.html#term-AIMD), a TCP host must be able to control its transmission
    rate. A first approach would be to use timers and adjust their expiration times
    in function of the rate imposed by [AIMD](../glossary.html#term-AIMD). Unfortunately,
    maintaining such timers for a large number of TCP connections can be difficult.
    Instead, [Van Jacobson](https://en.wikipedia.org/wiki/Van_Jacobson) noted that
    the rate of TCP congestion can be artificially controlled by constraining its
    sending window. A TCP connection cannot send data faster than \(\frac{window}{rtt}\)
    where \(window\) is the minimum between the host’s sending window and the window
    advertised by the receiver.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: TCP拥塞控制方案最初由[Van Jacobson](https://en.wikipedia.org/wiki/Van_Jacobson)在[[Jacobson1988]](../bibliography.html#jacobson1988)中提出。当前规范可以在[**RFC
    5681**](https://datatracker.ietf.org/doc/html/rfc5681.html)中找到。TCP依赖于累加增加和乘性减少（AIMD）。为了实现[A
    IMD](../glossary.html#term-AIMD)，TCP主机必须能够控制其传输速率。一种初步的方法是使用计时器，并根据[A IMD](../glossary.html#term-AIMD)施加的速率调整它们的过期时间。不幸的是，维护大量TCP连接的此类计时器可能很困难。相反，[Van
    Jacobson](https://en.wikipedia.org/wiki/Van_Jacobson)指出，可以通过限制其发送窗口来人为地控制TCP拥塞的速率。TCP连接的发送数据速率不能超过\(\frac{window}{rtt}\)，其中\(window\)是主机发送窗口和接收方广告窗口之间的最小值。
- en: TCP’s congestion control scheme is based on a congestion window. The current
    value of the congestion window (cwnd) is stored in the TCB of each TCP connection
    and the window that can be used by the sender is constrained by \(\min(cwnd,rwin,swin)\)
    where \(swin\) is the current sending window and \(rwin\) the last received receive
    window. The Additive Increase part of the TCP congestion control increments the
    congestion window by [MSS](../glossary.html#term-MSS) bytes every round-trip-time.
    In the TCP literature, this phase is often called the congestion avoidance phase.
    The Multiplicative Decrease part of the TCP congestion control divides the current
    value of the congestion window once congestion has been detected.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: TCP的拥塞控制方案基于拥塞窗口。拥塞窗口的当前值存储在每个TCP连接的TCB中，发送者可以使用的窗口由\(\min(cwnd,rwin,swin)\)约束，其中\(swin\)是当前发送窗口，\(rwin\)是最后接收到的接收窗口。TCP拥塞控制的累加增加部分在每个往返时间增加拥塞窗口[MSS](../glossary.html#term-MSS)字节。在TCP文献中，这个阶段通常被称为拥塞避免阶段。TCP拥塞控制的乘性减少部分在检测到拥塞后，将当前拥塞窗口的值除以一次。
- en: 'When a TCP connection begins, the sending host does not know whether the part
    of the network that it uses to reach the destination is congested or not. To avoid
    causing too much congestion, it must start with a small congestion window. [[Jacobson1988]](../bibliography.html#jacobson1988)
    recommends an initial window of MSS bytes. As the additive increase part of the
    TCP congestion control scheme increments the congestion window by MSS bytes every
    round-trip-time, the TCP connection may have to wait many round-trip-times before
    being able to efficiently use the available bandwidth. This is especially important
    in environments where the \(bandwidth \times rtt\) product is high. To avoid waiting
    too many round-trip-times before reaching a congestion window that is large enough
    to efficiently utilize the network, the TCP congestion control scheme includes
    the slow-start algorithm. The objective of the TCP slow-start phase is to quickly
    reach an acceptable value for the cwnd. During slow-start, the congestion window
    is doubled every round-trip-time. The slow-start algorithm uses an additional
    variable in the TCB : ssthresh (slow-start threshold). The ssthresh is an estimation
    of the last value of the cwnd that did not cause congestion. It is initialized
    at the sending window and is updated after each congestion event.'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 当TCP连接开始时，发送主机不知道它用来到达目的地的网络部分是否拥塞。为了避免造成过多的拥塞，它必须从一个小的拥塞窗口开始。[[Jacobson1988]](../bibliography.html#jacobson1988)建议初始窗口为MSS字节。由于TCP拥塞控制方案的累加增加部分在每个往返时间增加MSS字节的拥塞窗口，TCP连接可能需要等待多个往返时间才能有效地使用可用带宽。这在带宽乘以往返时间（\(bandwidth
    \times rtt\)）乘积较高的环境中尤为重要。为了避免在达到足够大的拥塞窗口以有效地利用网络之前等待过多的往返时间，TCP拥塞控制方案包括慢启动算法。TCP慢启动阶段的目标是快速达到cwnd的可接受值。在慢启动期间，拥塞窗口在每个往返时间翻倍。慢启动算法在TCB中使用一个额外的变量：ssthresh（慢启动阈值）。ssthresh是对未引起拥塞的cwnd最后值的估计。它初始化为发送窗口，并在每次拥塞事件后更新。
- en: 'A key question that must be answered by any congestion control scheme is how
    congestion is detected. The first implementations of the TCP congestion control
    scheme opted for a simple and pragmatic approach : packet losses indicate congestion.
    If the network is congested, router buffers are full and packets are discarded.
    In wired networks, packet losses are mainly caused by congestion. In wireless
    networks, packets can be lost due to transmission errors and for other reasons
    that are independent of congestion. TCP already detects segment losses to ensure
    a reliable delivery. The TCP congestion control scheme distinguishes between two
    types of congestion :'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 任何拥塞控制方案都必须回答的一个关键问题是如何检测拥塞。TCP拥塞控制方案的第一种实现选择了简单而实用的方法：数据包丢失表示拥塞。如果网络拥塞，路由器缓冲区将满，数据包将被丢弃。在有线网络中，数据包丢失主要是由拥塞引起的。在无线网络中，数据包可能由于传输错误或其他与拥塞无关的原因而丢失。TCP已经检测到段丢失以确保可靠交付。TCP拥塞控制方案区分两种类型的拥塞：
- en: mild congestion. TCP considers that the network is lightly congested if it receives
    three duplicate acknowledgments and performs a fast retransmit. If the fast retransmit
    is successful, this implies that only one segment has been lost. In this case,
    TCP performs multiplicative decrease and the congestion window is divided by 2.
    The slow-start threshold is set to the new value of the congestion window.
  id: totrans-302
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 轻度拥塞。如果TCP收到三个重复的确认并执行快速重传，TCP认为网络轻度拥塞。如果快速重传成功，这意味着只有一个数据段丢失。在这种情况下，TCP执行乘性减少，拥塞窗口除以2。慢启动阈值设置为新的拥塞窗口值。
- en: ''
  id: totrans-303
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-304
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: severe congestion. TCP considers that the network is severely congested when
    its retransmission timer expires. In this case, TCP retransmits the first segment,
    sets the slow-start threshold to 50% of the congestion window. The congestion
    window is reset to its initial value and TCP performs a slow-start.
  id: totrans-305
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 严重拥塞。当TCP的重传计时器超时时，TCP认为网络严重拥塞。在这种情况下，TCP会重传第一个数据段，将慢启动阈值设置为拥塞窗口的50%。拥塞窗口重置为其初始值，TCP执行慢启动。
- en: The figure below illustrates the evolution of the congestion window when there
    is severe congestion. At the beginning of the connection, the sender performs
    slow-start until the first segments are lost and the retransmission timer expires.
    At this time, the ssthresh is set to half of the current congestion window and
    the congestion window is reset at one segment. The lost segments are retransmitted
    as the sender again performs slow-start until the congestion window reaches the
    sshtresh. It then switches to congestion avoidance and the congestion window increases
    linearly until segments are lost and the retransmission timer expires.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 下图说明了严重拥塞时拥塞窗口的演变。在连接开始时，发送者执行慢启动，直到第一个段丢失且重传计时器到期。此时，ssthresh设置为当前拥塞窗口的一半，拥塞窗口重置为一个段。丢失的段被重传，因为发送者再次执行慢启动，直到拥塞窗口达到sshtresh。然后它切换到拥塞避免，拥塞窗口线性增加，直到段丢失且重传计时器到期。
- en: '[![../_images/tcp-congestion-severe.png](../Images/8bb9ad90fd07bc82d9cba2b40a1481a6.png)](../_images/tcp-congestion-severe.png)'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '![TCP拥塞严重情况](../Images/8bb9ad90fd07bc82d9cba2b40a1481a6.png)(../_images/tcp-congestion-severe.png)'
- en: Fig. 223 Evaluation of the TCP congestion window with severe congestion[#](#id109
    "Link to this image")
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 图223 严重拥塞时TCP拥塞窗口的评估[#](#id109 "链接到此图像")
- en: The figure below illustrates the evolution of the congestion window when the
    network is lightly congested and all lost segments can be retransmitted using
    fast retransmit. The sender begins with a slow-start. A segment is lost but successfully
    retransmitted by a fast retransmit. The congestion window is divided by 2 and
    the sender immediately enters congestion avoidance as this was a mild congestion.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 下图说明了网络轻微拥塞且所有丢失的段都可以使用快速重传重新传输时拥塞窗口的演变。发送者从慢启动开始。一个段丢失，但通过快速重传成功重传。由于这是轻微拥塞，拥塞窗口减半，发送者立即进入拥塞避免状态。
- en: '[![../_images/tcp-congestion-mild.png](../Images/118024671401b1ade2c8daa21527e64f.png)](../_images/tcp-congestion-mild.png)'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: '![TCP轻微拥塞情况](../Images/118024671401b1ade2c8daa21527e64f.png)(../_images/tcp-congestion-mild.png)'
- en: Fig. 224 Evaluation of the TCP congestion window when the network is lightly
    congested[#](#id110 "Link to this image")
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 图224 网络轻微拥塞时TCP拥塞窗口的评估[#](#id110 "链接到此图像")
- en: Most TCP implementations update the congestion window when they receive an acknowledgment.
    If we assume that the receiver acknowledges each received segment and the sender
    only sends MSS sized segments, the TCP congestion control scheme can be implemented
    using the simplified pseudo-code [[7]](#fwrap) below. This pseudocode includes
    the optimization proposed in [**RFC 3042**](https://datatracker.ietf.org/doc/html/rfc3042.html)
    that allows a sender to send new unsent data upon reception of the first or second
    duplicate acknowledgment. The reception of each of these acknowledgments indicates
    that one segment has left the network and thus additional data can be sent without
    causing more congestion. Note that the congestion window is *not* increased upon
    reception of these first duplicate acknowledgments.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数TCP实现会在收到确认时更新拥塞窗口。如果我们假设接收者确认每个接收到的段，并且发送者只发送MSS大小的段，则可以使用以下简化的伪代码实现TCP拥塞控制方案
    [[7]](#fwrap)。此伪代码包括在[**RFC 3042**](https://datatracker.ietf.org/doc/html/rfc3042.html)中提出的优化，允许发送者在收到第一个或第二个重复确认后发送新的未发送数据。接收这些确认中的每一个都表明一个段已经离开网络，因此可以发送更多数据而不会造成更多拥塞。请注意，在收到这些第一个重复确认时，拥塞窗口不会增加。
- en: '[PRE8]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Furthermore when a TCP connection has been idle for more than its current retransmission
    timer, it should reset its congestion window to the congestion window size that
    it uses when the connection begins, as it no longer knows the current congestion
    state of the network.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，当TCP连接空闲时间超过其当前的重传计时器时，它应将其拥塞窗口重置为连接开始时使用的拥塞窗口大小，因为它不再知道网络的当前拥塞状态。
- en: Note
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Initial congestion window
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 初始拥塞窗口
- en: The original TCP congestion control mechanism proposed in [[Jacobson1988]](../bibliography.html#jacobson1988)
    recommended that each TCP connection should begin by setting \(cwnd=MSS\). However,
    in today’s higher bandwidth networks, using such a small initial congestion window
    severely affects the performance for short TCP connections, such as those used
    by web servers. In 2002, [**RFC 3390**](https://datatracker.ietf.org/doc/html/rfc3390.html)
    allowed an initial congestion window of about 4 KBytes, which corresponds to 3
    segments in many environments. Recently, researchers from Google proposed to further
    increase the initial window up to 15 KBytes [[DRC+2010]](../bibliography.html#drc-2010).
    The measurements that they collected show that this increase would not significantly
    increase congestion but would significantly reduce the latency of short HTTP responses.
    Unsurprisingly, the chosen initial window corresponds to the average size of an
    HTTP response from a search engine. This proposed modification has been adopted
    in [**RFC 6928**](https://datatracker.ietf.org/doc/html/rfc6928.html) and TCP
    implementations support it.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [[Jacobson1988]](../bibliography.html#jacobson1988) 中提出的原始TCP拥塞控制机制建议每个TCP连接应从设置
    \(cwnd=MSS\) 开始。然而，在今天的宽带网络中，使用如此小的初始拥塞窗口严重影响了短TCP连接的性能，例如那些由Web服务器使用的连接。2002年，[**RFC
    3390**](https://datatracker.ietf.org/doc/html/rfc3390.html) 允许初始拥塞窗口约为4 KBytes，这在许多环境中对应于3个段。最近，谷歌的研究人员提出了将初始窗口进一步增加到15
    KBytes [[DRC+2010]](../bibliography.html#drc-2010)。他们收集的测量数据显示，这种增加不会显著增加拥塞，但会显著减少短HTTP响应的延迟。不出所料，所选的初始窗口对应于搜索引擎的HTTP响应的平均大小。这种提出的修改已在
    [**RFC 6928**](https://datatracker.ietf.org/doc/html/rfc6928.html) 中被采用，并且TCP实现支持它。
- en: Controlling congestion without losing data[#](#controlling-congestion-without-losing-data
    "Link to this heading")
  id: totrans-318
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 无数据丢失地控制拥塞[#](#controlling-congestion-without-losing-data "链接到这个标题")
- en: In today’s Internet, congestion is controlled by regularly sending packets at
    a higher rate than the network capacity. These packets fill the buffers of the
    routers and are eventually discarded. But shortly after, TCP senders retransmit
    packets containing exactly the same data. This is potentially a waste of resources
    since these successive retransmissions consume resources upstream of the router
    that discards the packets. Packet losses are not the only signal to detect congestion
    inside the network. An alternative is to allow routers to explicitly indicate
    their current level of congestion when forwarding packets. This approach was proposed
    in the late 1980s [[RJ1995]](../bibliography.html#rj1995) and used in some networks.
    Unfortunately, it took almost a decade before the Internet community agreed to
    consider this approach. In the mean time, a large number of TCP implementations
    and routers were deployed on the Internet.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 在今天的互联网中，通过定期以高于网络容量的速率发送数据包来控制拥塞。这些数据包填满了路由器的缓冲区，最终被丢弃。但不久之后，TCP发送者会重新发送包含完全相同数据的数据包。这可能导致资源的浪费，因为这些连续的重传消耗了丢弃数据包的路由器上游的资源。数据包丢失并不是检测网络内部拥塞的唯一信号。一种替代方案是允许路由器在转发数据包时明确地指示其当前的拥塞水平。这种方法在20世纪80年代末被提出
    [[RJ1995]](../bibliography.html#rj1995) 并在一些网络中使用。不幸的是，在互联网社区几乎经过十年才同意考虑这种方法。在此期间，大量的TCP实现和路由器被部署在互联网上。
- en: As explained earlier, Explicit Congestion Notification [**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)
    improves the detection of congestion by allowing routers to explicitly mark packets
    when they are lightly congested. In theory, a single bit in the packet header
    [[RJ1995]](../bibliography.html#rj1995) is sufficient to support this congestion
    control scheme. When a host receives a marked packet, it returns the congestion
    information to the source that adapts its transmission rate accordingly. Although
    the idea is relatively simple, deploying it on the entire Internet has proven
    to be challenging [[KNT2013]](../bibliography.html#knt2013). It is interesting
    to analyze the different factors that have hindered the deployment of this technique.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，显式拥塞通知 [**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)
    通过允许路由器在轻微拥塞时明确标记数据包来提高拥塞检测。理论上，数据包头部的一个比特 [[RJ1995]](../bibliography.html#rj1995)
    就足以支持这种拥塞控制方案。当主机收到标记的数据包时，它会将拥塞信息返回给源主机，源主机据此调整其传输速率。尽管这个想法相对简单，但在整个互联网上部署它已被证明是具有挑战性的
    [[KNT2013]](../bibliography.html#knt2013)。分析阻碍这种技术部署的不同因素是很有趣的。
- en: The first difficulty in adding Explicit Congestion Notification (ECN) in TCP/IP
    network was to modify the format of the network packet and transport segment headers
    to carry the required information. In the network layer, one bit was required
    to allow the routers to mark the packets they forward during congestion periods.
    In the IP network layer, this bit is called the Congestion Experienced (CE) bit
    and is part of the packet header. However, using a single bit to mark packets
    is not sufficient. Consider a simple scenario with two sources, one congested
    router and one destination. Assume that the first sender and the destination support
    ECN, but not the second sender. If the router is congested it will mark packets
    from both senders. The first sender will react to the packet markings by reducing
    its transmission rate. However since the second sender does not support ECN, it
    will not react to the markings. Furthermore, this sender could continue to increase
    its transmission rate, which would lead to more packets being marked and the first
    source would decrease again its transmission rate, … In the end, the sources that
    implement ECN are penalized compared to the sources that do not implement it.
    This unfairness issue is a major hurdle to widely deploy ECN on the public Internet
    [[8]](#fprivate). The solution proposed in [**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)
    to deal with this problem is to use a second bit in the network packet header.
    This bit, called the ECN-capable transport (ECT) bit, indicates whether the packet
    contains a segment produced by a transport protocol that supports ECN or not.
    Transport protocols that support ECN set the ECT bit in all packets. When a router
    is congested, it first verifies whether the ECT bit is set. In this case, the
    CE bit of the packet is set to indicate congestion. Otherwise, the packet is discarded.
    This eases the deployment of ECN [[9]](#fecnnonce).
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 在 TCP/IP 网络中添加显式拥塞通知 (ECN) 的第一个困难是修改网络数据包和传输段头的格式以携带所需的信息。在网络层，需要一个位来允许路由器在拥塞期间标记它们转发的数据包。在
    IP 网络层，这个位被称为拥塞经历 (CE) 位，是数据包头部的一部分。然而，使用单个位来标记数据包是不够的。考虑一个有两个源、一个拥塞路由器和目的地简单的场景。假设第一个发送器和目的地支持
    ECN，但第二个发送器不支持。如果路由器拥塞，它将标记来自两个发送器的数据包。第一个发送器将通过降低其传输速率来对数据包标记做出反应。然而，由于第二个发送器不支持
    ECN，它不会对标记做出反应。此外，这个发送器可能会继续增加其传输速率，这将导致更多数据包被标记，第一个源将再次降低其传输速率，……最终，实现 ECN 的源与未实现
    ECN 的源相比会受到惩罚。这个问题的不公平性是广泛部署 ECN 在公共互联网上的主要障碍 [[8]](#fprivate)。[**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)
    中提出的解决这个问题的方案是在网络数据包头部使用第二个位。这个位被称为 ECN 兼容传输 (ECT) 位，表示数据包是否包含由支持 ECN 的传输协议产生的段。支持
    ECN 的传输协议在所有数据包中设置 ECT 位。当路由器拥塞时，它首先验证 ECT 位是否设置。在这种情况下，数据包的 CE 位被设置为指示拥塞。否则，数据包将被丢弃。这简化了
    ECN 的部署 [[9]](#fecnnonce)。
- en: 'The second difficulty is how to allow the receiver to inform the sender of
    the reception of network packets marked with the CE bit. In reliable transport
    protocols like TCP and SCTP, the acknowledgments can be used to provide this feedback.
    For TCP, two options were possible : change some bits in the TCP segment header
    or define a new TCP option to carry this information. The designers of ECN opted
    for reusing spare bits in the TCP header. More precisely, two TCP flags have been
    added in the TCP header to support ECN. The ECN-Echo (ECE) is set in the acknowledgments
    when the CE was set in packets received on the forward path.'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个困难是如何让接收方通知发送方已接收带有 CE 位标记的网络数据包。在像 TCP 和 SCTP 这样的可靠传输协议中，可以通过确认来提供这种反馈。对于
    TCP 来说，有两种可能的选择：改变 TCP 段头中的某些位或定义一个新的 TCP 选项来携带这些信息。ECN 的设计者选择了在 TCP 头部重新使用空闲位。更确切地说，TCP
    头部中增加了两个标志来支持 ECN。当在正向路径上接收到的数据包中的 CE 位被设置时，ECN-Echo (ECE) 标志会在确认中设置。
- en: '[![../_images/tcp-enc.svg](../Images/0b92b95f1c0dadde63905a28574e87cb.png)](../_images/tcp-enc.svg)'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/tcp-enc.svg](../Images/0b92b95f1c0dadde63905a28574e87cb.png)'
- en: Fig. 225 The TCP flags[#](#id111 "Link to this image")
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 图 225 TCP 标志[#](#id111 "链接到这张图片")
- en: The third difficulty is to allow an ECN-capable sender to detect whether the
    remote host also supports ECN. This is a classical negotiation of extensions to
    a transport protocol. In TCP, this could have been solved by defining a new TCP
    option used during the three-way handshake. To avoid wasting space in the TCP
    options, the designers of ECN opted in [**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)
    for using the ECN-Echo and CWR bits in the TCP header to perform this negotiation.
    In the end, the result is the same with fewer bits exchanged.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个困难是允许一个支持 ECN 的发送者检测远程主机是否也支持 ECN。这是一个经典的传输协议扩展协商。在 TCP 中，这可以通过在三次握手期间定义一个新的
    TCP 选项来解决。为了避免在 TCP 选项中浪费空间，ECN 的设计者在 [**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)
    中选择了使用 TCP 头部的 ECN-Echo 和 CWR 位来进行这种协商。最终，结果是相同的，但交换的位数更少。
- en: Thanks to the ECT, CE and ECE, routers can mark packets during congestion and
    receivers can return the congestion information back to the TCP senders. However,
    these three bits are not sufficient to allow a server to reliably send the ECE
    bit to a TCP sender. TCP acknowledgments are not sent reliably. A TCP acknowledgment
    always contains the next expected sequence number. Since TCP acknowledgments are
    cumulative, the loss of one acknowledgment is recovered by the correct reception
    of a subsequent acknowledgment.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 多亏了 ECT、CE 和 ECE，路由器可以在拥塞期间标记数据包，接收器可以将拥塞信息返回给 TCP 发送者。然而，这三个位不足以让服务器可靠地向 TCP
    发送者发送 ECE 位。TCP 确认不是可靠发送的。TCP 确认总是包含下一个期望的序列号。由于 TCP 确认是累积的，一个确认的丢失可以通过后续正确接收的确认来恢复。
- en: If TCP acknowledgments are overloaded to carry the ECE bit, the situation is
    different. Consider the example shown in the figure below. A client sends packets
    to a server through a router. In the example below, the first packet is marked.
    The server returns an acknowledgment with the ECE bit set. Unfortunately, this
    acknowledgment is lost and never reaches the client. Shortly after, the server
    sends a data segment that also carries a cumulative acknowledgment. This acknowledgment
    confirms the reception of the data to the client, but it did not receive the congestion
    information through the ECE bit.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 如果将 TCP 确认过载用于携带 ECE 位，情况就不同了。考虑下面图中的示例。一个客户端通过路由器向服务器发送数据包。在下面的示例中，第一个数据包被标记。服务器返回一个设置了
    ECE 位的确认。不幸的是，这个确认丢失了，并且从未到达客户端。不久之后，服务器发送了一个也携带累积确认的数据段。这个确认确认了数据已到达客户端，但它没有通过
    ECE 位接收到拥塞信息。
- en: '![msc {'
  id: totrans-328
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![msc {'
- en: client [label="client", linecolour=black],
  id: totrans-329
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 客户端 [label="客户端", linecolour=black],
- en: router [label="router", linecolour=black],
  id: totrans-330
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 路由器 [label="路由器", linecolour=black],
- en: server [label="server", linecolour=black];
  id: totrans-331
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 服务器 [label="服务器", linecolour=black];
- en: ''
  id: totrans-332
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: client=>router [ label = "data[seq=1,ECT=1,CE=0]", arcskip="1" ];
  id: totrans-333
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 客户端=>路由器 [ label = "data[seq=1,ECT=1,CE=0]", arcskip="1" ];
- en: router=>server [ label = "data[seq=1,ECT=1,CE=1]", arcskip="1"];
  id: totrans-334
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 路由器=>服务器 [ label = "data[seq=1,ECT=1,CE=1]", arcskip="1"];
- en: '|||;'
  id: totrans-335
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '|||;'
- en: server=>router [ label = "ack=2,ECE=1", arcskip="1" ];
  id: totrans-336
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 服务器=>路由器 [ label = "ack=2,ECE=1", arcskip="1" ];
- en: router -x client [label="ack=2,ECE=1", arcskip="1" ];
  id: totrans-337
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 路由器 -x 客户端 [label="ack=2,ECE=1", arcskip="1" ];
- en: '|||;'
  id: totrans-338
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '|||;'
- en: server=>router [ label = "data[seq=x,ack=2,ECE=0,ECT=1,CE=0]", arcskip="1" ];
  id: totrans-339
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 服务器=>路由器 [ label = "data[seq=x,ack=2,ECE=0,ECT=1,CE=0]", arcskip="1" ];
- en: router=>client [ label = "data[seq=x,ack=2,ECE=0,ECT=1,CE=0]", arcskip="1"];
  id: totrans-340
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 路由器=>客户端 [ label = "data[seq=x,ack=2,ECE=0,ECT=1,CE=0]", arcskip="1"];
- en: '|||;'
  id: totrans-341
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '|||;'
- en: client->server [linecolour=white];
  id: totrans-342
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 客户端->服务器 [linecolour=white];
- en: '}](../Images/d2ed1589241adeb9e699082587d1916d.png)<map id="700c52eed1dd99ea5abd5216ffd2e044e6fee931"
    name="700c52eed1dd99ea5abd5216ffd2e044e6fee931"></map>'
  id: totrans-343
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '}](../Images/d2ed1589241adeb9e699082587d1916d.png)<map id="700c52eed1dd99ea5abd5216ffd2e044e6fee931"
    name="700c52eed1dd99ea5abd5216ffd2e044e6fee931"></map>'
- en: 'To solve this problem, [**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)
    uses an additional bit in the TCP header : the Congestion Window Reduced (CWR)
    bit.'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，[**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)
    在 TCP 头部中使用了额外的位：拥塞窗口减少 (CWR) 位。
- en: '![msc {'
  id: totrans-345
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![msc {'
- en: client [label="client", linecolour=black],
  id: totrans-346
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 客户端 [label="客户端", linecolour=black],
- en: router [label="router", linecolour=black],
  id: totrans-347
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 路由器 [label="路由器", linecolour=black],
- en: server [label="server", linecolour=black];
  id: totrans-348
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 服务器 [label="服务器", linecolour=black];
- en: client=>router [ label = "data[seq=1,ECT=1,CE=0]", arcskip="1" ];
  id: totrans-349
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 客户端=>路由器 [ label = "data[seq=1,ECT=1,CE=0]", arcskip="1" ];
- en: router=>server [ label = "data[seq=1,ECT=1,CE=1]", arcskip="1"];
  id: totrans-350
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 路由器=>服务器 [ label = "data[seq=1,ECT=1,CE=1]", arcskip="1"];
- en: '|||;'
  id: totrans-351
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '|||;'
- en: server=>router [ label = "ack=2,ECE=1", arcskip="1" ];
  id: totrans-352
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 服务器=>路由器 [ label = "ack=2,ECE=1", arcskip="1" ];
- en: router -x client [label="ack=2,ECE=1", arcskip="1" ];
  id: totrans-353
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 路由器 -x 客户端 [label="ack=2,ECE=1", arcskip="1" ];
- en: '|||;'
  id: totrans-354
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '|||;'
- en: server=>router [ label = "data[seq=x,ack=2,ECE=1,ECT=1,CE=0]", arcskip="1" ];
  id: totrans-355
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: server=>router [ label = "data[seq=x,ack=2,ECE=1,ECT=1,CE=0]", arcskip="1" ];
- en: router=>client [ label = "data[seq=x,ack=2,ECE=1,ECT=1,CE=0]", arcskip="1"];
  id: totrans-356
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: router=>client [ label = "data[seq=x,ack=2,ECE=1,ECT=1,CE=0]", arcskip="1"];
- en: '|||;'
  id: totrans-357
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '|||;'
- en: client=>router [ label = "data[seq=1,ECT=1,CE=0,CWR=1]", arcskip="1" ];
  id: totrans-358
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: client=>router [ label = "data[seq=1,ECT=1,CE=0,CWR=1]", arcskip="1" ];
- en: router=>server [ label = "data[seq=1,ECT=1,CE=1,CWR=1]", arcskip="1"];
  id: totrans-359
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: router=>server [ label = "data[seq=1,ECT=1,CE=1,CWR=1]", arcskip="1"];
- en: '|||;'
  id: totrans-360
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '|||;'
- en: client->server [linecolour=white];
  id: totrans-361
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: client->server [linecolour=white];
- en: '}](../Images/36533b7c4d47ba50cac29ebf6ebcc1f1.png)<map id="d60c580a7379dbdd26f90fd2eead54f832ee6ad6"
    name="d60c580a7379dbdd26f90fd2eead54f832ee6ad6"></map>'
  id: totrans-362
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '}](../Images/36533b7c4d47ba50cac29ebf6ebcc1f1.png)<map id="d60c580a7379dbdd26f90fd2eead54f832ee6ad6"
    name="d60c580a7379dbdd26f90fd2eead54f832ee6ad6"></map>'
- en: The CWR bit of the TCP header provides some form of acknowledgment for the ECE
    bit. When a TCP receiver detects a packet marked with the CE bit, it sets the
    ECE bit in all segments that it returns to the sender. Upon reception of an acknowledgment
    with the ECE bit set, the sender reduces its congestion window to reflect a mild
    congestion and sets the CWR bit. This bit remains set as long as the segments
    received contained the ECE bit set. A sender should only react once per round-trip-time
    to marked packets.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: TCP头部的CWR位为ECE位提供了一种确认形式。当TCP接收方检测到标记了CE位的分组时，它会将其返回给发送方的所有段中的ECE位置位。在收到ECE位已置位的确认后，发送方将其拥塞窗口减少以反映轻微的拥塞，并设置CWR位。只要接收到的段包含已置位的ECE位，此位将保持置位状态。发送方应仅对每个往返时间标记的分组做出一次反应。
- en: 'The last point that needs to be discussed about Explicit Congestion Notification
    is the algorithm that is used by routers to detect congestion. On a router, congestion
    manifests itself by the number of packets that are stored inside the router buffers.
    As explained earlier, we need to distinguish between two types of routers :'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 需要讨论的最后一个关于显式拥塞通知的问题是路由器用于检测拥塞的算法。在路由器上，拥塞通过路由器缓冲区中存储的分组数量来体现。如前所述，我们需要区分两种类型的路由器：
- en: routers that have a single FIFO queue
  id: totrans-365
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有单个FIFO队列的路由器
- en: ''
  id: totrans-366
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-367
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: routers that have several queues served by a round-robin scheduler
  id: totrans-368
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由轮询调度器服务的具有多个队列的路由器
- en: Routers that use a single queue measure their buffer occupancy as the number
    of bytes of packets stored in the queue [[10]](#fslot). A first method to detect
    congestion is to measure the instantaneous buffer occupancy and consider the router
    to be congested as soon as this occupancy is above a threshold. Typical values
    of the threshold could be 40% of the total buffer. Measuring the instantaneous
    buffer occupancy is simple since it only requires one counter. However, this value
    is fragile from a control viewpoint since it changes frequently. A better solution
    is to measure the *average* buffer occupancy and consider the router to be congested
    when this average occupancy is too high. Random Early Detection (RED) [[FJ1993]](../bibliography.html#fj1993)
    is an algorithm that was designed to support Explicit Congestion Notification.
    In addition to measuring the average buffer occupancy, it also uses probabilistic
    marking. When the router is congested, the arriving packets are marked with a
    probability that increases with the average buffer occupancy. The main advantage
    of using probabilistic marking instead of marking all arriving packets is that
    flows will be marked in proportion of the number of packets that they transmit.
    If the router marks 10% of the arriving packets when congested, then a large flow
    that sends hundred packets per second will be marked 10 times while a flow that
    only sends one packet per second will not be marked. This probabilistic marking
    allows marking packets in proportion of their usage of the network resources.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 使用单个队列的路由器将它们的缓冲区占用率测量为队列中存储的数据包字节数 [[10]](#fslot)。检测拥塞的一种方法是测量瞬时的缓冲区占用率，一旦这个占用率超过一个阈值，就认为路由器发生了拥塞。阈值的典型值可能是总缓冲区的40%。测量瞬时的缓冲区占用率很简单，因为它只需要一个计数器。然而，从控制的角度来看，这个值是脆弱的，因为它会频繁变化。一个更好的解决方案是测量*平均*缓冲区占用率，并在这个平均占用率过高时认为路由器发生了拥塞。随机早期检测（RED）[[FJ1993]](../bibliography.html#fj1993)
    是一个设计用来支持显式拥塞通知的算法。除了测量平均缓冲区占用率外，它还使用概率标记。当路由器拥塞时，到达的数据包会以随着平均缓冲区占用率增加的概率被标记。使用概率标记而不是标记所有到达的数据包的主要优点是，流量将被按它们传输的数据包数量成比例地标记。如果路由器在拥塞时标记了10%的到达数据包，那么每秒发送一百个数据包的大流量将被标记10次，而每秒只发送一个数据包的流量则不会被标记。这种概率标记允许按数据包对网络资源使用的比例进行标记。
- en: If the router uses several queues served by a scheduler, the situation is different.
    If a large and a small flow are competing for bandwidth, the scheduler will already
    favor the small flow that is not using its fair share of the bandwidth. The queue
    for the small flow will be almost empty while the queue for the large flow will
    build up. On routers using such schedulers, a good way of marking the packets
    is to set a threshold on the occupancy of each queue and mark the packets that
    arrive in a particular queue as soon as its occupancy is above the configured
    threshold.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 如果路由器使用由调度器服务的多个队列，情况就不同了。如果一个大型流量和一个小型流量在争夺带宽，调度器已经会偏向于使用带宽份额不足的小流量。小型流量的队列几乎会空，而大型流量的队列则会逐渐增加。在采用此类调度器的路由器上，标记数据包的一个好方法是设置每个队列的占用率阈值，并在特定队列的占用率超过配置的阈值时立即标记到达该队列的数据包。
- en: Modeling TCP congestion control[#](#modeling-tcp-congestion-control "Link to
    this heading")
  id: totrans-371
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模拟TCP拥塞控制[#](#modeling-tcp-congestion-control "链接到这个标题")
- en: Thanks to its congestion control scheme, TCP adapts its transmission rate to
    the losses that occur in the network. Intuitively, the TCP transmission rate decreases
    when the percentage of losses increases. Researchers have proposed detailed models
    that allow the prediction of the throughput of a TCP connection when losses occur
    [[MSMO1997]](../bibliography.html#msmo1997) . To have some intuition about the
    factors that affect the performance of TCP, let us consider a very simple model.
    Its assumptions are not completely realistic, but it gives us good intuition without
    requiring complex mathematics.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其拥塞控制方案，TCP会根据网络中发生的损失来调整其传输速率。直观地说，当损失百分比增加时，TCP的传输速率会降低。研究人员已经提出了详细的模型，允许预测TCP连接在发生损失时的吞吐量
    [[MSMO1997]](../bibliography.html#msmo1997)。为了对影响TCP性能的因素有所了解，让我们考虑一个非常简单的模型。它的假设并不完全现实，但它能给我们良好的直觉，而不需要复杂的数学。
- en: This model considers a hypothetical TCP connection that suffers from equally
    spaced segment losses. If \(p\) is the segment loss ratio, then the TCP connection
    successfully transfers \(\frac{1}{p}-1\) segments and the next segment is lost.
    If we ignore the slow-start at the beginning of the connection, TCP in this environment
    is always in congestion avoidance as there are only isolated losses that can be
    recovered by using fast retransmit. The evolution of the congestion window is
    thus as shown in the figure below. Note that the x-axis of this figure represents
    time measured in units of one round-trip-time, which is supposed to be constant
    in the model, and the y-axis represents the size of the congestion window measured
    in MSS-sized segments.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型考虑了一个假设的TCP连接，该连接遭受均匀分布的段丢失。如果 \(p\) 是段丢失率，那么TCP连接成功传输 \(\frac{1}{p}-1\)
    个段，下一个段丢失。如果我们忽略连接开始时的慢启动，由于只有可以通过快速重传恢复的孤立丢失，因此在此环境中TCP始终处于拥塞避免状态。因此，拥塞窗口的演变如图所示。请注意，该图的x轴表示以往返时间为单位的测量时间，在模型中应保持恒定，而y轴表示以MSS大小的段为单位的拥塞窗口大小。
- en: '[![../_images/tcp-congestion-regular.png](../Images/aba5ecafe63f482ae07b7a280f8f3275.png)](../_images/tcp-congestion-regular.png)'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: '[![../_images/tcp-congestion-regular.png](../Images/aba5ecafe63f482ae07b7a280f8f3275.png)](../_images/tcp-congestion-regular.png)'
- en: Fig. 226 Evolution of the congestion window with regular losses[#](#id112 "Link
    to this image")
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 图226：规律性丢失下的拥塞窗口演变[#](#id112 "链接到这张图片")
- en: 'As the losses are equally spaced, the congestion window always starts at some
    value (\(\frac{W}{2}\)), and is incremented by one MSS every round-trip-time until
    it reaches twice this value (W). At this point, a segment is retransmitted and
    the cycle starts again. If the congestion window is measured in MSS-sized segments,
    a cycle lasts \(\frac{W}{2}\) round-trip-times. The bandwidth of the TCP connection
    is the number of bytes that have been transmitted during a given period of time.
    During a cycle, the number of segments that are sent on the TCP connection is
    equal to the area of the yellow trapeze in the figure. Its area is thus :'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 由于丢失是均匀分布的，拥塞窗口始终从某个值（\(\frac{W}{2}\)）开始，并在每个往返时间增加一个MSS，直到达到这个值的两倍（W）。此时，一个段被重传，周期重新开始。如果以MSS大小的段来衡量拥塞窗口，一个周期持续
    \(\frac{W}{2}\) 个往返时间。TCP连接的带宽是在给定时间段内已传输的字节数。在一个周期内，TCP连接上发送的段数等于图中黄色梯形的面积。因此，其面积为：
- en: \(area=(\frac{W}{2})^2 + \frac{1}{2} \times (\frac{W}{2})^2 = \frac{3 \times
    W^2}{8}\)
  id: totrans-377
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: \(area=(\frac{W}{2})^2 + \frac{1}{2} \times (\frac{W}{2})^2 = \frac{3 \times
    W^2}{8}\)
- en: 'However, given the regular losses that we consider, the number of segments
    that are sent between two losses (i.e. during a cycle) is by definition equal
    to \(\frac{1}{p}\). Thus, \(W=\sqrt{\frac{8}{3 \times p}}=\frac{k}{\sqrt{p}}\).
    The throughput (in bytes per second) of the TCP connection is equal to the number
    of segments transmitted divided by the duration of the cycle :'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，考虑到我们考虑的规律性丢失，两个丢失之间的段数（即在周期内）根据定义等于 \(\frac{1}{p}\)。因此，\(W=\sqrt{\frac{8}{3
    \times p}}=\frac{k}{\sqrt{p}}\)。TCP连接的吞吐量（以每秒字节数表示）等于传输的段数除以周期持续时间：
- en: \(Throughput=\frac{area \times MSS}{time} = \frac{ \frac{3 \times W^2}{8}}{\frac{W}{2}
    \times rtt}\) or, after having eliminated W, \(Throughput=\sqrt{\frac{3}{2}} \times
    \frac{MSS}{rtt \times \sqrt{p}}\)
  id: totrans-379
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: \(Throughput=\frac{area \times MSS}{time} = \frac{ \frac{3 \times W^2}{8}}{\frac{W}{2}
    \times rtt}\) 或者，在消除W之后，\(Throughput=\sqrt{\frac{3}{2}} \times \frac{MSS}{rtt
    \times \sqrt{p}}\)
- en: 'More detailed models and the analysis of simulations have shown that a first
    order model of the TCP throughput when losses occur was \(Throughput \approx \frac{k
    \times MSS}{rtt \times \sqrt{p}}\). This is an important result which shows that
    :'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 更详细的模型和模拟分析表明，当发生丢包时，TCP吞吐量的首阶模型为 \(Throughput \approx \frac{k \times MSS}{rtt
    \times \sqrt{p}}\)。这是一个重要的结果，它表明：
- en: TCP connections with a small round-trip-time can achieve a higher throughput
    than TCP connections having a longer round-trip-time when losses occur. This implies
    that the TCP congestion control scheme is not completely fair since it favors
    the connections that have the shorter round-trip-times.
  id: totrans-381
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当发生丢包时，具有较短往返时间的TCP连接可以比具有较长往返时间的TCP连接实现更高的吞吐量。这表明TCP拥塞控制方案并不完全公平，因为它有利于具有较短的往返时间的连接。
- en: ''
  id: totrans-382
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-383
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: TCP connections that use a large MSS can achieve a higher throughput that the
    TCP connections that use a shorter MSS. This creates another source of unfairness
    between TCP connections. However, it should be noted that today most hosts are
    using almost the same MSS, roughly 1460 bytes.
  id: totrans-384
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用较大MSS的TCP连接可以比使用较短MSS的TCP连接实现更高的吞吐量。这为TCP连接之间又增加了不平等的一个来源。然而，需要注意的是，如今大多数主机几乎都使用相同大小的MSS，大约为1460字节。
- en: In general, the maximum throughput that can be achieved by a TCP connection
    depends on its maximum window size and the round-trip-time if there are no losses.
    If there are losses, it depends on the MSS, the round-trip-time and the loss ratio.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，TCP连接能够达到的最大吞吐量取决于其最大窗口大小和往返时间，如果没有丢失。如果有丢失，则取决于MSS、往返时间和丢失率。
- en: \(Throughput<\min(\frac{window}{rtt},\frac{k \times MSS}{rtt \times \sqrt{p}})\)
  id: totrans-386
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: \(Throughput<\min(\frac{window}{rtt},\frac{k \times MSS}{rtt \times \sqrt{p}})\)
- en: Note
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The TCP congestion control zoo
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: TCP拥塞控制动物园
- en: 'The first TCP congestion control scheme was proposed by [Van Jacobson](https://en.wikipedia.org/wiki/Van_Jacobson)
    in [[Jacobson1988]](../bibliography.html#jacobson1988). In addition to writing
    the scientific paper, [Van Jacobson](https://en.wikipedia.org/wiki/Van_Jacobson)
    also implemented the slow-start and congestion avoidance schemes in release 4.3
    Tahoe of the BSD Unix distributed by the University of Berkeley. Later, he improved
    the congestion control by adding the fast retransmit and the fast recovery mechanisms
    in the Reno release of 4.3 BSD Unix. Since then, many researchers have proposed,
    simulated and implemented modifications to the TCP congestion control scheme.
    Some of these modifications are still used today, e.g. :'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个TCP拥塞控制方案是由[Van Jacobson](https://en.wikipedia.org/wiki/Van_Jacobson)在[[Jacobson1988]](../bibliography.html#jacobson1988)提出的。除了撰写科学论文外，[Van
    Jacobson](https://en.wikipedia.org/wiki/Van_Jacobson)还在伯克利大学分发的BSD Unix的4.3 Tahoe版本中实现了慢启动和拥塞避免方案。后来，他在4.3
    BSD Unix的Reno版本中通过添加快速重传和快速恢复机制来改进拥塞控制。从那时起，许多研究人员提出了、模拟并实现了对TCP拥塞控制方案的修改。其中一些修改至今仍在使用，例如：
- en: NewReno ([**RFC 3782**](https://datatracker.ietf.org/doc/html/rfc3782.html)),
    which was proposed as an improvement of the fast recovery mechanism in the Reno
    implementation.
  id: totrans-390
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: NewReno([**RFC 3782**](https://datatracker.ietf.org/doc/html/rfc3782.html))，它被提出作为Reno实现中快速恢复机制的改进。
- en: ''
  id: totrans-391
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-392
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: TCP Vegas, which uses changes in the round-trip-time to estimate congestion
    in order to avoid it [[BOP1994]](../bibliography.html#bop1994). This is one of
    the examples of the delay-based congestion control algorithms. A Vegas sender
    continuously measures the evolution of the round-trip-time and slows down when
    the round-trip-time increases significantly. This enables Vegas to prevent congestion
    when used alone. Unfortunately, if Vegas senders compete with more aggressive
    TCP congestion control schemes that only react to losses, Vegas senders may have
    difficulties to use their fair share of the available bandwidth.
  id: totrans-393
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: TCP Vegas使用往返时间的变化来估计拥塞以避免它[[BOP1994]](../bibliography.html#bop1994)。这是基于延迟的拥塞控制算法的一个例子。Vegas发送器持续测量往返时间的演变，并在往返时间显著增加时减速。这使得Vegas在单独使用时能够防止拥塞。不幸的是，如果Vegas发送器与仅对丢失做出反应的更具侵略性的TCP拥塞控制方案竞争，Vegas发送器可能难以使用其应有的带宽份额。
- en: ''
  id: totrans-394
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-395
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: CUBIC, which was designed for high bandwidth links and is the default congestion
    control scheme in Linux since the Linux 2.6.19 kernel [[HRX2008]](../bibliography.html#hrx2008).
    It is now used by several operating systems and is becoming the default congestion
    control scheme [**RFC 8312**](https://datatracker.ietf.org/doc/html/rfc8312.html).
    A key difference between CUBIC and the TCP congestion control scheme described
    in this chapter is that CUBIC is much more aggressive when probing the network.
    Instead of relying on additive increase after a fast recovery, a CUBIC sender
    adjusts its congestion by using a cubic function. Thanks to this function, the
    congestion windows grows faster. This is particularly important in high-bandwidth
    delay networks.
  id: totrans-396
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: CUBIC是为高带宽链路设计的，自Linux 2.6.19内核以来一直是Linux的默认拥塞控制方案[[HRX2008]](../bibliography.html#hrx2008)。现在它被几个操作系统使用，并正在成为默认的拥塞控制方案[**RFC
    8312**](https://datatracker.ietf.org/doc/html/rfc8312.html)。CUBIC与本章中描述的TCP拥塞控制方案的一个关键区别在于，CUBIC在探测网络时更为激进。它不是在快速恢复后依赖加性增长，而是通过使用立方函数来调整拥塞。多亏了这个函数，拥塞窗口增长得更快。这在高带宽延迟网络中尤为重要。
- en: ''
  id: totrans-397
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-398
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: BBR, which is being developed by Google researchers and is included in recent
    Linux kernels [[CCG+2016]](../bibliography.html#ccg-2016). BBR periodically estimates
    the available bandwidth and the round-trip-times. To adapt to changes in network
    conditions, BBR regularly tries to send at 1.25 times the current bandwidth. This
    enables BBR senders to probe the network, but can also cause large amount of losses.
    Recent scientific articles indicate that BBR is unfair to other congestion control
    schemes in specific conditions [[WMSS2019]](../bibliography.html#wmss2019).
  id: totrans-399
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: BBR是由谷歌研究人员开发并包含在最近的Linux内核中的技术[[CCG+2016]](../bibliography.html#ccg-2016)。BBR定期估计可用带宽和往返时间。为了适应网络条件的变化，BBR定期尝试以当前带宽的1.25倍发送数据。这使BBR发送者能够探测网络，但也可能导致大量损失。最近的科学文章表明，在特定条件下，BBR对其他拥塞控制方案是不公平的[[WMSS2019]](../bibliography.html#wmss2019)。
- en: A wide range of congestion control schemes have been proposed in the scientific
    literature and several of them have been widely deployed. A detailed comparison
    of these congestion control schemes is outside the scope of this chapter. A recent
    survey paper describing many of the implemented TCP congestion control schemes
    may be found in [[TKU2019]](../bibliography.html#tku2019).
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 在科学文献中已经提出了多种拥塞控制方案，其中一些已经被广泛部署。这些拥塞控制方案的详细比较超出了本章的范围。一篇最近的研究综述描述了许多已实现的TCP拥塞控制方案，可以在[[TKU2019]](../bibliography.html#tku2019)中找到。
- en: Footnotes
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 脚注
- en: Footnotes
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 脚注
- en: Sharing bandwidth[#](#sharing-bandwidth "Link to this heading")
  id: totrans-403
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分享带宽[#](#sharing-bandwidth "链接到这个标题")
- en: In all these networks, except the full-mesh, the link bandwidth is shared among
    all connected hosts. Various algorithms have been proposed and are used to efficiently
    share the access to this resource. We explain several of them in the Medium Access
    Control section below.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有这些网络中，除了全网状网络外，链路带宽被所有连接的主机共享。已经提出了各种算法，并用于有效地共享对这一资源的访问。我们将在下面的介质访问控制部分解释其中的一些。
- en: Note
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 注释
- en: Fairness in computer networks
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机网络中的公平性
- en: Sharing resources is important to ensure that the network efficiently serves
    its user. In practice, there are many ways to share resources. Some resource sharing
    schemes consider that some users are more important than others and should obtain
    more resources. For example, on the roads, police cars and ambulances have priority.
    In some cities, traffic lanes are reserved for buses to promote public services,
    … In computer networks, the same problem arise. Given that resources are limited,
    the network needs to enable users to efficiently share them. Before designing
    an efficient resource sharing scheme, one needs to first formalize its objectives.
    In computer networks, the most popular objective for resource sharing schemes
    is that they must be fair. In a simple situation, for example two hosts using
    a shared 2 Mbps link, the sharing scheme should allocate the same bandwidth to
    each user, in this case 1 Mbps. However, in a large networks, simply dividing
    the available resources by the number of users is not sufficient. Consider the
    network shown in the figure below where A1 sends data to A2, B1 to B2, … In this
    network, how should we divide the bandwidth among the different flows ? A first
    approach would be to allocate the same bandwidth to each flow. In this case, each
    flow would obtain 5 Mbps and the link between R2 and R3 would not be fully loaded.
    Another approach would be to allocate 10 Mbps to A1-A2, 20 Mbps to C1-C2 and nothing
    to B1-B2. This is clearly unfair.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 分享资源对于确保网络高效地为用户提供服务至关重要。在实践中，有许多共享资源的方法。一些资源共享方案认为某些用户比其他用户更重要，应该获得更多资源。例如，在道路上，警车和救护车有优先权。在一些城市，交通车道被保留给公交车以促进公共服务，……在计算机网络中，同样的问题也会出现。鉴于资源有限，网络需要使用户能够有效地共享资源。在设计一个有效的资源共享方案之前，首先需要形式化其目标。在计算机网络中，资源共享方案最流行的目标之一是它们必须是公平的。在简单的情况下，例如两个主机使用共享的2
    Mbps链路，资源共享方案应该为每个用户分配相同的带宽，在这种情况下为1 Mbps。然而，在大规模网络中，简单地按用户数量分配可用资源是不够的。考虑下面图中所示的网络，其中A1向A2发送数据，B1向B2发送，……在这个网络中，我们应该如何在不同流之间分配带宽？一种初步的方法是为每个流分配相同的带宽。在这种情况下，每个流将获得5
    Mbps，R2和R3之间的链路将不会完全负载。另一种方法是分配10 Mbps给A1-A2，20 Mbps给C1-C2，而B1-B2则不分配。这显然是不公平的。
- en: '![Figure made with TikZ](../Images/a92629ffc43cb0912e0548fff34a5038.png)'
  id: totrans-408
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用TikZ制作的图](../Images/a92629ffc43cb0912e0548fff34a5038.png)'
- en: ''
  id: totrans-409
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 192 A small network
  id: totrans-410
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图192 一个小网络
- en: In large networks, fairness is always a compromise. The most widely used definition
    of fairness is the max-min fairness. A bandwidth allocation in a network is said
    to be max-min fair if it is such that it is impossible to allocate more bandwidth
    to one of the flows without reducing the bandwidth of a flow that already has
    a smaller allocation than the flow that we want to increase. If the network is
    completely known, it is possible to derive a max-min fair allocation as follows.
    Initially, all flows have a null bandwidth and they are placed in the candidate
    set. The bandwidth allocation of all flows in the candidate set is increased until
    one link becomes congested. At this point, the flows that use the congested link
    have reached their maximum allocation. They are removed from the candidate set
    and the process continues until the candidate set becomes empty.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 在大型网络中，公平性总是需要妥协的。最广泛使用的公平性定义是最大最小公平性。如果一个网络的带宽分配是最大最小公平的，那么它意味着不可能在不减少比我们想要增加的流量分配更小的流量带宽的情况下，为其中一个流量分配更多的带宽。如果网络完全已知，可以推导出最大最小公平分配如下。最初，所有流量都有一个零带宽，并且它们被放置在候选集中。候选集中所有流量的带宽分配都会增加，直到一个链路变得拥塞。此时，使用拥塞链路的流量已达到最大分配。它们被从候选集中移除，然后继续这个过程，直到候选集变为空。
- en: In the above network, the allocation of all flows would grow until A1-A2 and
    B1-B2 reach 5 Mbps. At this point, link R1-R2 becomes congested and these two
    flows have reached their maximum. The allocation for flow C1-C2 can increase until
    reaching 15 Mbps. At this point, link R2-R3 is congested. To increase the bandwidth
    allocated to C1-C2, one would need to reduce the allocation to flow B1-B2. Similarly,
    the only way to increase the allocation to flow B1-B2 would require a decrease
    of the allocation to A1-A2.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述网络中，所有流量的分配会增长，直到A1-A2和B1-B2达到5 Mbps。此时，R1-R2链路变得拥塞，这两个流量已达到最大。C1-C2流量的分配可以增加，直到达到15
    Mbps。此时，R2-R3链路变得拥塞。要增加分配给C1-C2的带宽，需要减少分配给B1-B2的带宽。同样，增加B1-B2的分配的唯一方法需要减少A1-A2的分配。
- en: Network congestion[#](#network-congestion "Link to this heading")
  id: totrans-413
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 网络拥塞[#](#network-congestion "链接到本标题")
- en: Sharing bandwidth among the hosts directly attached to a link is not the only
    sharing problem that occurs in computer networks. To understand the general problem,
    let us consider a very simple network which contains only point-to-point links.
    This network contains three hosts and two routers. All the links inside the network
    have the same capacity. For example, let us assume that all links have a bandwidth
    of 1000 bits per second and that the hosts send packets containing exactly one
    thousand bits.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 在直接连接到链路的宿主机之间共享带宽并不是计算机网络中唯一出现的共享问题。为了理解一般问题，让我们考虑一个非常简单的网络，该网络只包含点对点链路。这个网络包含三个宿主机和两个路由器。网络内部的所有链路都有相同的容量。例如，让我们假设所有链路的带宽为每秒1000比特，并且宿主机发送包含恰好一千比特的数据包。
- en: '![Figure made with TikZ](../Images/f79da50c17973252bf5368a3df95f186.png)'
  id: totrans-415
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用TikZ制作的图](../Images/f79da50c17973252bf5368a3df95f186.png)'
- en: ''
  id: totrans-416
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 193 A small network
  id: totrans-417
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图193 一个小网络
- en: In the network above, consider the case where host A is transmitting packets
    to destination C. A can send one packet per second and its packets will be delivered
    to C. Now, let us explore what happens when host B also starts to transmit a packet.
    Node R1 will receive two packets that must be forwarded to R2. Unfortunately,
    due to the limited bandwidth on the R1-R2 link, only one of these two packets
    can be transmitted. The outcome of the second packet will depend on the available
    buffers on R1. If R1 has one available buffer, it could store the packet that
    has not been transmitted on the R1-R2 link until the link becomes available. If
    R1 does not have available buffers, then the packet needs to be discarded.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的网络中，考虑宿主机A向目的地C传输数据包的情况。A可以每秒发送一个数据包，并且其数据包将被送达C。现在，让我们探索当宿主机B也开始传输数据包时会发生什么。节点R1将接收到两个必须转发到R2的数据包。不幸的是，由于R1-R2链路上的带宽有限，只能传输这两个数据包中的一个。第二个数据包的结果将取决于R1上的可用缓冲区。如果R1有一个可用缓冲区，它可以存储在R1-R2链路上尚未传输的数据包，直到链路变得可用。如果没有可用缓冲区，则该数据包需要被丢弃。
- en: Besides the link bandwidth, the buffers on the network nodes are the second
    type of resource that needs to be shared inside the network. The node buffers
    play an important role in the operation of the network because that can be used
    to absorb transient traffic peaks. Consider again the example above. Assume that
    on average host A and host B send a group of three packets every ten seconds.
    Their combined transmission rate (0.6 packets per second) is, on average, lower
    than the network capacity (1 packet per second). However, if they both start to
    transmit at the same time, node R1 will have to absorb a burst of packets. This
    burst of packets is a small network congestion. We will say that a network is
    congested, when the sum of the traffic demand from the hosts is larger than the
    network capacity \(\sum{demand}>capacity\). This network congestion problem is
    one of the most difficult resource sharing problem in computer networks. Congestion
    occurs in almost all networks. Minimizing the amount of congestion is a key objective
    for many network operators. In most cases, they will have to accept transient
    congestion, i.e. congestion lasting a few seconds or perhaps minutes, but will
    want to prevent congestion that lasts days or months. For this, they can rely
    on a wide range of solutions. We briefly present some of these in the paragraphs
    below.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 除了链路带宽外，网络节点上的缓冲区是需要在网络内部共享的第二类资源。节点缓冲区在网络操作中扮演着重要角色，因为它们可以用来吸收瞬时的流量峰值。再次考虑上述例子。假设主机A和主机B平均每十秒发送一组三个数据包。它们的总传输速率（每秒0.6个数据包）平均低于网络容量（每秒1个数据包）。然而，如果它们同时开始传输，节点R1将不得不吸收一个数据包的突发。这个数据包的突发是一个小的网络拥塞。我们将说网络拥塞，当来自主机的总流量需求大于网络容量时
    \(\sum{demand}>capacity\)。这个网络拥塞问题是计算机网络中最难的资源共享问题之一。拥塞几乎发生在所有网络中。最小化拥塞量是许多网络运营商的关键目标。在大多数情况下，他们必须接受短暂的拥塞，即持续几秒或几分钟的拥塞，但他们会希望防止持续数天或数月的拥塞。为此，他们可以依赖一系列广泛的解决方案。我们将在下面的段落中简要介绍其中的一些。
- en: If R1 has enough buffers, it will be able to absorb the load without having
    to discard packets. The packets sent by hosts A and B will reach their final destination
    C, but will experience a longer delay than when they are transmitting alone. The
    amount of buffering on the network node is the first parameter that a network
    operator can tune to control congestion inside his network. Given the decreasing
    cost of memory, one could be tempted to put as many buffers [[1]](#fbufferbloat)
    as possible on the network nodes. Let us consider this case in the network above
    and assume that R1 has infinite buffers. Assume now that hosts A and B try to
    transmit a file that corresponds to one thousand packets each. Both are using
    a reliable protocol that relies on go-back-n to recover from transmission errors.
    The transmission starts and packets start to accumulate in R1’s buffers. The presence
    of these packets in the buffers increases the delay between the transmission of
    a packet by A and the return of the corresponding acknowledgment. Given the increasing
    delay, host A (and B as well) will consider that some of the packets that it sent
    have been lost. These packets will be retransmitted and will enter the buffers
    of R1. The occupancy of the buffers of R1 will continue to increase and the delays
    as well. This will cause new retransmissions, … In the end, only one file will
    be delivered (very slowly) to the destination, but the link R1-R2 will transfer
    much more bytes than the size of the file due to the multiple copies of the same
    packets. This is known as the congestion collapse problem [**RFC 896**](https://datatracker.ietf.org/doc/html/rfc896.html).
    Congestion collapse is the nightmare for network operators. When it happens, the
    network carries packets without delivering useful data to the end users.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 如果R1有足够的缓冲区，它将能够吸收负载而无需丢弃数据包。主机A和B发送的数据包将到达它们的最终目的地C，但将比单独传输时经历更长的延迟。网络节点上的缓冲区数量是网络运营商可以调整以控制其网络内部拥塞的第一个参数。鉴于内存成本的降低，人们可能会倾向于在网络节点上放置尽可能多的缓冲区
    [[1]](#fbufferbloat)。让我们考虑上述网络中的这种情况，并假设R1有无限的缓冲区。现在假设主机A和B尝试传输一个对应于一千个数据包的文件。两者都使用依赖回退N来恢复传输错误的可靠协议。传输开始，数据包开始积累在R1的缓冲区中。这些数据包在缓冲区中的存在增加了A（以及B）发送数据包和接收相应确认之间的延迟。鉴于延迟的增加，主机A（以及B）将认为它发送的一些数据包已经丢失。这些数据包将被重新传输并进入R1的缓冲区。R1缓冲区的占用将继续增加，延迟也是如此。这将导致新的重传，……最终，只有一个文件（非常慢地）被发送到目的地，但R1-R2链路将传输比文件大小更多的字节，因为相同数据包的多个副本。这被称为拥塞崩溃问题
    [**RFC 896**](https://datatracker.ietf.org/doc/html/rfc896.html)。拥塞崩溃是网络运营商的噩梦。当它发生时，网络携带数据包而不向最终用户传输有用数据。
- en: Note
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Congestion collapse on the Internet
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 互联网上的拥塞崩溃
- en: Congestion collapse is unfortunately not only an academic experience. Van Jacobson
    reports in [[Jacobson1988]](../bibliography.html#jacobson1988) one of these events
    that affected him while he was working at the Lawrence Berkeley Laboratory (LBL).
    LBL was two network nodes away from the University of California in Berkeley.
    At that time, the link between the two sites had a bandwidth of 32 Kbps, but some
    hosts were already attached to 10 Mbps LANs. “In October 1986, the data throughput
    from LBL to UC Berkeley … dropped from 32 Kbps to 40 bps. We were fascinated by
    this sudden factor-of-thousand drop in bandwidth and embarked on an investigation
    of why things had gotten so bad.” This work lead to the development of various
    congestion control techniques that have allowed the Internet to continue to grow
    without experiencing widespread congestion collapse events.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 拥塞崩溃不幸地不仅仅是一种学术经验。Van Jacobson在 [[Jacobson1988]](../bibliography.html#jacobson1988)
    中报告了这样一件事件，当时他在劳伦斯伯克利实验室（LBL）工作。LBL距离加州大学伯克利分校有两个网络节点。当时，两个站点之间的链路带宽为32 Kbps，但一些主机已经连接到10
    Mbps的局域网。 “1986年10月，从LBL到加州大学伯克利的……数据吞吐量从32 Kbps下降到40 bps。我们对这种带宽突然下降到千分之一的现象感到着迷，并开始调查为什么事情变得如此糟糕。”
    这项工作导致了各种拥塞控制技术的发展，这些技术使得互联网能够在不经历广泛的拥塞崩溃事件的情况下继续增长。
- en: Besides bandwidth and memory, a third resource that needs to be shared inside
    a network is the (packet) processing capacity. To forward a packet, a router needs
    bandwidth on the outgoing link, but it also needs to analyze the packet header
    to perform a lookup inside its forwarding table. Performing these lookup operations
    require resources such as CPU cycles or memory accesses. Routers are usually designed
    to be able to sustain a given packet processing rate, measured in packets per
    second [[2]](#fpps).
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 除了带宽和内存之外，网络内部需要共享的第三个资源是（数据包）处理能力。为了转发一个数据包，路由器需要在出链路上有带宽，但它还需要分析数据包头部以在其转发表中执行查找。执行这些查找操作需要资源，如CPU周期或内存访问。路由器通常设计为能够维持一定的数据包处理速率，以每秒数据包数来衡量
    [[2]](#fpps)。
- en: Note
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Packets per second versus bits per second
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 每秒数据包数与每秒比特数
- en: 'The performance of network nodes (either routers or switches) can be characterized
    by two key metrics :'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 网络节点（无论是路由器还是交换机）的性能可以通过两个关键指标来表征：
- en: the node’s capacity measured in bits per second
  id: totrans-428
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点的每秒比特数容量
- en: ''
  id: totrans-429
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-430
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: the node’s lookup performance measured in packets per second
  id: totrans-431
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点的每秒查找性能
- en: The node’s capacity in bits per second mainly depends on the physical interfaces
    that it uses and also on the capacity of the internal interconnection (bus, crossbar
    switch, …) between the different interfaces inside the node. Many vendors, in
    particular for low-end devices will use the sum of the bandwidth of the nodes’
    interfaces as the node capacity in bits per second. Measurements do not always
    match this maximum theoretical capacity. A well designed network node will usually
    have a capacity in bits per second larger than the sum of its link capacities.
    Such nodes will usually reach this maximum capacity when forwarding large packets.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 节点的每秒比特数容量主要取决于它所使用的物理接口，以及节点内部不同接口之间的内部互连（总线、交叉开关等）的容量。许多供应商，特别是对于低端设备，会将节点接口的带宽总和作为节点的每秒比特数容量。测量结果并不总是与这个最大理论容量相匹配。一个设计良好的网络节点通常其每秒比特数容量会大于其链路容量的总和。这样的节点通常在转发大型数据包时达到这个最大容量。
- en: When a network node forwards small packets, its performance is usually limited
    by the number of lookup operations that it can perform every second. This lookup
    performance is measured in packets per second. The performance may depend on the
    length of the forwarded packets. The key performance factor is the number of minimal
    size packets that are forwarded by the node every second. This rate can lead to
    a capacity in bits per second which is much lower than the sum of the bandwidth
    of the node’s links.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 当网络节点转发小型数据包时，其性能通常受限于它每秒可以执行查找操作的数量。这种查找性能以每秒数据包数来衡量。性能可能取决于转发数据包的长度。关键性能因素是节点每秒转发的最小尺寸数据包的数量。这个速率可能导致每秒比特数容量远低于节点链路带宽的总和。
- en: Let us now try to present a broad overview of the congestion problem in networks.
    We will assume that the network is composed of dedicated links having a fixed
    bandwidth [[3]](#fadjust). A network contains hosts that generate and receive
    packets and nodes (routers and switches) that forward packets. Assuming that each
    host is connected via a single link to the network, the largest demand is \(\sum{Access
    Links}\). In practice, this largest demand is never reached and the network will
    be engineered to sustain a much lower traffic demand. The difference between the
    worst-case traffic demand and the sustainable traffic demand can be large, up
    to several orders of magnitude. Fortunately, the hosts are not completely dumb
    and they can adapt their traffic demand to the current state of the network and
    the available bandwidth. For this, the hosts need to sense the current level of
    congestion and adjust their own traffic demand based on the estimated congestion.
    Network nodes can react in different ways to network congestion and hosts can
    sense the level of congestion in different ways.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们尝试对网络中的拥塞问题进行广泛的概述。我们将假设网络由具有固定带宽的专用链路组成[[3]](#fadjust)。网络包含生成和接收数据包的主机以及转发数据包的节点（路由器和交换机）。假设每个主机通过单个链路连接到网络，最大的需求是
    \(\sum{访问链路}\)。实际上，这个最大的需求永远不会达到，网络将被设计成能够承受远低于最大交通需求。最坏情况下的交通需求与可持续的交通需求之间的差异可能很大，高达几个数量级。幸运的是，主机并不完全愚蠢，它们可以根据网络的当前状态和可用带宽调整自己的交通需求。为此，主机需要感知当前的拥塞水平并根据估计的拥塞调整自己的交通需求。网络节点可以以不同的方式对网络拥塞做出反应，主机也可以以不同的方式感知拥塞水平。
- en: Let us first explore which mechanisms can be used inside a network to control
    congestion and how these mechanisms can influence the behavior of the end hosts.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先探索可以在网络内部使用的机制来控制拥塞，以及这些机制如何影响终端主机的行为。
- en: As explained earlier, one of the first manifestation of congestion on network
    nodes is the saturation of the network links that leads to a growth in the occupancy
    of the buffers of the node. This growth of the buffer occupancy implies that some
    packets will spend more time in the buffer and thus in the network. If hosts measure
    the network delays (e.g. by measuring the round-trip-time between the transmission
    of a packet and the return of the corresponding acknowledgment) they could start
    to sense congestion. On low bandwidth links, a growth in the buffer occupancy
    can lead to an increase of the delays which can be easily measured by the end
    hosts. On high bandwidth links, a few packets inside the buffer will cause a small
    variation in the delay which may not necessarily be larger that the natural fluctuations
    of the delay measurements.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，网络节点上拥塞的第一个表现是网络链路的饱和，这导致节点缓冲区占用率的增长。缓冲区占用率的增长意味着一些数据包将在缓冲区中花费更多的时间，从而在网络中停留更长时间。如果主机测量网络延迟（例如，通过测量数据包传输和相应的确认返回之间的往返时间），它们可以开始感知拥塞。在低带宽链路上，缓冲区占用率的增长可能导致延迟的增加，这可以通过终端主机轻松测量。在高带宽链路上，缓冲区内的几个数据包可能导致延迟的小幅变化，这不一定比延迟测量的自然波动更大。
- en: If the buffer’s occupancy continues to grow, it will overflow and packets will
    need to be discarded. Discarding packets during congestion is the second possible
    reaction of a network node to congestion. Before looking at how a node can discard
    packets, it is interesting to discuss qualitatively the impact of the buffer occupancy
    on the reliable delivery of data through a network. This is illustrated by figure
    [Fig. 194](#fig-congestion-jain), adapted from [[Jain1990]](../bibliography.html#jain1990).
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 如果缓冲区的占用率持续增长，它将溢出，并且需要丢弃数据包。在拥塞期间丢弃数据包是网络节点对拥塞的第二种可能反应。在探讨节点如何丢弃数据包之前，讨论缓冲区占用对通过网络可靠传输数据的影响是有趣的。这可以通过图[图194](#fig-congestion-jain)，改编自[[Jain1990]](../bibliography.html#jain1990)来说明。
- en: '![../_images/jain.png](../Images/b9e0fdb8cefccc00202ebacd9b171691.png)'
  id: totrans-438
  prefs: []
  type: TYPE_IMG
  zh: '![../_images/jain.png](../Images/b9e0fdb8cefccc00202ebacd9b171691.png)'
- en: Fig. 194 Network congestion[#](#fig-congestion-jain "Link to this image")
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 图. 194 网络拥塞[#](#fig-congestion-jain "链接到这张图片")
- en: When the network load is low, buffer occupancy and link utilization are low.
    The buffers on the network nodes are mainly used to absorb very short bursts of
    packets, but on average the traffic demand is lower than the network capacity.
    If the demand increases, the average buffer occupancy will increase as well. Measurements
    have shown that the total throughput increases as well. If the buffer occupancy
    is zero or very low, transmission opportunities on network links can be missed.
    This is not the case when the buffer occupancy is small but non zero. However,
    if the buffer occupancy continues to increase, the buffer becomes overloaded and
    the throughput does not increase anymore. When the buffer occupancy is close to
    the maximum, the throughput may decrease. This drop in throughput can be caused
    by excessive retransmissions of reliable protocols that incorrectly assume that
    previously sent packets have been lost while they are still waiting in the buffer.
    The network delay on the other hand increases with the buffer occupancy. In practice,
    a good operating point for a network buffer is a low occupancy to achieve high
    link utilization and also low delay for interactive applications.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 当网络负载较低时，缓冲区占用率和链路利用率都较低。网络节点上的缓冲区主要用于吸收非常短暂的数据包突发，但平均而言，流量需求低于网络容量。如果需求增加，平均缓冲区占用率也会增加。测量表明，总吞吐量也会增加。如果缓冲区占用率为零或非常低，可能会错过网络链路上的传输机会。然而，当缓冲区占用率较小但非零时，情况并非如此。但是，如果缓冲区占用率持续增加，缓冲区就会过载，吞吐量不再增加。当缓冲区占用率接近最大值时，吞吐量可能会下降。这种吞吐量下降可能是由于可靠协议的过度重传造成的，这些协议错误地假设之前发送的数据包已经丢失，而它们仍在缓冲区中等待。另一方面，网络延迟会随着缓冲区占用率的增加而增加。在实践中，网络缓冲区的一个良好工作点是低占用率，以实现高链路利用率和低延迟，这对于交互式应用来说也很重要。
- en: 'Discarding packets is one of the signals that the network nodes can use to
    inform the hosts of the current level of congestion. Buffers on network nodes
    are usually used as FIFO queues to preserve packet ordering. Several packet discard
    mechanisms have been proposed for network nodes. These techniques basically answer
    two different questions :'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 丢弃数据包是网络节点可以用来通知主机当前拥塞程度的信号之一。网络节点上的缓冲区通常用作FIFO队列以保持数据包的顺序。已经为网络节点提出了几种数据包丢弃机制。这些技术基本上回答了两个不同的问题：
- en: 'What triggers a packet to be discarded ? What are the conditions that lead
    a network node to decide to discard a packet? The simplest answer to this question
    is : When the buffer is full. Although this is a good congestion indication, it
    is probably not the best one from a performance viewpoint. An alternative is to
    discard packets when the buffer occupancy grows too much. In this case, it is
    likely that the buffer will become full shortly. Since packet discarding is an
    information that allows hosts to adapt their transmission rate, discarding packets
    early could allow hosts to react earlier and thus prevent congestion from happening.'
  id: totrans-442
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么触发了一个数据包被丢弃？导致网络节点决定丢弃数据包的条件是什么？对这个问题的最简单回答是：当缓冲区满时。虽然这是一个很好的拥塞指示，但从性能角度来看，可能不是最好的。另一种选择是在缓冲区占用率增长过多时丢弃数据包。在这种情况下，缓冲区很快就会满。由于数据包丢弃是一种允许主机调整其传输速率的信息，因此提前丢弃数据包可以允许主机更早地做出反应，从而防止拥塞发生。
- en: ''
  id: totrans-443
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-444
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Which packet(s) should be discarded ? Once the network node has decided to discard
    packets, it needs to actually discard real packets.
  id: totrans-445
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应该丢弃哪个（些）数据包？一旦网络节点决定丢弃数据包，它实际上需要丢弃真实的数据包。
- en: By combining different answers to these questions, network researchers have
    developed different packet discard mechanisms.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 通过结合对这些问题的不同回答，网络研究人员已经开发出了不同的数据包丢弃机制。
- en: Tail drop is the simplest packet discard technique. When a buffer is full, the
    arriving packet is discarded. Tail drop can be easily implemented. This is, by
    far, the most widely used packet discard mechanism. However, it suffers from two
    important drawbacks. First, since tail drop discards packets only when the buffer
    is full, buffers tend to be congested and real-time applications may suffer from
    increased delays. Second, tail drop is blind when it discards a packet. It may
    discard a packet from a low bandwidth interactive flow while most of the buffer
    is used by large file transfers.
  id: totrans-447
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尾部丢弃是最简单的数据包丢弃技术。当缓冲区满时，到达的数据包被丢弃。尾部丢弃可以很容易地实现。这到目前为止是最广泛使用的丢弃机制。然而，它有两个重要的缺点。首先，由于尾部丢弃仅在缓冲区满时丢弃数据包，缓冲区往往会拥塞，实时应用可能会遭受增加的延迟。其次，尾部丢弃在丢弃数据包时是盲目的。它可能会丢弃来自低带宽交互流的数据包，而大多数缓冲区被大文件传输占用。
- en: ''
  id: totrans-448
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-449
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Drop from front is an alternative packet discard technique. Instead of removing
    the arriving packet, it removes the packet that was at the head of the queue.
    Discarding this packet instead of the arriving one can have two advantages. First,
    it already stayed a long time in the buffer. Second, hosts should be able to detect
    the loss (and thus the congestion) earlier.
  id: totrans-450
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 前端丢弃是另一种数据包丢弃技术。它不是移除到达的数据包，而是移除队列头部的数据包。丢弃这个数据包而不是到达的数据包可以有两个优点。首先，它已经在缓冲区中停留了很长时间。其次，主机应该能够更早地检测到丢失（以及拥塞）。
- en: ''
  id: totrans-451
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-452
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Probabilistic drop. Various random drop techniques have been proposed. A frequently
    cited technique is Random Early Discard (RED) [[FJ1993]](../bibliography.html#fj1993).
    RED measures the average buffer occupancy and discards packets with a given probability
    when this average occupancy is too high. Compared to tail drop and drop from front,
    an advantage of RED is that thanks to the probabilistic drops, packets should
    be discarded from different flows in proportion of their bandwidth.
  id: totrans-453
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 概率丢弃。已经提出了各种随机丢弃技术。经常引用的技术是随机早期丢弃（RED）[[FJ1993]](../bibliography.html#fj1993)。RED测量平均缓冲区占用率，并在平均占用率过高时以一定的概率丢弃数据包。与尾部丢弃和前端丢弃相比，RED的一个优点是，由于概率丢弃，应该按不同流带宽的比例丢弃数据包。
- en: Discarding packets is a frequent reaction to network congestion. Unfortunately,
    discarding packets is not optimal since a packet which is discarded on a network
    node has already consumed resources on the upstream nodes. There are other ways
    for the network to inform the end hosts of the current congestion level. A first
    solution is to mark the packets when a node is congested. Several networking technologies
    have relied on this kind of packet marking.
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 丢弃数据包是应对网络拥塞的常见反应。不幸的是，丢弃数据包并不是最佳选择，因为在一个网络节点上被丢弃的数据包已经在上游节点上消耗了资源。网络还有其他方式来告知终端主机当前的拥塞水平。一种解决方案是在节点拥塞时标记数据包。几种网络技术都依赖于这种类型的数据包标记。
- en: In datagram networks, Forward Explicit Congestion Notification (FECN) can be
    used. One field of the packet header, typically one bit, is used to indicate congestion.
    When a host sends a packet, the congestion bit is unset. If the packet passes
    through a congested node, the congestion bit is set. The destination can then
    determine the current congestion level by measuring the fraction of the packets
    that it received with the congestion bit set. It may then return this information
    to the sending host to allow it to adapt its retransmission rate. Compared to
    packet discarding, the main advantage of FECN is that hosts can detect congestion
    explicitly without having to rely on packet losses.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据报网络中，可以使用前向显式拥塞通知（FECN）。数据包头部的一个字段，通常是一个比特位，用于指示拥塞。当主机发送数据包时，拥塞位被清除。如果数据包通过一个拥塞节点，拥塞位被设置。目的地可以通过测量收到拥塞位设置的数据包的比例来确定当前的拥塞水平。然后，它可以向发送主机返回此信息，以便它能够调整其重传速率。与丢弃数据包相比，FECN的主要优势是主机可以明确检测到拥塞，而无需依赖于数据包丢失。
- en: In virtual circuit networks, packet marking can be improved if the return packets
    follow the reverse path of the forward packets. It this case, a network node can
    detect congestion on the forward path (e.g. due to the size of its buffer), but
    mark the packets on the return path. Marking the return packets (e.g. the acknowledgments
    used by reliable protocols) provides a faster feedback to the sending hosts compared
    to FECN. This technique is usually called Backward Explicit Congestion Notification
    (BECN).
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 在虚拟电路网络中，如果返回包遵循正向包的反向路径，则数据包标记可以得到改进。在这种情况下，网络节点可以检测到正向路径上的拥塞（例如，由于其缓冲区的大小），但在反向路径上标记数据包。与FECN相比，标记返回包（例如，可靠协议使用的确认）为发送主机提供了更快的反馈。这种技术通常称为向后显式拥塞通知（BECN）。
- en: If the packet header does not contain any bit in the header to represent the
    current congestion level, an alternative is to allow the network nodes to send
    a control packet to the source to indicate the current congestion level. Some
    networking technologies use such control packets to explicitly regulate the transmission
    rate of sources. However, their usage is mainly restricted to small networks.
    In large networks, network nodes usually avoid using such control packets. These
    control packets are even considered to be dangerous in some networks. First, using
    them increases the network load when the network is congested. Second, while network
    nodes are optimized to forward packets, they are usually pretty slow at creating
    new packets.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据包头部不包含表示当前拥塞级别的任何位，则一种替代方法是允许网络节点向源发送控制包以指示当前拥塞级别。一些网络技术使用此类控制包来显式调节源头的传输速率。然而，它们的用途主要限于小型网络。在大规模网络中，网络节点通常避免使用此类控制包。在某些网络中，这些控制包甚至被认为是有危险的。首先，在拥塞时使用它们会增加网络负载。其次，虽然网络节点优化了转发数据包，但它们通常在创建新数据包方面相当慢。
- en: Dropping and marking packets is not the only possible reaction of a router that
    becomes congested. A router could also selectively delay packets belonging to
    some flows. There are different algorithms that can be used by a router to delay
    packets. If the objective of the router is to fairly distribute to bandwidth of
    an output link among competing flows, one possibility is to organize the buffers
    of the router as a set of queues. For simplicity, let us assume that the router
    is capable of supporting a fixed number of concurrent flows, say N. One of the
    queues of the router is associated to each flow and when a packet arrives, it
    is placed at the tail of the corresponding queue. All the queues are controlled
    by a scheduler. A scheduler is an algorithm that is run each time there is an
    opportunity to transmit a packet on the outgoing link. Various schedulers have
    been proposed in the scientific literature and some are used in real routers.
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 当路由器出现拥塞时，丢弃和标记数据包并不是唯一的可能反应。路由器还可以选择性地延迟某些流的包。路由器可以使用不同的算法来延迟数据包。如果路由器的目标是公平地分配输出链路的带宽给竞争的流，一个可能的方法是将路由器的缓冲区组织成一组队列。为了简化，让我们假设路由器能够支持固定数量的并发流，比如说N。路由器的一个队列与每个流相关联，当一个数据包到达时，它被放置在相应队列的尾部。所有队列都由一个调度器控制。调度器是一种算法，每次有机会在出站链路上传输数据包时都会运行。科学文献中已经提出了各种调度器，其中一些被用于实际的路由器中。
- en: '![Figure made with TikZ](../Images/e6916b3dd773fa746d317a93e0a077db.png)'
  id: totrans-459
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用TikZ制作的图](../Images/e6916b3dd773fa746d317a93e0a077db.png)'
- en: ''
  id: totrans-460
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 195 A round-robin scheduler, where N = 5
  id: totrans-461
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图195：循环调度器，其中N = 5
- en: A very simple scheduler is the round-robin scheduler. This scheduler serves
    all the queues in a round-robin fashion. If all flows send packets of the same
    size, then the round-robin scheduler fairly allocates the bandwidth among the
    different flows. Otherwise, it favors flows that are using larger packets. Extensions
    to the round-robin scheduler have been proposed to provide a fair distribution
    of the bandwidth with variable-length packets [[SV1995]](../bibliography.html#sv1995)
    but these are outside the scope of this chapter.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 一个非常简单的调度器是循环调度器。这种调度器以循环方式服务于所有队列。如果所有流发送相同大小的数据包，那么循环调度器将带宽公平地分配给不同的流。否则，它更倾向于使用较大数据包的流。为了在具有可变长度数据包的情况下提供带宽的公平分配，已经提出了循环调度器的扩展方案
    [[SV1995]](../bibliography.html#sv1995)，但这些内容超出了本章的范围。
- en: '[PRE9]'
  id: totrans-463
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Distributing the load across the network[#](#distributing-the-load-across-the-network
    "Link to this heading")
  id: totrans-464
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在网络中分配负载[#](#distributing-the-load-across-the-network "链接到本标题")
- en: Delays, packet discards, packet markings and control packets are the main types
    of information that the network can exchange with the end hosts. Discarding packets
    is the main action that a network node can perform if the congestion is too severe.
    Besides tackling congestion at each node, it is also possible to divert some traffic
    flows from heavily loaded links to reduce congestion. Early routing algorithms
    [[MRR1980]](../bibliography.html#mrr1980) have used delay measurements to detect
    congestion between network nodes and update the link weights dynamically. By reflecting
    the delay perceived by applications in the link weights used for the shortest
    paths computation, these routing algorithms managed to dynamically change the
    forwarding paths in reaction to congestion. However, deployment experience showed
    that these dynamic routing algorithms could cause oscillations and did not necessarily
    lower congestion. Deployed datagram networks rarely use dynamic routing algorithms,
    except in some wireless networks. In datagram networks, the state of the art reaction
    to long term congestion, i.e. congestion lasting hours, days or more, is to measure
    the traffic demand and then select the link weights [[FRT2002]](../bibliography.html#frt2002)
    that allow minimizing the maximum link loads. If the congestion lasts longer,
    changing the weights is not sufficient anymore and the network needs to be upgraded
    with additional or faster links. However, in Wide Area Networks, adding new links
    can take months.
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 延迟、数据包丢弃、数据包标记和控制数据包是网络可以与终端主机交换的主要信息类型。如果拥塞过于严重，丢弃数据包是网络节点可以执行的主要操作。除了在每个节点解决拥塞外，还可以将一些流量从负载过重的链路转移到其他链路以减少拥塞。早期的路由算法
    [[MRR1980]](../bibliography.html#mrr1980) 使用延迟测量来检测网络节点之间的拥塞并动态更新链路权重。通过将应用程序感知到的延迟反映在用于最短路径计算的链路权重中，这些路由算法能够动态地改变转发路径以应对拥塞。然而，部署经验表明，这些动态路由算法可能会引起振荡，并不一定能够降低拥塞。部署的数据报网络很少使用动态路由算法，除了在一些无线网络中。在数据报网络中，对长期拥塞（即持续数小时、数天或更长时间的拥塞）的最佳反应是测量流量需求，然后选择允许最小化最大链路负载的链路权重
    [[FRT2002]](../bibliography.html#frt2002)。如果拥塞持续更长时间，改变权重就不再足够，网络需要通过添加额外的或更快的链路进行升级。然而，在广域网络中，添加新链路可能需要数月时间。
- en: In virtual circuit networks, another way to manage or prevent congestion is
    to limit the number of circuits that use the network at any time. This technique
    is usually called connection admission control. When a host requests the creation
    of a new circuit in the network, it specifies the destination and in some networking
    technologies the required bandwidth. With this information, the network can check
    whether there are enough resources available to reach this particular destination.
    If yes, the circuit is established. If not, the request is denied and the host
    will have to defer the creation of its virtual circuit. Connection admission control
    schemes are widely used in the telephone networks. In these networks, a busy tone
    corresponds to an unavailable destination or a congested network.
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 在虚电路网络中，管理或防止拥塞的另一种方法是限制在任何时间使用网络的电路数量。这种技术通常被称为连接接纳控制。当主机请求在网络中创建新的电路时，它指定了目的地，在某些网络技术中还需要指定所需的带宽。有了这些信息，网络可以检查是否有足够的资源可用以到达该特定目的地。如果是的话，电路将被建立。如果不是，请求将被拒绝，主机将不得不推迟其虚拟电路的创建。连接接纳控制方案在电话网络中得到广泛应用。在这些网络中，忙音表示不可用的目的地或拥塞的网络。
- en: In datagram networks, this technique cannot be easily used since the basic assumption
    of such a network is that a host can send any packet towards any destination at
    any time. A host does not need to request the authorization of the network to
    send packets towards a particular destination.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据报网络中，这种技术不能轻易使用，因为这种网络的基本假设是主机可以在任何时间向任何目的地发送任何数据包。主机不需要请求网络授权以向特定目的地发送数据包。
- en: Based on the feedback received from the network, the hosts can adjust their
    transmission rate. We discuss in section Congestion control some techniques that
    allow hosts to react to congestion.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 基于从网络收到的反馈，主机可以调整它们的传输速率。我们在“拥塞控制”一节中讨论了一些允许主机对拥塞做出反应的技术。
- en: Another way to share the network resources is to distribute the load across
    multiple links. Many techniques have been designed to spread the load over the
    network. As an illustration, let us briefly consider how the load can be shared
    when accessing some content. Consider a large and popular file such as the image
    of a Linux distribution or the upgrade of a commercial operating system that will
    be downloaded by many users. There are many ways to distribute this large file.
    A naive solution is to place one copy of the file on a server and allow all users
    to download this file from the server. If the file is popular and millions of
    users want to download it, the server will quickly become overloaded. There are
    two classes of solutions that can be used to serve a large number of users. A
    first approach is to store the file on servers whose name is known by the clients.
    Before retrieving the file, each client will query the name service to obtain
    the address of the server. If the file is available from many servers, the name
    service can provide different addresses to different clients. This will automatically
    spread the load since different clients will download the file from different
    servers. Most large content providers use such a solution to distribute large
    files or videos.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种共享网络资源的方法是将负载分配到多个链接上。已经设计了许多技术来在网络中分散负载。作为一个例子，让我们简要地考虑在访问某些内容时如何共享负载。考虑一个大型且受欢迎的文件，例如Linux发行版的镜像或商业操作系统的升级，这些文件将被许多用户下载。有几种方法可以分发这个大文件。一个简单的方法是将文件的副本放置在服务器上，并允许所有用户从服务器下载此文件。如果文件很受欢迎，并且有数百万用户想要下载它，服务器将很快变得过载。有两种类型的解决方案可以用来服务大量用户。第一种方法是将文件存储在客户端已知名称的服务器上。在检索文件之前，每个客户端都会查询名称服务以获取服务器的地址。如果文件可以从多个服务器获取，名称服务可以为不同的客户端提供不同的地址。这将自动分散负载，因为不同的客户端将从不同的服务器下载文件。大多数大型内容提供商都使用这种解决方案来分发大文件或视频。
- en: There is another solution that allows spreading the load among many sources
    without relying on the name service. The popular [bittorent](https://www.bittorrent.com)
    service is an example of this approach. With this solution, each file is divided
    in blocks of fixed size. To retrieve a file, a client needs to retrieve all the
    blocks that compose the file. However, nothing forces the client to retrieve all
    the blocks in sequence and from the same server. Each file is associated with
    metadata that indicates for each block a list of addresses of hosts that store
    this block. To retrieve a complete file, a client first downloads the metadata.
    Then, it tries to retrieve each block from one of the hosts that store the block.
    In practice, implementations often try to download several blocks in parallel.
    Once one block has been successfully downloaded, the next block can be requested.
    If a host is slow to provide one block or becomes unavailable, the client can
    contact another host listed in the metadata. Most deployments of bittorrent allow
    the clients to participate to the distribution of blocks. Once a client has downloaded
    one block, it contacts the server which stores the metadata to indicate that it
    can also provide this block. With this scheme, when a file is popular, its blocks
    are downloaded by many hosts that automatically participate in the distribution
    of the blocks. Thus, the number of servers that are capable of providing blocks
    from a popular file automatically increases with the file’s popularity.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种解决方案允许在不依赖名称服务的情况下在多个源之间分散负载。流行的[bittorent](https://www.bittorrent.com)服务就是这种方法的例子。使用这种解决方案，每个文件都被分成固定大小的块。要检索一个文件，客户端需要检索组成该文件的所有块。然而，没有任何东西强迫客户端按顺序和从同一服务器检索所有块。每个文件都与元数据相关联，该元数据为每个块列出了存储该块的主机地址列表。为了检索完整的文件，客户端首先下载元数据。然后，它尝试从存储该块的某个主机检索每个块。在实践中，实现通常尝试并行下载多个块。一旦成功下载了一个块，就可以请求下一个块。如果一个主机在提供某个块时速度较慢或变得不可用，客户端可以联系元数据中列出的另一个主机。大多数bittorrent部署允许客户端参与块的分发。一旦客户端下载了一个块，它就会联系存储元数据的服务器，表明它也可以提供这个块。在这个方案中，当一个文件很受欢迎时，它的块被许多自动参与块分发的宿主机下载。因此，能够提供流行文件块的服务器数量会随着文件受欢迎程度的增加而自动增加。
- en: 'Now that we have provided a broad overview of the techniques that can be used
    to spread the load and allocate resources in the network, let us analyze two techniques
    in more details : Medium Access Control and Congestion control.'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经提供了关于如何在网络中分配负载和资源的技术的广泛概述，让我们更详细地分析两种技术：介质访问控制和拥塞控制。
- en: Medium Access Control algorithms[#](#medium-access-control-algorithms "Link
    to this heading")
  id: totrans-472
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介质访问控制算法[#](#medium-access-control-algorithms "链接到本标题")
- en: The common problem among Local Area Networks is how to efficiently share the
    available bandwidth. If two devices send a frame at the same time, the two electrical,
    optical or radio signals that correspond to these frames will appear at the same
    time on the transmission medium and a receiver will not be able to decode either
    frame. Such simultaneous transmissions are called collisions. A collision may
    involve frames transmitted by two or more devices attached to the Local Area Network.
    Collisions are the main cause of errors in wired Local Area Networks.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 局域网中普遍存在的问题是如何有效地共享可用带宽。如果两个设备同时发送一个帧，对应这些帧的两个或多个设备传输的电气、光学或无线电信号将同时出现在传输介质上，接收器将无法解码任何一个帧。这种同时传输称为冲突。冲突可能涉及局域网中两个或多个设备传输的帧。冲突是有线局域网中错误的主要原因。
- en: 'All Local Area Network technologies rely on a Medium Access Control algorithm
    to regulate the transmissions to either minimize or avoid collisions. There are
    two broad families of Medium Access Control algorithms :'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 所有局域网技术都依赖于介质访问控制算法来调节传输，以最小化或避免冲突。介质访问控制算法分为两大类：
- en: Deterministic or pessimistic MAC algorithms. These algorithms assume that collisions
    are a very severe problem and that they must be completely avoided. These algorithms
    ensure that at any time, at most one device is allowed to send a frame on the
    LAN. This is usually achieved by using a distributed protocol which elects one
    device that is allowed to transmit at each time. A deterministic MAC algorithm
    ensures that no collision will happen, but there is some overhead in regulating
    the transmission of all the devices attached to the LAN.
  id: totrans-475
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定性或悲观的MAC算法。这些算法假设冲突是一个非常严重的问题，必须完全避免。这些算法确保在任何时候，最多只允许一个设备在局域网上发送一个帧。这通常是通过使用分布式协议来实现的，该协议在每个时间点选择一个允许传输的设备。确定性MAC算法确保不会发生冲突，但调节局域网中所有设备传输的调节开销是有的。
- en: ''
  id: totrans-476
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-477
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Stochastic or optimistic MAC algorithms. These algorithms assume that collisions
    are part of the normal operation of a Local Area Network. They aim to minimize
    the number of collisions, but they do not try to avoid all collisions. Stochastic
    algorithms are usually easier to implement than deterministic ones.
  id: totrans-478
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机或乐观的MAC算法。这些算法假设冲突是局域网正常操作的一部分。它们的目的是最小化冲突的数量，但并不试图避免所有冲突。随机算法通常比确定性算法更容易实现。
- en: We first discuss a simple deterministic MAC algorithm and then we describe several
    important optimistic algorithms, before coming back to a distributed and deterministic
    MAC algorithm.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先讨论一个简单的确定性MAC算法，然后描述几个重要的乐观算法，最后再回到分布式和确定性MAC算法。
- en: Static allocation methods[#](#static-allocation-methods "Link to this heading")
  id: totrans-480
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 静态分配方法[#](#static-allocation-methods "链接到本标题")
- en: A first solution to share the available resources among all the devices attached
    to one Local Area Network is to define, a priori, the distribution of the transmission
    resources among the different devices. If N devices need to share the transmission
    capacities of a LAN operating at b Mbps, each device could be allocated a bandwidth
    of \(\frac{b}{N}\) Mbps.
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个局域网中共享所有设备的可用资源的一个初步解决方案是在事先定义不同设备之间的传输资源分配。如果N个设备需要共享一个以b Mbps运行的局域网的传输容量，每个设备可以分配到\(\frac{b}{N}\)
    Mbps的带宽。
- en: Limited resources need to be shared in other environments than Local Area Networks.
    Since the first radio transmissions by [Marconi](http://en.wikipedia.org/wiki/Guglielmo_Marconi)
    more than one century ago, many applications that exchange information through
    radio signals have been developed. Each radio signal is an electromagnetic wave
    whose power is centered around a given frequency. The radio spectrum corresponds
    to frequencies ranging between roughly 3 KHz and 300 GHz. Frequency allocation
    plans negotiated among governments reserve most frequency ranges for specific
    applications such as broadcast radio, broadcast television, mobile communications,
    aeronautical radio navigation, amateur radio, satellite, etc. Each frequency range
    is then subdivided into channels and each channel can be reserved for a given
    application, e.g. a radio broadcaster in a given region.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 在局域网以外的其他环境中需要共享有限资源。自从一个多世纪前[马可尼](http://en.wikipedia.org/wiki/Guglielmo_Marconi)进行首次无线电传输以来，已经开发了许多通过无线电信号交换信息的应用。每个无线电信号都是一个以给定频率为中心的电磁波。无线电频谱对应于大约3
    KHz到300 GHz之间的频率。政府之间协商的频率分配计划为广播无线电、广播电视、移动通信、航空无线电导航、业余无线电、卫星等特定应用保留了大多数频率范围。然后，每个频率范围被细分为频道，每个频道可以保留给特定的应用，例如某个地区的广播电台。
- en: Frequency Division Multiplexing (FDM) is a static allocation scheme in which
    a frequency is allocated to each device attached to the shared medium. As each
    device uses a different transmission frequency, collisions cannot occur. In optical
    networks, a variant of FDM called Wavelength Division Multiplexing (WDM) can be
    used. An optical fiber can transport light at different wavelengths without interference.
    With WDM, a different wavelength is allocated to each of the devices that share
    the same optical fiber.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 频分复用（Frequency Division Multiplexing, FDM）是一种静态分配方案，其中为连接到共享介质的每个设备分配一个频率。由于每个设备使用不同的传输频率，因此不会发生冲突。在光网络中，可以使用FDM的一种变体，称为波分复用（Wavelength
    Division Multiplexing, WDM）。光纤可以在不同的波长上传输光而不发生干扰。使用WDM，为共享同一光纤的每个设备分配不同的波长。
- en: Time Division Multiplexing (TDM) is a static bandwidth allocation method that
    was initially defined for the telephone network. In the fixed telephone network,
    a voice conversation is usually transmitted as a 64 Kbps signal. Thus, a telephone
    conservation generates 8 KBytes per second or one byte every 125 microseconds.
    Telephone conversations often need to be multiplexed together on a single line.
    For example, in Europe, thirty 64 Kbps voice signals are multiplexed over a single
    2 Mbps (E1) line. This is done by using Time Division Multiplexing (TDM). TDM
    divides the transmission opportunities into slots. In the telephone network, a
    slot corresponds to 125 microseconds. A position inside each slot is reserved
    for each voice signal. The figure below illustrates TDM on a link that is used
    to carry four voice conversations. The vertical lines represent the slot boundaries
    and the letters the different voice conversations. One byte from each voice conversation
    is sent during each 125 microseconds slot. The byte corresponding to a given conversation
    is always sent at the same position in each slot.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 时间分复用（Time Division Multiplexing, TDM）是一种最初为电话网络定义的静态带宽分配方法。在固定电话网络中，语音对话通常以64
    Kbps的信号传输。因此，电话对话每秒生成8 KBytes或每125微秒一个字节。电话对话通常需要在一个单独的线路上复用。例如，在欧洲，三十个64 Kbps的语音信号通过一个2
    Mbps（E1）的单独线路复用。这是通过使用时间分复用（TDM）实现的。TDM将传输机会划分为时隙。在电话网络中，一个时隙对应于125微秒。每个时隙内的一个位置为每个语音信号预留。下面的图示说明了用于携带四个语音对话的链路上的TDM。垂直线代表时隙边界，字母代表不同的语音对话。每个语音对话的字节在每个125微秒的时隙中发送。对应于给定对话的字节总是在每个时隙中的相同位置发送。
- en: '![Figure made with TikZ](../Images/a5ce7017001779fb85df0a821c9dfa33.png)'
  id: totrans-485
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用TikZ制作的图](../Images/a5ce7017001779fb85df0a821c9dfa33.png)'
- en: ''
  id: totrans-486
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 196 Time-division multiplexing
  id: totrans-487
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图196 时间分复用
- en: TDM as shown above can be completely static, i.e. the same conversations always
    share the link, or dynamic. In the latter case, the two endpoints of the link
    must exchange messages specifying which conversation uses which byte inside each
    slot. Thanks to these control messages, it is possible to dynamically add and
    remove voice conversations from a given link.
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 如上图所示，TDM可以是完全静态的，即相同的对话总是共享链路，或者动态的。在后一种情况下，链路的两个端点必须交换消息，指定每个对话在每个时隙中使用哪个字节。得益于这些控制消息，可以动态地向给定链路添加和删除语音对话。
- en: TDM and FDM are widely used in telephone networks to support fixed bandwidth
    conversations. Using them in Local Area Networks that support computers would
    probably be inefficient. Computers usually do not send information at a fixed
    rate. Instead, they often have an on-off behavior. During the on period, the computer
    tries to send at the highest possible rate, e.g. to transfer a file. During the
    off period, which is often much longer than the on period, the computer does not
    transmit any packet. Using a static allocation scheme for computers attached to
    a LAN would lead to huge inefficiencies, as they would only be able to transmit
    at \(\frac{1}{N}\) of the total bandwidth during their on period, despite the
    fact that the other computers are in their off period and thus do not need to
    transmit any information. The dynamic MAC algorithms discussed in the remainder
    of this chapter aim to solve this problem.
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: TDM和FDM在电话网络中被广泛用于支持固定带宽的通话。在支持计算机的局域网中使用它们可能会效率低下。计算机通常不会以固定速率发送信息。相反，它们往往具有开/关的行为。在开启期间，计算机试图以尽可能高的速率发送信息，例如传输文件。在关闭期间，这个期间通常比开启期间长得多，计算机不发送任何数据包。为连接到局域网的计算机使用静态分配方案会导致巨大的低效率，因为它们在开启期间只能以\(\frac{1}{N}\)的总带宽进行传输，尽管其他计算机处于关闭期间，因此不需要传输任何信息。本章余下的部分讨论的动态MAC算法旨在解决这个问题。
- en: ALOHA[#](#aloha "Link to this heading")
  id: totrans-490
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ALOHA[#](#aloha "链接到这个标题")
- en: In the 1960s, computers were mainly mainframes with a few dozen terminals attached
    to them. These terminals were usually in the same building as the mainframe and
    were directly connected to it. In some cases, the terminals were installed in
    remote locations and connected through a [modem](../glossary.html#term-modem)
    attached to a [dial-up line](../glossary.html#term-dial-up-line). The university
    of Hawaii chose a different organization. Instead of using telephone lines to
    connect the distant terminals, they developed the first packet radio technology
    [[Abramson1970]](../bibliography.html#abramson1970). Until then, computer networks
    were built on top of either the telephone network or physical cables. ALOHANet
    showed that it is possible to use radio signals to interconnect computers.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 在20世纪60年代，计算机主要是大型机，连接了几十个终端。这些终端通常位于主机的同一栋大楼内，并直接连接到它。在某些情况下，终端被安装在远程位置，并通过连接到[调制解调器](../glossary.html#term-modem)的[拨号线路](../glossary.html#term-dial-up-line)进行连接。夏威夷大学选择了不同的组织方式。他们没有使用电话线来连接远程终端，而是开发了第一种分组无线电技术[[Abramson1970]](../bibliography.html#abramson1970)。在此之前，计算机网络要么建立在电话网络之上，要么建立在物理电缆之上。ALOHA网证明了使用无线电信号互联计算机是可能的。
- en: The first version of ALOHANet, described in [[Abramson1970]](../bibliography.html#abramson1970),
    operated as follows. First, the terminals and the mainframe exchanged fixed-length
    frames composed of 704 bits. Each frame contained 80 8-bit characters, some control
    bits and parity information to detect transmission errors. Two channels in the
    400 MHz range were reserved for the operation of ALOHANet. The first channel was
    used by the mainframe to send frames to all terminals. The second channel was
    shared among all terminals to send frames to the mainframe. As all terminals share
    the same transmission channel, there is a risk of collision. To deal with this
    problem as well as transmission errors, the mainframe verified the parity bits
    of the received frame and sent an acknowledgment on its channel for each correctly
    received frame. The terminals on the other hand had to retransmit the unacknowledged
    frames. As for TCP, retransmitting these frames immediately upon expiration of
    a fixed timeout is not a good approach as several terminals may retransmit their
    frames at the same time leading to a network collapse. A better approach, but
    still far from perfect, is for each terminal to wait a random amount of time after
    the expiration of its retransmission timeout. This avoids synchronization among
    multiple retransmitting terminals.
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: ALOHANet 的第一个版本，如 [[Abramson1970]](../bibliography.html#abramson1970) 所述，操作如下。首先，终端和主机交换由
    704 位组成的固定长度帧。每个帧包含 80 个 8 位字符，一些控制位和用于检测传输错误的奇偶校验信息。400 MHz 范围内的两个信道被保留用于 ALOHANet
    的操作。第一个信道由主机用于向所有终端发送帧。第二个信道由所有终端共享，用于向主机发送帧。由于所有终端共享相同的传输信道，因此存在碰撞的风险。为了处理这个问题以及传输错误，主机验证接收到的帧的奇偶校验位，并为每个正确接收到的帧在其信道上发送确认。另一方面，终端必须重传未确认的帧。对于
    TCP 来说，在固定超时到期后立即重传这些帧不是一个好的方法，因为多个终端可能同时重传它们的帧，从而导致网络崩溃。一个更好的方法，但仍然远非完美，是每个终端在其重传超时到期后等待随机的时间。这避免了多个重传终端之间的同步。
- en: The pseudo-code below shows the operation of an ALOHANet terminal. We use this
    python syntax for all Medium Access Control algorithms described in this chapter.
    The algorithm is applied to each new frame that needs to be transmitted. It attempts
    to transmit a frame at most max times (while loop). Each transmission attempt
    is performed as follows. First, the frame is sent. Each frame is protected by
    a timeout. Then, the terminal waits for either a valid acknowledgment frame or
    the expiration of its timeout. If the terminal receives an acknowledgment, the
    frame has been delivered correctly and the algorithm terminates. Otherwise, the
    terminal waits for a random time and attempts to retransmit the frame.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的伪代码显示了 ALOHANet 终端的操作。我们使用这种 Python 语法描述本章中所有介质访问控制算法。该算法应用于需要传输的每个新帧。它尝试最多
    max 次传输一个帧（while 循环）。每次传输尝试如下进行。首先，发送帧。每个帧都有一个超时保护。然后，终端等待有效的确认帧或其超时的到期。如果终端收到确认，则帧已正确交付，算法终止。否则，终端等待随机时间并尝试重传帧。
- en: '[PRE10]'
  id: totrans-494
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[[Abramson1970]](../bibliography.html#abramson1970) analyzed the performance
    of ALOHANet under particular assumptions and found that ALOHANet worked well when
    the channel was lightly loaded. In this case, the frames are rarely retransmitted
    and the channel traffic, i.e. the total number of (correct and retransmitted)
    frames transmitted per unit of time is close to the channel utilization, i.e.
    the number of correctly transmitted frames per unit of time. Unfortunately, the
    analysis also reveals that the channel utilization reaches its maximum at \(\frac{1}{2
    \times e}=0.186\) times the channel bandwidth. At higher utilization, ALOHANet
    becomes unstable and the network collapses due to collided retransmissions.'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: '[[Abramson1970]](../bibliography.html#abramson1970) 在特定假设下分析了 ALOHANet 的性能，发现当信道负载较轻时，ALOHANet
    工作良好。在这种情况下，帧很少需要重传，信道流量，即每单位时间内传输的（正确和重传）帧的总数接近信道利用率，即每单位时间内正确传输的帧数。不幸的是，分析还显示，信道利用率达到最大值时为信道带宽的
    \(\frac{1}{2 \times e}=0.186\) 倍。在更高的利用率下，ALOHANet 变得不稳定，网络因碰撞重传而崩溃。'
- en: Note
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Amateur packet radio
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 业余包交换无线电
- en: Packet radio technologies have evolved in various directions since the first
    experiments performed at the University of Hawaii. The Amateur packet radio service
    developed by amateur radio operators is one of the descendants ALOHANet. Many
    amateur radio operators are very interested in new technologies and they often
    spend countless hours developing new antennas or transceivers. When the first
    personal computers appeared, several amateur radio operators designed radio modems
    and their own datalink layer protocols [[KPD1985]](../bibliography.html#kpd1985)
    [[BNT1997]](../bibliography.html#bnt1997). This network grew and it was possible
    to connect to servers in several European countries by only using packet radio
    relays. Some amateur radio operators also developed TCP/IP protocol stacks that
    were used over the packet radio service. Some parts of the [amateur packet radio
    network](http://www.ampr.org/) are connected to the global Internet and use the
    44.0.0.0/8 IPv4 prefix.
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 自从在夏威夷大学进行首次实验以来，包无线电技术已经向多个方向发展。由业余无线电操作员开发的业余包无线电服务是ALOHA网络的继承者之一。许多业余无线电操作员对新技术非常感兴趣，他们经常花费无数小时开发新的天线或收发器。当第一台个人计算机出现时，几位业余无线电操作员设计了无线电调制解调器和他们自己的数据链路层协议
    [[KPD1985]](../bibliography.html#kpd1985) [[BNT1997]](../bibliography.html#bnt1997)。这个网络不断发展，仅使用包无线电中继就可以连接到几个欧洲国家的服务器。一些业余无线电操作员还开发了在包无线电服务上使用的TCP/IP协议栈。[业余包无线电网络](http://www.ampr.org/)的一些部分连接到全球互联网，并使用44.0.0.0/8
    IPv4前缀。
- en: Many improvements to ALOHANet have been proposed since the publication of [[Abramson1970]](../bibliography.html#abramson1970),
    and this technique, or some of its variants, are still found in wireless networks
    today. The slotted technique proposed in [[Roberts1975]](../bibliography.html#roberts1975)
    is important because it shows that a simple modification can significantly improve
    channel utilization. Instead of allowing all terminals to transmit at any time,
    [[Roberts1975]](../bibliography.html#roberts1975) proposed to divide time into
    slots and allow terminals to transmit only at the beginning of each slot. Each
    slot corresponds to the time required to transmit one fixed size frame. In practice,
    these slots can be imposed by a single clock that is received by all terminals.
    In ALOHANet, it could have been located on the central mainframe. The analysis
    in [[Roberts1975]](../bibliography.html#roberts1975) reveals that this simple
    modification improves the channel utilization by a factor of two.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 自从[[Abramson1970]](../bibliography.html#abramson1970)发表以来，针对ALOHA网络提出了许多改进，这种技术或其某些变体今天仍然存在于无线网络中。[[Roberts1975]](../bibliography.html#roberts1975)提出的时隙技术很重要，因为它表明简单的修改可以显著提高信道利用率。不是允许所有终端在任何时间传输，[[Roberts1975]](../bibliography.html#roberts1975)提出将时间划分为时隙，并允许终端只在每个时隙的开始传输。每个时隙对应于传输一个固定大小帧所需的时间。在实践中，这些时隙可以通过所有终端接收的单个时钟来强制执行。在ALOHA网络中，它可能位于中央主框上。[[Roberts1975]](../bibliography.html#roberts1975)的分析表明，这种简单的修改将信道利用率提高了两倍。
- en: '### Carrier Sense Multiple Access[#](#carrier-sense-multiple-access "Link to
    this heading")'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: '### 载波侦听多路访问[#](#carrier-sense-multiple-access "链接到本标题")'
- en: ALOHA and slotted ALOHA can easily be implemented, but unfortunately, they can
    only be used in networks that are very lightly loaded. Designing a network for
    a very low utilization is possible, but it clearly increases the cost of the network.
    To overcome the problems of ALOHA, many Medium Access Control mechanisms have
    been proposed which improve channel utilization. Carrier Sense Multiple Access
    (CSMA) is a significant improvement compared to ALOHA. CSMA requires all nodes
    to listen to the transmission channel to verify that it is free before transmitting
    a frame [[KT1975]](../bibliography.html#kt1975). When a node senses the channel
    to be busy, it defers its transmission until the channel becomes free again. The
    pseudo-code below provides a more detailed description of the operation of CSMA.
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: ALOHA和时隙ALOHA很容易实现，但遗憾的是，它们只能用于负载非常轻的网络。为非常低利用率设计网络是可能的，但这显然会增加网络的成本。为了克服ALOHA的问题，已经提出了许多介质访问控制机制，这些机制提高了信道利用率。与ALOHA相比，载波侦听多路访问（CSMA）是一个显著的改进。CSMA要求所有节点在发送帧之前先监听传输信道以验证其是否空闲
    [[KT1975]](../bibliography.html#kt1975)。当一个节点检测到信道繁忙时，它会推迟其传输，直到信道再次空闲。下面的伪代码提供了CSMA操作的更详细描述。
- en: '[PRE11]'
  id: totrans-502
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The above pseudo-code is often called persistent CSMA [[KT1975]](../bibliography.html#kt1975)
    as the terminal will continuously listen to the channel and transmit its frame
    as soon as the channel becomes free. Another important variant of CSMA is the
    non-persistent CSMA [[KT1975]](../bibliography.html#kt1975). The main difference
    between persistent and non-persistent CSMA described in the pseudo-code below
    is that a non-persistent CSMA node does not continuously listen to the channel
    to determine when it becomes free. When a non-persistent CSMA terminal senses
    the transmission channel to be busy, it waits for a random time before sensing
    the channel again. This improves channel utilization compared to persistent CSMA.
    With persistent CSMA, when two terminals sense the channel to be busy, they will
    both transmit (and thus cause a collision) as soon as the channel becomes free.
    With non-persistent CSMA, this synchronization does not occur, as the terminals
    wait a random time after having sensed the transmission channel. However, the
    higher channel utilization achieved by non-persistent CSMA comes at the expense
    of a slightly higher waiting time in the terminals when the network is lightly
    loaded.
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 上述伪代码通常被称为持续载波监听多路访问（CSMA）[[KT1975]](../bibliography.html#kt1975)，因为终端会持续监听信道，一旦信道空闲，就会立即发送其帧。CSMA的另一个重要变体是非持续CSMA
    [[KT1975]](../bibliography.html#kt1975)。以下伪代码中描述的持续和非持续CSMA之间的主要区别是，非持续CSMA节点不会持续监听信道以确定何时空闲。当一个非持续CSMA终端检测到传输信道忙碌时，它会在再次检测信道之前等待一个随机时间。这比持续CSMA提高了信道利用率。在持续CSMA中，当两个终端检测到信道忙碌时，它们会在信道空闲的瞬间同时发送（从而引起冲突）。而在非持续CSMA中，这种同步不会发生，因为终端在检测到传输信道后等待一个随机时间。然而，非持续CSMA通过提高信道利用率所实现的，是以网络轻载时终端稍微增加的等待时间为代价的。
- en: '[PRE12]'
  id: totrans-504
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[[KT1975]](../bibliography.html#kt1975) analyzes in detail the performance
    of several CSMA variants. Under some assumptions about the transmission channel
    and the traffic, the analysis compares ALOHA, slotted ALOHA, persistent and non-persistent
    CSMA. Under these assumptions, ALOHA achieves a channel utilization of only 18.4%
    of the channel capacity. Slotted ALOHA is able to use 36.6% of this capacity.
    Persistent CSMA improves the utilization by reaching 52.9% of the capacity while
    non-persistent CSMA achieves 81.5% of the channel capacity.  ### Carrier Sense
    Multiple Access with Collision Detection[#](#carrier-sense-multiple-access-with-collision-detection
    "Link to this heading")'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: '[[KT1975]](../bibliography.html#kt1975) 详细分析了几个CSMA变体的性能。在关于传输信道和流量的某些假设下，该分析比较了ALOHA、时隙ALOHA、持续和非持续CSMA。在这些假设下，ALOHA的信道利用率仅为信道容量的18.4%。时隙ALOHA能够使用36.6%的容量。持续CSMA通过达到52.9%的容量来提高利用率，而非持续CSMA实现了信道容量的81.5%。  ###
    带冲突检测的载波监听多路访问[#](#carrier-sense-multiple-access-with-collision-detection "链接到本标题")'
- en: CSMA improves channel utilization compared to ALOHA. However, the performance
    can still be improved, especially in wired networks. Consider the situation of
    two terminals that are connected to the same cable. This cable could, for example,
    be a coaxial cable as in the early days of Ethernet [[Metcalfe1976]](../bibliography.html#metcalfe1976).
    It could also be built with twisted pairs. Before extending CSMA, it is useful
    to understand, more intuitively, how frames are transmitted in such a network
    and how collisions can occur. The figure below illustrates the physical transmission
    of a frame on such a cable. To transmit its frame, host A must send an electrical
    signal on the shared medium. The first step is thus to begin the transmission
    of the electrical signal. This is point (1) in the figure below. This electrical
    signal will travel along the cable. Although electrical signals travel fast, we
    know that information cannot travel faster than the speed of light (i.e. 300.000
    kilometers/second). On a coaxial cable, an electrical signal is slightly slower
    than the speed of light and 200.000 kilometers per second is a reasonable estimation.
    This implies that if the cable has a length of one kilometer, the electrical signal
    will need 5 microseconds to travel from one end of the cable to the other. The
    ends of coaxial cables are equipped with termination points that ensure that the
    electrical signal is not reflected back to its source. This is illustrated at
    point (3) in the figure, where the electrical signal has reached the left endpoint
    and host B. At this point, B starts to receive the frame being transmitted by
    A. Notice that there is a delay between the transmission of a bit on host A and
    its reception by host B. If there were other hosts attached to the cable, they
    would receive the first bit of the frame at slightly different times. As we will
    see later, this timing difference is a key problem for MAC algorithms. At point
    (4), the electrical signal has reached both ends of the cable and occupies it
    completely. Host A continues to transmit the electrical signal until the end of
    the frame. As shown at point (5), when the sending host stops its transmission,
    the electrical signal corresponding to the end of the frame leaves the coaxial
    cable. The channel becomes empty again once the entire electrical signal has been
    removed from the cable.
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: CSMA相比ALOHA提高了信道利用率。然而，性能仍然可以进一步提高，尤其是在有线网络中。考虑两个终端连接到同一电缆的情况。例如，这条电缆可以是像以太网早期那样使用的同轴电缆
    [[Metcalfe1976]](../bibliography.html#metcalfe1976)。它也可以由双绞线构建。在扩展CSMA之前，了解这样的网络中帧的传输方式和碰撞如何发生是有用的。下面的图示说明了在这样的电缆上帧的物理传输。为了传输其帧，主机A必须在共享介质上发送一个电信号。因此，第一步是开始传输电信号。这在下面的图中表示为点（1）。这个电信号将沿着电缆传播。尽管电信号传播得很快，但我们知道信息不能比光速传播得更快（即每秒300,000公里）。在同轴电缆上，电信号略慢于光速，每秒200,000公里是一个合理的估计。这意味着如果电缆长度为一公里，电信号需要5微秒才能从电缆的一端传播到另一端。同轴电缆的末端装有终止点，以确保电信号不会反射回其源头。这在图中的点（3）中得到了说明，其中电信号已经到达左端点和主机B。在这个时候，B开始接收A正在传输的帧。请注意，在主机A上传输一个比特和主机B接收它之间存在延迟。如果有其他主机连接到电缆上，它们会在不同时间接收到帧的第一个比特。正如我们稍后将会看到的，这种时间差异是MAC算法的一个关键问题。在点（4）处，电信号已经到达电缆的两端并完全占据它。主机A继续传输电信号，直到帧的结束。如图（5）所示，当发送主机停止传输时，对应于帧结束的电信号离开同轴电缆。一旦整个电信号从电缆中移除，信道再次变为空闲。
- en: '[![../_images/frame-bus.png](../Images/ab89b8b4019e54d32dc8e8a85f104ba1.png)](../_images/frame-bus.png)'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/frame-bus.png](../Images/ab89b8b4019e54d32dc8e8a85f104ba1.png)'
- en: Fig. 197 Frame transmission on a shared bus[#](#id85 "Link to this image")
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 图197 共享总线上的帧传输[#](#id85 "链接到这张图片")
- en: Now that we have looked at how a frame is actually transmitted as an electrical
    signal on a shared bus, it is interesting to look in more detail at what happens
    when two hosts transmit a frame at almost the same time. This is illustrated in
    the figure below, where hosts A and B start their transmission at the same time
    (point (1)). At this time, if host C senses the channel, it will consider it to
    be free. This will not last a long time and at point (2) the electrical signals
    from both host A and host B reach host C. The combined electrical signal (shown
    graphically as the superposition of the two curves in the figure) cannot be decoded
    by host C. Host C detects a collision, as it receives a signal that it cannot
    decode. Since host C cannot decode the frames, it cannot determine which hosts
    are sending the colliding frames. Note that host A (and host B) will detect the
    collision after host C (point (3) in figure [Fig. 198](#fig-collision-bus)).
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了帧是如何作为一个电信号在共享总线上传输的，那么详细观察当两个主机几乎同时发送帧时会发生什么就很有趣了。这如图所示，其中主机A和主机B同时开始传输（点（1））。在这个时候，如果主机C检测到信道，它将认为它是空闲的。这种情况不会持续太久，在点（2）时，主机A和主机B的电信号都到达了主机C。合并后的电信号（如图中两个曲线的叠加所示）无法被主机C解码。主机C检测到冲突，因为它接收到了它无法解码的信号。由于主机C无法解码帧，它无法确定哪些主机正在发送冲突的帧。请注意，主机A（以及主机B）将在主机C之后检测到冲突（如图[图198](#fig-collision-bus)中的点（3））。
- en: '[![../_images/frame-collision.png](../Images/7b88fb2c9cc28c5857f616b145a56cb6.png)](../_images/frame-collision.png)'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: '[![../_images/frame-collision.png](../Images/7b88fb2c9cc28c5857f616b145a56cb6.png)](../_images/frame-collision.png)'
- en: Fig. 198 Frame collision on a shared bus[#](#fig-collision-bus "Link to this
    image")
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 图198 共享总线上的帧冲突[#](#fig-collision-bus "链接到这张图片")
- en: As shown above, hosts detect collisions when they receive an electrical signal
    that they cannot decode. In a wired network, a host is able to detect such a collision
    both while it is listening (e.g. like host C in the figure above) and also while
    it is sending its own frame. When a host transmits a frame, it can compare the
    electrical signal that it transmits with the electrical signal that it senses
    on the wire. At points (1) and (2) in the figure above, host A senses only its
    own signal. At point (3), it senses an electrical signal that differs from its
    own signal and can thus detects the collision. At this point, its frame is corrupted
    and it can stop its transmission. The ability to detect collisions while transmitting
    is the starting point for the Carrier Sense Multiple Access with Collision Detection
    (CSMA/CD) Medium Access Control algorithm, which is used in Ethernet networks
    [[Metcalfe1976]](../bibliography.html#metcalfe1976) [[IEEE802.3]](../bibliography.html#ieee802-3)
    . When an Ethernet host detects a collision while it is transmitting, it immediately
    stops its transmission. Compared with pure CSMA, CSMA/CD is an important improvement
    since when collisions occur, they only last until colliding hosts have detected
    it and stopped their transmission. In practice, when a host detects a collision,
    it sends a special jamming signal on the cable to ensure that all hosts have detected
    the collision.
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所示，当主机接收到它无法解码的电信号时，它们会检测到冲突。在有线的网络中，主机能够在监听时（例如，如图中所示的主机C）以及发送自己的帧时检测到这样的冲突。当主机发送一个帧时，它可以比较它发送的电信号与它在电线上感知到的电信号。在上图中的点（1）和（2）时，主机A只感知到它自己的信号。在点（3）时，它感知到一个与自己的信号不同的电信号，因此可以检测到冲突。在这个时候，它的帧被损坏，它可以停止传输。在传输过程中检测冲突的能力是载波侦听多路访问与冲突检测（CSMA/CD）介质访问控制算法的起点，该算法用于以太网网络[[Metcalfe1976]](../bibliography.html#metcalfe1976)
    [[IEEE802.3]](../bibliography.html#ieee802-3)。当以太网主机在传输过程中检测到冲突时，它会立即停止传输。与纯CSMA相比，CSMA/CD是一个重要的改进，因为当发生冲突时，它们只会持续到冲突的主机检测到并停止它们的传输。实际上，当主机检测到冲突时，它会在电缆上发送一个特殊的干扰信号，以确保所有主机都检测到了冲突。
- en: To better understand these collisions, it is useful to analyze what would be
    the worst collision on a shared bus network. Let us consider a wire with two hosts
    attached at both ends, as shown in the figure below. Host A starts to transmit
    its frame and its electrical signal is propagated on the cable. Its propagation
    time depends on the physical length of the cable and the speed of the electrical
    signal. Let us use \(\tau\) to represent this propagation delay in seconds. Slightly
    less than \(\tau\) seconds after the beginning of the transmission of A’s frame,
    B decides to start transmitting its own frame. After \(\epsilon\) seconds, B senses
    A’s frame, detects the collision and stops transmitting. The beginning of B’s
    frame travels on the cable until it reaches host A. Host A can thus detect the
    collision at time \(\tau-\epsilon+\tau \approx 2\times\tau\). An important point
    to note is that a collision can only occur during the first \(2\times\tau\) seconds
    of its transmission. If a collision did not occur during this period, it cannot
    occur afterwards since the transmission channel is busy after \(\tau\) seconds
    and CSMA/CD hosts sense the transmission channel before transmitting their frame.
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解这些碰撞，分析在共享总线网络中最糟糕的碰撞情况是有用的。让我们考虑一个两端连接有两个主机的电线，如图所示。主机A开始传输其帧，其电信号在电缆上传播。其传播时间取决于电缆的物理长度和电信号的速度。让我们用
    \(\tau\) 来表示这种传播延迟（以秒为单位）。在A的帧传输开始后略少于 \(\tau\) 秒，B决定开始传输自己的帧。经过 \(\epsilon\)
    秒后，B检测到A的帧，检测到碰撞并停止传输。B的帧的开始在电缆上传播，直到它到达主机A。因此，主机A可以在 \(\tau-\epsilon+\tau \approx
    2\times\tau\) 时刻检测到碰撞。需要注意的是，碰撞只能在传输的前 \(2\times\tau\) 秒内发生。如果在这一时期内没有发生碰撞，那么之后也不会发生，因为传输通道在
    \(\tau\) 秒后变得繁忙，并且 CSMA/CD 主机在传输帧之前会检测传输通道。
- en: '[![../_images/frame-collision-worst.png](../Images/cb963f4bef31245667608aad2e590553.png)](../_images/frame-collision-worst.png)'
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: '[![../_images/frame-collision-worst.png](../Images/cb963f4bef31245667608aad2e590553.png)](../_images/frame-collision-worst.png)'
- en: Fig. 199 The worst collision on a shared bus[#](#id86 "Link to this image")
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 图199 共享总线上的最糟糕的碰撞[#](#id86 "链接到这张图片")
- en: Furthermore, on the wired networks where CSMA/CD is used, collisions are almost
    the only cause of transmission errors that affect frames. Transmission errors
    that only affect a few bits inside a frame seldom occur in these wired networks.
    For this reason, the designers of CSMA/CD chose to completely remove the acknowledgment
    frames in the datalink layer. When a host transmits a frame, it verifies whether
    its transmission has been affected by a collision. If not, given the negligible
    Bit Error Ratio of the underlying network, it assumes that the frame was received
    correctly by its destination. Otherwise the frame is retransmitted after some
    delay.
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在采用 CSMA/CD 的有线网络中，碰撞几乎是影响帧的传输错误的唯一原因。在这些有线网络中，仅影响帧内少数比特的传输错误很少发生。因此，CSMA/CD
    的设计者选择在数据链路层完全删除确认帧。当主机传输一个帧时，它会验证其传输是否受到碰撞的影响。如果没有，考虑到底层网络的几乎可以忽略不计的比特错误率，它假设帧已被正确接收。否则，帧将在一段时间后重新传输。
- en: Removing acknowledgments is an interesting optimization as it reduces the number
    of frames that are exchanged on the network and the number of frames that need
    to be processed by the hosts. However, to use this optimization, we must ensure
    that all hosts will be able to detect all the collisions that affect their frames.
    The problem is important for short frames. Let us consider two hosts, A and B,
    that are sending a small frame to host C as illustrated in the figure below. If
    the frames sent by A and B are very short, the situation illustrated below may
    occur. Hosts A and B send their frame and stop transmitting (point (1)). When
    the two short frames arrive at the location of host C, they collide and host C
    cannot decode them (point (2)). The two frames are absorbed by the ends of the
    wire. Neither host A nor host B have detected the collision. They both consider
    their frame to have been received correctly by its destination.
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 移除确认是一种有趣的优化，因为它减少了网络交换的帧数以及主机需要处理的帧数。然而，为了使用这种优化，我们必须确保所有主机都能检测到影响其帧的所有碰撞。对于短帧来说，这个问题很重要。让我们考虑两个主机，A和B，它们向主机C发送一个小帧，如图所示。如果A和B发送的帧非常短，可能会出现以下情况。主机A和B发送它们的帧并停止传输（点（1））。当两个短帧到达主机C的位置时，它们发生碰撞，主机C无法解码它们（点（2））。两个帧被线的两端吸收。主机A和主机B都没有检测到碰撞。他们都认为他们的帧已经正确地被其目的地接收。
- en: '[![../_images/frame-collision-short.png](../Images/9a5d6d727ec45fd15b48e2c3fdc820d7.png)](../_images/frame-collision-short.png)'
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/frame-collision-short.png](../Images/9a5d6d727ec45fd15b48e2c3fdc820d7.png)'
- en: Fig. 200 The short-frame collision problem[#](#id87 "Link to this image")
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: 图200 短帧碰撞问题[#](#id87 "链接到这张图片")
- en: To solve this problem, networks using CSMA/CD require hosts to transmit for
    at least \(2\times\tau\) seconds. Since the network transmission speed is fixed
    for a given network technology, this implies that a technology that uses CSMA/CD
    enforces a minimum frame size. In the most popular CSMA/CD technology, Ethernet,
    \(2\times\tau\) is called the slot time [[4]](#fslottime).
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，使用CSMA/CD的网络要求主机至少传输\(2\times\tau\)秒。由于网络传输速度对于给定的网络技术是固定的，这意味着使用CSMA/CD的技术强制执行最小帧大小。在最受欢迎的CSMA/CD技术以太网中，\(2\times\tau\)被称为时隙时间
    [[4]](#fslottime)。
- en: The last innovation introduced by CSMA/CD is the computation of the retransmission
    timeout. As for ALOHA, this timeout cannot be fixed, otherwise hosts could become
    synchronized and always retransmit at the same time. Setting such a timeout is
    always a compromise between the network access delay and the amount of collisions.
    A short timeout would lead to a low network access delay but with a higher risk
    of collisions. On the other hand, a long timeout would cause a long network access
    delay but a lower risk of collisions. The binary exponential back-off algorithm
    was introduced in CSMA/CD networks to solve this problem.
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: CSMA/CD引入的最后一个创新是重传超时的计算。至于ALOHA，这个超时不能固定，否则主机可能会同步并且总是同时重传。设置这样的超时总是在网络访问延迟和碰撞数量之间做出妥协。超时时间短会导致网络访问延迟低，但碰撞风险高。另一方面，超时时间长会导致网络访问延迟长，但碰撞风险低。为了解决这个问题，CSMA/CD网络中引入了二进制指数退避算法。
- en: 'To understand binary exponential back-off, let us consider a collision caused
    by exactly two hosts. Once it has detected the collision, a host can either retransmit
    its frame immediately or defer its transmission for some time. If each colliding
    host flips a coin to decide whether to retransmit immediately or to defer its
    retransmission, four cases are possible :'
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解二进制指数退避，让我们考虑由恰好两个主机引起的碰撞。一旦检测到碰撞，主机可以立即重传其帧或推迟其传输一段时间。如果每个碰撞的主机抛硬币来决定是否立即重传或推迟重传，可能出现四种情况：
- en: Both hosts retransmit immediately and a new collision occurs
  id: totrans-523
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 两个主机立即重传，并发生新的碰撞
- en: ''
  id: totrans-524
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-525
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: The first host retransmits immediately and the second defers its retransmission
  id: totrans-526
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一个主机立即重传，而第二个主机推迟其重传
- en: ''
  id: totrans-527
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-528
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: The second host retransmits immediately and the first defers its retransmission
  id: totrans-529
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二个主机立即重传，而第一个主机推迟其重传
- en: ''
  id: totrans-530
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-531
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Both hosts defer their retransmission and a new collision occurs
  id: totrans-532
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 两个主机推迟重传，并发生新的碰撞
- en: In the second and third cases, both hosts have flipped different coins. The
    delay chosen by the host that defers its retransmission should be long enough
    to ensure that its retransmission will not collide with the immediate retransmission
    of the other host. However the delay should not be longer than the time necessary
    to avoid the collision, because if both hosts decide to defer their transmission,
    the network will be idle during this delay. The slot time is the optimal delay
    since it is the shortest delay that ensures that the first host will be able to
    retransmit its frame completely without any collision.
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二种和第三种情况下，两个主机抛出了不同的硬币。延迟选择延迟重传的主机应该足够长，以确保其重传不会与另一个主机的即时重传发生冲突。然而，延迟不应超过避免冲突所需的时间，因为如果两个主机都决定延迟它们的传输，网络将在这种延迟期间空闲。时隙时间是最佳延迟，因为它是最短的延迟，可以确保第一个主机能够完全重传其帧而不会发生任何冲突。
- en: If two hosts are competing, the algorithm above will avoid a second collision
    50% of the time. However, if the network is heavily loaded, several hosts may
    be competing at the same time. In this case, the hosts should be able to automatically
    adapt their retransmission delay. The binary exponential back-off performs this
    adaptation based on the number of collisions that have affected a frame. After
    the first collision, the host flips a coin and waits 0 or 1 slot time. After the
    second collision, it generates a random number and waits 0, 1, 2 or 3 slot times,
    etc. The duration of the waiting time is doubled after each collision. The complete
    pseudo-code for the CSMA/CD algorithm is shown in the figure below.
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: 如果两个主机正在竞争，上述算法将避免50%的第二次冲突。然而，如果网络负载很重，可能同时有多个主机在竞争。在这种情况下，主机应该能够自动调整它们的重传延迟。二进制指数退避算法根据受影响的帧的冲突次数进行这种调整。在第一次冲突后，主机抛硬币并等待0或1个时隙时间。在第二次冲突后，它生成一个随机数并等待0、1、2或3个时隙时间，等等。每次冲突后，等待时间都会加倍。等待时间的长度在每次冲突后都会加倍。CSMA/CD算法的完整伪代码如图所示。
- en: '[PRE13]'
  id: totrans-535
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The inter-frame delay used in this pseudo-code is a short delay corresponding
    to the time required by a network adapter to switch from transmit to receive mode.
    It is also used to prevent a host from sending a continuous stream of frames without
    leaving any transmission opportunities for other hosts on the network. This contributes
    to the fairness of CSMA/CD. Despite this delay, there are still conditions where
    CSMA/CD is not completely fair [[RY1994]](../bibliography.html#ry1994). Consider
    for example a network with two hosts : a server sending long frames and a client
    sending acknowledgments. Measurements reported in [[RY1994]](../bibliography.html#ry1994)
    have shown that there are situations where the client could suffer from repeated
    collisions that lead it to wait for long periods of time due to the exponential
    back-off algorithm.  ### Carrier Sense Multiple Access with Collision Avoidance[#](#carrier-sense-multiple-access-with-collision-avoidance
    "Link to this heading")'
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: 在此伪代码中使用的帧间延迟是一个短延迟，对应于网络适配器从发送模式切换到接收模式所需的时间。它还用于防止主机发送连续的帧流，而不给网络上的其他主机留下任何传输机会。这有助于CSMA/CD的公平性。尽管有这种延迟，仍然存在CSMA/CD不完全公平的情况[[RY1994]](../bibliography.html#ry1994)。例如，考虑一个有两个主机的网络：一个服务器发送长帧，一个客户端发送确认。[[RY1994]](../bibliography.html#ry1994)中报告的测量结果表明，存在客户端可能因指数退避算法而遭受重复冲突的情况，这导致它需要长时间等待。
- en: The Carrier Sense Multiple Access with Collision Avoidance (CSMA/CA) Medium
    Access Control algorithm was designed for the popular WiFi wireless network technology
    [[IEEE802.11]](../bibliography.html#ieee802-11). CSMA/CA also senses the transmission
    channel before transmitting a frame. Furthermore, CSMA/CA tries to avoid collisions
    by carefully tuning the timers used by CSMA/CA devices.
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: 带有冲突避免的载波侦听多路访问（CSMA/CA）介质访问控制算法是为流行的WiFi无线网络技术设计的[[IEEE802.11]](../bibliography.html#ieee802-11)。CSMA/CA在发送帧之前也会侦听传输通道。此外，CSMA/CA通过仔细调整CSMA/CA设备使用的计时器来尝试避免冲突。
- en: CSMA/CA uses acknowledgments like CSMA. Each frame contains a sequence number
    and a CRC. The CRC is used to detect transmission errors while the sequence number
    is used to avoid frame duplication. When a device receives a correct frame, it
    returns a special acknowledgment frame to the sender. CSMA/CA introduces a small
    delay, named Short Inter Frame Spacing (SIFS), between the reception of a frame
    and the transmission of the acknowledgment frame. This delay corresponds to the
    time that is required to switch the radio of a device between the reception and
    transmission modes.
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: CSMA/CA使用类似于CSMA的确认。每个帧包含一个序列号和一个CRC。CRC用于检测传输错误，而序列号用于避免帧重复。当设备接收到正确的帧时，它会向发送者返回一个特殊的确认帧。CSMA/CA在接收帧和传输确认帧之间引入了一个小的延迟，称为短帧间间隔（SIFS）。这个延迟对应于设备在接收和传输模式之间切换无线电所需的时间。
- en: 'Compared to CSMA, CSMA/CA defines more precisely when a device is allowed to
    send a frame. First, CSMA/CA defines two delays : DIFS and EIFS. To send a frame,
    a device must first wait until the channel has been idle for at least the Distributed
    Coordination Function Inter Frame Space (DIFS) if the previous frame was received
    correctly. However, if the previously received frame was corrupted, this indicates
    that there are collisions and the device must sense the channel idle for at least
    the Extended Inter Frame Space (EIFS), with \(SIFS<DIFS<EIFS\). The exact values
    for SIFS, DIFS and EIFS depend on the underlying physical layer [[IEEE802.11]](../bibliography.html#ieee802-11).'
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: 与CSMA相比，CSMA/CA更精确地定义了设备何时可以发送帧。首先，CSMA/CA定义了两个延迟：DIFS和EIFS。为了发送帧，设备必须首先等待信道至少空闲了分布式协调功能帧间空间（DIFS）的时间，如果之前接收到的帧是正确的。然而，如果之前接收到的帧已损坏，这表明存在冲突，设备必须检测信道空闲至少为扩展帧间空间（EIFS），其中\(SIFS<DIFS<EIFS\)。SIFS、DIFS和EIFS的确切值取决于底层物理层
    [[IEEE802.11]](../bibliography.html#ieee802-11)。
- en: The figure below shows the basic operation of CSMA/CA devices. Before transmitting,
    host A verifies that the channel is empty for a long enough period. Then, its
    sends its data frame. After checking the validity of the received frame, the recipient
    sends an acknowledgment frame after a short SIFS delay. Host C, which does not
    participate in the frame exchange, senses the channel to be busy at the beginning
    of the data frame. Host C can use this information to determine how long the channel
    will be busy for. Note that as \(SIFS<DIFS<EIFS\), even a device that would start
    to sense the channel immediately after the last bit of the data frame could not
    decide to transmit its own frame during the transmission of the acknowledgment
    frame.
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了CSMA/CA设备的基本操作。在传输之前，主机A验证信道在足够长的时间内是空闲的。然后，它发送其数据帧。在检查接收到的帧的有效性后，接收者在短暂的SIFS延迟后发送一个确认帧。不参与帧交换的主机C在数据帧的开始时检测到信道是忙碌的。主机C可以使用这个信息来确定信道将忙碌多长时间。请注意，由于\(SIFS<DIFS<EIFS\)，即使在数据帧的最后一位之后立即开始检测信道的设备，也无法在确认帧传输期间决定发送自己的帧。
- en: '[![../_images/csmaca-1.png](../Images/a384b3211b0772e04aaf1c46baf44b77.png)](../_images/csmaca-1.png)'
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/csmaca-1.png](../Images/a384b3211b0772e04aaf1c46baf44b77.png)'
- en: Fig. 201 Operation of a CSMA/CA device[#](#id88 "Link to this image")
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: 图201 CSMA/CA设备的工作原理[#](#id88 "链接到这张图片")
- en: The main difficulty with CSMA/CA is when two or more devices transmit at the
    same time and cause collisions. This is illustrated in the figure below, assuming
    a fixed timeout after the transmission of a data frame. With CSMA/CA, the timeout
    after the transmission of a data frame is very small, since it corresponds to
    the SIFS plus the time required to transmit the acknowledgment frame.
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: CSMA/CA的主要困难在于当两个或更多设备同时传输并引起冲突时。这在下图中得到说明，假设在数据帧传输后有一个固定的超时时间。使用CSMA/CA时，数据帧传输后的超时时间非常小，因为它对应于SIFS加上传输确认帧所需的时间。
- en: '[![../_images/csmaca-2.png](../Images/0dbf88b43018a324dcb149e4a1fe2cae.png)](../_images/csmaca-2.png)'
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/csmaca-2.png](../Images/0dbf88b43018a324dcb149e4a1fe2cae.png)'
- en: Fig. 202 Collisions with CSMA/CA[#](#id89 "Link to this image")
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: 图202 CSMA/CA的冲突[#](#id89 "链接到这张图片")
- en: To deal with this problem, CSMA/CA relies on a backoff timer. This backoff timer
    is a random delay that is chosen by each device in a range that depends on the
    number of retransmissions for the current frame. The range grows exponentially
    with the retransmissions as in CSMA/CD. The minimum range for the backoff timer
    is \([0,7*slotTime]\) where the slotTime is a parameter that depends on the underlying
    physical layer. Compared to CSMA/CD’s exponential backoff, there are two important
    differences to notice. First, the initial range for the backoff timer is seven
    times larger. This is because it is impossible in CSMA/CA to detect collisions
    as they happen. With CSMA/CA, a collision may affect the entire frame while with
    CSMA/CD it can only affect the beginning of the frame. Second, a CSMA/CA device
    must regularly sense the transmission channel during its back off timer. If the
    channel becomes busy (i.e. because another device is transmitting), then the back
    off timer must be frozen until the channel becomes free again. Once the channel
    becomes free, the back off timer is restarted. This is in contrast with CSMA/CD
    where the back off is recomputed after each collision. This is illustrated in
    the figure below. Host A chooses a smaller backoff than host C. When C senses
    the channel to be busy, it freezes its backoff timer and only restarts it once
    the channel is free again.
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理这个问题，CSMA/CA依赖于一个退避计时器。这个退避计时器是一个随机延迟，由每个设备在当前帧的重传次数所决定的范围内选择。范围随着重传次数呈指数增长，就像在CSMA/CD中一样。退避计时器的最小范围是\([0,7*slotTime]\)，其中slotTime是一个依赖于底层物理层的参数。与CSMA/CD的指数退避相比，有两个重要的不同点需要注意。首先，退避计时器的初始范围是七倍之大。这是因为CSMA/CA中无法检测到发生的碰撞。使用CSMA/CA时，一个碰撞可能会影响整个帧，而CSMA/CD则只能影响帧的开始部分。其次，一个CSMA/CA设备必须在它的退避计时器期间定期检测传输通道。如果通道变得繁忙（即，因为另一个设备正在传输），那么退避计时器必须被冻结，直到通道再次变得空闲。一旦通道变得空闲，退避计时器重新启动。这与CSMA/CD不同，在每次碰撞后都会重新计算退避。这在下图中得到了说明。主机A选择的退避时间比主机C小。当C检测到通道繁忙时，它会冻结其退避计时器，并且只有在通道再次空闲时才会重新启动。
- en: '[![../_images/csmaca-3.png](../Images/9634d388481fa8d42a5b4b7de8b205c0.png)](../_images/csmaca-3.png)'
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: '![CSMA/CA-3](../_images/csmaca-3.png)'
- en: Fig. 203 Detailed example with CSMA/CA[#](#id90 "Link to this image")
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: 图203 CSMA/CA的详细示例[#](#id90 "链接到这个图像")
- en: The pseudo-code below summarizes the operation of a CSMA/CA device. The values
    of the SIFS, DIFS, EIFS and \(slotTime\) depend on the underlying physical layer
    technology [[IEEE802.11]](../bibliography.html#ieee802-11)
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的伪代码总结了CSMA/CA设备的工作原理。SIFS、DIFS、EIFS和\(slotTime\)的值取决于底层物理层技术 [[IEEE802.11]](../bibliography.html#ieee802-11)
- en: '[PRE14]'
  id: totrans-550
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Another problem faced by wireless networks is often called the hidden station
    problem. In a wireless network, radio signals are not always propagated same way
    in all directions. For example, two devices separated by a wall may not be able
    to receive each other’s signal while they could both be receiving the signal produced
    by a third host. This is illustrated in the figure below, but it can happen in
    other environments. For example, two devices that are on different sides of a
    hill may not be able to receive each other’s signal while they are both able to
    receive the signal sent by a station at the top of the hill. Furthermore, the
    radio propagation conditions may change with time. For example, a truck may temporarily
    block the communication between two nearby devices.
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: 无线网络面临的另一个问题通常被称为隐藏站问题。在无线网络中，无线电信号并不总是以相同的方式向所有方向传播。例如，被墙壁隔开的两个设备可能无法接收彼此的信号，尽管它们都能接收由第三个主机产生的信号。这在下图中得到了说明，但这种情况也可能发生在其他环境中。例如，位于山的不同侧的两个设备可能无法接收彼此的信号，尽管它们都能接收山顶站发送的信号。此外，无线电传播条件可能会随时间变化。例如，一辆卡车可能会暂时阻断两个附近设备之间的通信。
- en: '[![../_images/csmaca-hidden.png](../Images/1dd2db4f7a4f3df51403915d42254672.png)](../_images/csmaca-hidden.png)'
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: '![CSMA/CA隐藏问题](../_images/csmaca-hidden.png)'
- en: Fig. 204 The hidden station problem[#](#id91 "Link to this image")
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: 图204 隐藏站问题[#](#id91 "链接到这个图像")
- en: 'To avoid collisions in these situations, CSMA/CA allows devices to reserve
    the transmission channel for some time. This is done by using two control frames
    : Request To Send (RTS) and Clear To Send (CTS). Both are very short frames to
    minimize the risk of collisions. To reserve the transmission channel, a device
    sends a RTS frame to the intended recipient of the data frame. The RTS frame contains
    the duration of the requested reservation. The recipient replies, after a SIFS
    delay, with a CTS frame which also contains the duration of the reservation. As
    the duration of the reservation has been sent in both RTS and CTS, all hosts that
    could collide with either the sender or the reception of the data frame are informed
    of the reservation. They can compute the total duration of the transmission and
    defer their access to the transmission channel until then. This is illustrated
    in the figure below where host A reserves the transmission channel to send a data
    frame to host B. Host C notices the reservation and defers its transmission.'
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免在这些情况下发生碰撞，CSMA/CA允许设备预留传输信道一段时间。这是通过使用两个控制帧来完成的：请求发送（RTS）和允许发送（CTS）。这两个帧都非常短，以最大限度地减少碰撞的风险。为了预留传输信道，设备向数据帧的预期接收者发送一个RTS帧。RTS帧包含请求预留的持续时间。接收者在SIFS延迟后回复一个CTS帧，该帧也包含预留的持续时间。由于预留的持续时间已经在RTS和CTS中发送，所有可能与其他发送者或接收数据帧的接收者发生碰撞的主机都会被告知预留情况。它们可以计算传输的总持续时间，并在那时推迟对传输信道的访问。这在下图中得到说明，其中主机A预留传输信道以向主机B发送数据帧。主机C注意到预留并推迟了其传输。
- en: '[![../_images/csmaca-reserv.png](../Images/d32c0a1c69694ffdbad7f26e535e2135.png)](../_images/csmaca-reserv.png)'
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: '![![../_images/csmaca-reserv.png](../Images/d32c0a1c69694ffdbad7f26e535e2135.png)](../_images/csmaca-reserv.png)'
- en: Fig. 205 Reservations with CSMA/CA[#](#id92 "Link to this image")
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: 图. 205 CSMA/CA中的预留[#](#id92 "链接到此图像")
- en: The utilization of the reservations with CSMA/CA is an optimization that is
    useful when collisions are frequent. If there are few collisions, the time required
    to transmit the RTS and CTS frames can become significant and in particular when
    short frames are exchanged. Some devices only turn on RTS/CTS after transmission
    errors.
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: 在碰撞频繁的情况下，使用CSMA/CA进行预留是一种有用的优化。如果碰撞很少，传输RTS和CTS帧所需的时间可能会变得显著，尤其是在交换短帧时。一些设备仅在传输错误后才会开启RTS/CTS。
- en: Deterministic Medium Access Control algorithms[#](#deterministic-medium-access-control-algorithms
    "Link to this heading")
  id: totrans-558
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 确定性介质访问控制算法[#](#deterministic-medium-access-control-algorithms "链接到本标题")
- en: During the 1970s and 1980s, there were huge debates in the networking community
    about the best suited Medium Access Control algorithms for Local Area Networks.
    The optimistic algorithms that we have described until now were relatively easy
    to implement when they were designed. From a performance perspective, mathematical
    models and simulations showed the ability of these optimistic techniques to sustain
    load. However, none of the optimistic techniques are able to guarantee that a
    frame will be delivered within a given delay bound and some applications require
    predictable transmission delays. The deterministic MAC algorithms were considered
    by a fraction of the networking community as the best solution to fulfill the
    needs of Local Area Networks.
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: 在20世纪70年代和80年代，网络社区就最适合局域网的介质访问控制算法进行了激烈的辩论。我们之前描述的乐观算法在设计时相对容易实现。从性能角度来看，数学模型和模拟显示这些乐观技术能够维持负载。然而，没有任何一种乐观技术能够保证在给定的延迟界限内交付一个帧，而某些应用需要可预测的传输延迟。确定性MAC算法被网络社区中的一部分人视为满足局域网需求的最佳解决方案。
- en: Both the proponents of the deterministic and the opportunistic techniques lobbied
    to develop standards for Local Area networks that would incorporate their solution.
    Instead of trying to find an impossible compromise between these diverging views,
    the IEEE 802 committee that was chartered to develop Local Area Network standards
    chose to work in parallel on three different LAN technologies and created three
    working groups. The [IEEE 802.3 working group](http://www.ieee802.org/3/) became
    responsible for CSMA/CD. The proponents of deterministic MAC algorithms agreed
    on the basic principle of exchanging special frames called tokens between devices
    to regulate the access to the transmission medium. However, they did not agree
    on the most suitable physical layout for the network. IBM argued in favor of Ring-shaped
    networks while the manufacturing industry, led by General Motors, argued in favor
    of a bus-shaped network. This led to the creation of the [IEEE 802.4 working group](http://www.ieee802.org/4/)
    to standardize Token Bus networks and the [IEEE 802.5 working group](http://www.ieee802.org/5/)
    to standardize Token Ring networks. Although these techniques are not widely used
    anymore today, the principles behind a token-based protocol are still important.
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: 确定性技术和机会主义技术的支持者都游说制定适用于局域网的标准，以纳入他们的解决方案。而不是试图在这两种分歧的观点之间找到一个不可能的折中方案，负责制定局域网标准的
    IEEE 802 委员会决定并行工作在三种不同的局域网技术上，并创建了三个工作组。[IEEE 802.3 工作组](http://www.ieee802.org/3/)
    负责CSMA/CD。确定性 MAC 算法的支持者就交换称为令牌的特殊帧以调节对传输介质访问的基本原则达成一致。然而，他们并没有就网络最合适的物理布局达成一致。IBM
    支持环形网络，而由通用汽车领导的制造业则支持总线形网络。这导致了 [IEEE 802.4 工作组](http://www.ieee802.org/4/) 的成立，以标准化令牌总线网络，以及
    [IEEE 802.5 工作组](http://www.ieee802.org/5/) 的成立，以标准化令牌环网络。尽管这些技术今天不再广泛使用，但基于令牌的协议背后的原理仍然很重要。
- en: The IEEE 802.5 Token Ring technology is defined in [[IEEE802.5]](../bibliography.html#ieee802-5).
    We use Token Ring as an example to explain the principles of the token-based MAC
    algorithms in ring-shaped networks. Other ring-shaped networks include the defunct
    FDDI [[Ross1989]](../bibliography.html#ross1989) or Resilient Pack Ring [[DYGU2004]](../bibliography.html#dygu2004)
    . A good survey of the early token ring networks may be found in [[Bux1989]](../bibliography.html#bux1989)
    .
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: IEEE 802.5 令牌环技术定义在 [[IEEE802.5]](../bibliography.html#ieee802-5) 中。我们以令牌环为例来解释环形网络中基于令牌的
    MAC 算法原理。其他环形网络包括已废弃的 FDDI [[Ross1989]](../bibliography.html#ross1989) 或弹性包环 [[DYGU2004]](../bibliography.html#dygu2004)。早期令牌环网络的良好综述可以在
    [[Bux1989]](../bibliography.html#bux1989) 中找到。
- en: 'A Token Ring network is composed of a set of stations that are attached to
    a unidirectional ring. The basic principle of the Token Ring MAC algorithm is
    that two types of frames travel on the ring : tokens and data frames. When the
    Token Ring starts, one of the stations sends the token. The token is a small frame
    that represents the authorization to transmit data frames on the ring. To transmit
    a data frame on the ring, a station must first capture the token by removing it
    from the ring. As only one station can capture the token at a time, the station
    that owns the token can safely transmit a data frame on the ring without risking
    collisions. After having transmitted its frame, the station must remove it from
    the ring and resend the token so that other stations can transmit their own frames.'
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: 令牌环网络由一组连接到单向环上的站点组成。令牌环 MAC 算法的基本原理是，两种类型的帧在环上传输：令牌和数据帧。当令牌环启动时，其中一个站点发送令牌。令牌是一个表示在环上传输数据帧的授权的小帧。要传输数据帧到环上，一个站点必须首先通过从环上移除它来捕获令牌。由于一次只能有一个站点捕获令牌，拥有令牌的站点可以在不冒风险发生冲突的情况下安全地在环上传输数据帧。在传输完其帧后，该站点必须将其从环上移除并重新发送令牌，以便其他站点可以传输它们自己的帧。
- en: '[![../_images/token-ring.png](../Images/204991c6fea7862f915a3396c1578736.png)](../_images/token-ring.png)'
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/token-ring.png](../Images/204991c6fea7862f915a3396c1578736.png)'
- en: Fig. 206 A Token Ring network[#](#id93 "Link to this image")
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: 图 206 令牌环网络[#](#id93 "链接到这张图片")
- en: While the basic principles of the Token Ring are simple, there are several subtle
    implementation details that add complexity to Token Ring networks. To understand
    these details let us analyze the operation of a Token Ring interface on a station.
    A Token Ring interface serves three different purposes. Like other LAN interfaces,
    it must be able to send and receive frames. In addition, a Token Ring interface
    is part of the ring, and as such, it must be able to forward the electrical signal
    that passes on the ring even when its station is powered off.
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管令牌环的基本原理简单，但其中包含一些细微的实现细节，这些细节增加了令牌环网络的复杂性。为了理解这些细节，让我们分析一个站点上令牌环接口的操作。令牌环接口有三个不同的作用。与其他局域网接口一样，它必须能够发送和接收帧。此外，令牌环接口是环的一部分，因此它必须能够在其站点断电时转发环上传递的电气信号。
- en: 'When powered-on, Token Ring interfaces operate in two different modes : listen
    and transmit. When operating in listen mode, a Token Ring interface receives an
    electrical signal from its upstream neighbor on the ring, introduces a delay equal
    to the transmission time of one bit on the ring and regenerates the signal before
    sending it to its downstream neighbor on the ring.'
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
  zh: 当开启电源时，令牌环接口以两种不同的模式运行：监听和传输。在监听模式下运行时，令牌环接口从环上的上游邻居接收一个电气信号，在环上引入一个等于一个比特传输时间的延迟，并在将其发送到环上的下游邻居之前再生信号。
- en: The first problem faced by a Token Ring network is that as the token represents
    the authorization to transmit, it must continuously travel on the ring when no
    data frame is being transmitted. Let us assume that a token has been produced
    and sent on the ring by one station. In Token Ring networks, the token is a 24
    bits frame whose structure is shown below.
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
  zh: 令牌环网络面临的第一个问题是，由于令牌代表传输的授权，当没有数据帧正在传输时，令牌必须持续在环上传播。让我们假设一个令牌已经被一个站点产生并发送到环上。在令牌环网络中，令牌是一个24比特的帧，其结构如下所示。
- en: '[![../_images/token-ring.svg](../Images/d3fd5c0099436c887eea9ad8ae351d82.png)](../_images/token-ring.svg)'
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: '![![../_images/token-ring.svg](../Images/d3fd5c0099436c887eea9ad8ae351d82.png)](../_images/token-ring.svg)'
- en: Fig. 207 802.5 token format[#](#id94 "Link to this image")
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: 图. 207 802.5令牌格式[#](#id94 "链接到这张图片")
- en: The token is composed of three fields. First, the Starting Delimiter is the
    marker that indicates the beginning of a frame. The first Token Ring networks
    used Manchester coding and the Starting Delimiter contained both symbols representing
    0 and symbols that do not represent bits. The last field is the Ending Delimiter
    which marks the end of the token. The Access Control field is present in all frames,
    and contains several flags. The most important is the Token bit that is set in
    token frames and reset in other frames.
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: 令牌由三个字段组成。首先，起始定界符是表示帧开始的标记。最初的令牌环网络使用曼彻斯特编码，起始定界符包含表示0的符号和不表示比特的符号。最后一个字段是结束定界符，它标记令牌的结束。访问控制字段存在于所有帧中，并包含几个标志。最重要的是令牌位，它在令牌帧中设置，在其他帧中重置。
- en: Let us consider the five station network depicted in figure [A Token Ring network](#fig-tokenring)
    above and assume that station S1 sends a token. If we neglect the propagation
    delay on the inter-station links, as each station introduces a one bit delay,
    the first bit of the frame would return to S1 while it sends the fifth bit of
    the token. If station S1 is powered off at that time, only the first five bits
    of the token will travel on the ring. To avoid this problem, there is a special
    station called the Monitor on each Token Ring. To ensure that the token can travel
    forever on the ring, this Monitor inserts a delay that is equal to at least 24
    bit transmission times. If station S3 was the Monitor in figure [A Token Ring
    network](#fig-tokenring), S1 would have been able to transmit the entire token
    before receiving the first bit of the token from its upstream neighbor.
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑上图所示的五个站点网络，并假设站点S1发送一个令牌。如果我们忽略站点间链路上的传播延迟，因为每个站点引入一个比特延迟，帧的第一个比特会在发送令牌的第五比特时返回到S1。如果那时站点S1断电，只有令牌的前五个比特会在环上传播。为了避免这个问题，每个令牌环上都有一个特殊的站点，称为监控器。为了确保令牌可以永远在环上传播，这个监控器插入一个等于至少24比特传输时间的延迟。如果图中的[A
    Token Ring网络](#fig-tokenring)中的监控器是S3，那么S1在从其上游邻居接收令牌的第一个比特之前就能够发送整个令牌。
- en: Now that we have explained how the token can be forwarded on the ring, let us
    analyze how a station can capture a token to transmit a data frame. For this,
    we need some information about the format of the data frames. An 802.5 data frame
    begins with the Starting Delimiter followed by the Access Control field whose
    Token bit is reset, a Frame Control field that enables the definition of several
    types of frames, destination and source address, a payload, a CRC, the Ending
    Delimiter and a Frame Status field. The format of the Token Ring data frames is
    illustrated below.
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经解释了如何在环上转发令牌，让我们分析一个站点如何捕获令牌以发送数据帧。为此，我们需要一些关于数据帧格式的信息。802.5 数据帧以起始定界符开始，随后是令牌位被重置的访问控制字段，一个允许定义多种类型帧的帧控制字段，目的地址和源地址，有效载荷，CRC，结束定界符和一个帧状态字段。Token
    Ring 数据帧的格式如下所示。
- en: '[![../_images/8025.svg](../Images/9f175bb0486e691ee2c9018db5a42d22.png)](../_images/8025.svg)'
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: '[![../_images/8025.svg](../Images/9f175bb0486e691ee2c9018db5a42d22.png)](../_images/8025.svg)'
- en: Fig. 208 802.5 data frame format[#](#id95 "Link to this image")
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: 图 208 802.5 数据帧格式[#](#id95 "链接到这张图片")
- en: To capture a token, a station must operate in Listen mode. In this mode, the
    station receives bits from its upstream neighbor. If the bits correspond to a
    data frame, they must be forwarded to the downstream neighbor. If they correspond
    to a token, the station can capture it and transmit its data frame. Both the data
    frame and the token are encoded as a bit string beginning with the Starting Delimiter
    followed by the Access Control field. When the station receives the first bit
    of a Starting Delimiter, it cannot know whether this is a data frame or a token
    and must forward the entire delimiter to its downstream neighbor. It is only when
    it receives the fourth bit of the Access Control field (i.e. the Token bit) that
    the station knows whether the frame is a data frame or a token. If the Token bit
    is reset, it indicates a data frame and the remaining bits of the data frame must
    be forwarded to the downstream station. Otherwise (Token bit is set), this is
    a token and the station can capture it by resetting the bit that is currently
    in its buffer. Thanks to this modification, the beginning of the token is now
    the beginning of a data frame and the station can switch to Transmit mode and
    send its data frame starting at the fifth bit of the Access Control field. Thus,
    the one-bit delay introduced by each Token Ring station plays a key role in enabling
    the stations to efficiently capture the token.
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: 要捕获令牌，站点必须处于监听模式。在这种模式下，站点从其上游邻居接收位。如果这些位对应于数据帧，它们必须转发给下游邻居。如果它们对应于令牌，站点可以捕获它并发送其数据帧。数据帧和令牌都编码为以起始定界符开始，后跟访问控制字段的位字符串。当站点接收到起始定界符的第一个位时，它无法知道这是一个数据帧还是一个令牌，必须将整个定界符转发给其下游邻居。只有当它接收到访问控制字段的第四位（即令牌位）时，站点才知道帧是数据帧还是令牌。如果令牌位被重置，它表示这是一个数据帧，数据帧的其余位必须转发给下游站点。否则（令牌位被设置），这是一个令牌，站点可以通过重置其缓冲区中当前位的位来捕获它。多亏了这个修改，令牌的开始现在就是数据帧的开始，站点可以切换到传输模式，并从访问控制字段的第五位开始发送其数据帧。因此，每个
    Token Ring 站点引入的一个位延迟在使站点能够有效地捕获令牌方面起着关键作用。
- en: After having transmitted its data frame, the station must remain in Transmit
    mode until it has received the last bit of its own data frame. This ensures that
    the bits sent by a station do not remain in the network forever. A data frame
    sent by a station in a Token Ring network passes in front of all stations attached
    to the network. Each station can detect the data frame and analyze the destination
    address to possibly capture the frame.
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
  zh: 在发送完其数据帧后，站点必须保持在传输模式，直到它接收到自己数据帧的最后一位。这确保了站点发送的位不会永远留在网络中。在 Token Ring 网络中，由站点发送的数据帧会经过网络中连接的所有站点。每个站点都可以检测到数据帧并分析目的地址，以可能捕获该帧。
- en: The text above describes the basic operation of a Token Ring network when all
    stations work correctly. Unfortunately, a real Token Ring network must be able
    to handle various types of anomalies and this increases the complexity of Token
    Ring stations. We briefly list the problems and outline their solutions below.
    A detailed description of the operation of Token Ring stations may be found in
    [[IEEE802.5]](../bibliography.html#ieee802-5). The first problem is when all the
    stations attached to the network start. One of them must bootstrap the network
    by sending the first token. For this, all stations implement a distributed election
    mechanism that is used to select the Monitor. Any station can become a Monitor.
    The Monitor manages the Token Ring network and ensures that it operates correctly.
    Its first role is to introduce a delay of 24 bit transmission times to ensure
    that the token can travel smoothly on the ring. Second, the Monitor sends the
    first token on the ring. It must also verify that the token passes regularly.
    According to the Token Ring standard [[IEEE802.5]](../bibliography.html#ieee802-5),
    a station cannot retain the token to transmit data frames for a duration longer
    than the Token Holding Time (THT) (slightly less than 10 milliseconds). On a network
    containing N stations, the Monitor must receive the token at least every \(N \times
    THT\) seconds. If the Monitor does not receive a token during such a period, it
    cuts the ring for some time and then re-initializes the ring and sends a token.
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: 上文描述了当所有站点正常工作时，令牌环网络的基本操作。不幸的是，一个真实的令牌环网络必须能够处理各种类型的异常，这增加了令牌环站点的复杂性。以下简要列出了一些问题和概述了解决方案。有关令牌环站点的详细操作描述，请参阅[[IEEE802.5]](../bibliography.html#ieee802-5)。第一个问题是当所有连接到网络的站点启动时。其中之一必须通过发送第一个令牌来引导网络。为此，所有站点都实现了一种分布式选举机制，用于选择监控器。任何站点都可以成为监控器。监控器管理令牌环网络并确保其正确运行。它的第一个角色是引入24位传输时间的延迟，以确保令牌可以在环上平稳地传输。其次，监控器在环上发送第一个令牌。它还必须验证令牌是否定期通过。根据令牌环标准[[IEEE802.5]](../bibliography.html#ieee802-5)，一个站点不能保留令牌超过令牌保持时间（THT）（略小于10毫秒）来传输数据帧。在一个包含N个站点的网络中，监控器必须至少每\(N
    \times THT\)秒接收一次令牌。如果在这样的期间内监控器没有收到令牌，它将切断一段时间，然后重新初始化环并发送令牌。
- en: Several other anomalies may occur in a Token Ring network. For example, a station
    could capture a token and be powered off before having resent the token. Another
    station could have captured the token, sent its data frame and be powered off
    before receiving all of its data frame. In this case, the bit string corresponding
    to the end of a frame would remain in the ring without being removed by its sender.
    Several techniques are defined in [[IEEE802.5]](../bibliography.html#ieee802-5)
    to allow the Monitor to handle all these problems. If unfortunately, the Monitor
    fails, another station will be elected to become the new Monitor.
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
  zh: 令牌环网络中可能发生其他异常。例如，一个站点可能在重新发送令牌之前捕获令牌并断电。另一个站点可能在收到所有数据帧之前捕获令牌、发送其数据帧并断电。在这种情况下，对应于帧结束的比特串将留在环中，而不会被其发送者移除。[[IEEE802.5]](../bibliography.html#ieee802-5)中定义了多种技术，允许监控器处理所有这些问题。如果不幸的是监控器失败，另一个站点将被选为新的监控器。
- en: Static allocation methods[#](#static-allocation-methods "Link to this heading")
  id: totrans-579
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 静态分配方法[#](#static-allocation-methods "链接到本标题")
- en: A first solution to share the available resources among all the devices attached
    to one Local Area Network is to define, a priori, the distribution of the transmission
    resources among the different devices. If N devices need to share the transmission
    capacities of a LAN operating at b Mbps, each device could be allocated a bandwidth
    of \(\frac{b}{N}\) Mbps.
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个局域网中，将可用资源在所有连接的设备之间共享的第一个解决方案是事先定义不同设备之间的传输资源分配。如果需要N个设备共享一个以b Mbps运行的局域网的传输容量，每个设备可以分配到\(\frac{b}{N}\)
    Mbps的带宽。
- en: Limited resources need to be shared in other environments than Local Area Networks.
    Since the first radio transmissions by [Marconi](http://en.wikipedia.org/wiki/Guglielmo_Marconi)
    more than one century ago, many applications that exchange information through
    radio signals have been developed. Each radio signal is an electromagnetic wave
    whose power is centered around a given frequency. The radio spectrum corresponds
    to frequencies ranging between roughly 3 KHz and 300 GHz. Frequency allocation
    plans negotiated among governments reserve most frequency ranges for specific
    applications such as broadcast radio, broadcast television, mobile communications,
    aeronautical radio navigation, amateur radio, satellite, etc. Each frequency range
    is then subdivided into channels and each channel can be reserved for a given
    application, e.g. a radio broadcaster in a given region.
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: 在局域网以外的其他环境中需要共享有限资源。自从一个多世纪前[马可尼](http://en.wikipedia.org/wiki/Guglielmo_Marconi)进行首次无线电传输以来，已经开发了许多通过无线电信号交换信息的应用。每个无线电信号都是一个以给定频率为中心的电磁波。无线电频谱对应于大约3
    KHz到300 GHz之间的频率。政府之间协商的频率分配计划为广播无线电、广播电视、移动通信、航空无线电导航、业余无线电、卫星等特定应用保留了大多数频率范围。然后，每个频率范围被细分为频道，每个频道可以保留给特定的应用，例如某个地区的广播电台。
- en: Frequency Division Multiplexing (FDM) is a static allocation scheme in which
    a frequency is allocated to each device attached to the shared medium. As each
    device uses a different transmission frequency, collisions cannot occur. In optical
    networks, a variant of FDM called Wavelength Division Multiplexing (WDM) can be
    used. An optical fiber can transport light at different wavelengths without interference.
    With WDM, a different wavelength is allocated to each of the devices that share
    the same optical fiber.
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: 频分复用（Frequency Division Multiplexing, FDM）是一种静态分配方案，其中为连接到共享介质的每个设备分配一个频率。由于每个设备使用不同的传输频率，因此不会发生冲突。在光网络中，可以使用FDM的一种变体，称为波分复用（Wavelength
    Division Multiplexing, WDM）。光纤可以在不同的波长上传输光而不发生干扰。使用WDM，为共享同一光纤的每个设备分配不同的波长。
- en: Time Division Multiplexing (TDM) is a static bandwidth allocation method that
    was initially defined for the telephone network. In the fixed telephone network,
    a voice conversation is usually transmitted as a 64 Kbps signal. Thus, a telephone
    conservation generates 8 KBytes per second or one byte every 125 microseconds.
    Telephone conversations often need to be multiplexed together on a single line.
    For example, in Europe, thirty 64 Kbps voice signals are multiplexed over a single
    2 Mbps (E1) line. This is done by using Time Division Multiplexing (TDM). TDM
    divides the transmission opportunities into slots. In the telephone network, a
    slot corresponds to 125 microseconds. A position inside each slot is reserved
    for each voice signal. The figure below illustrates TDM on a link that is used
    to carry four voice conversations. The vertical lines represent the slot boundaries
    and the letters the different voice conversations. One byte from each voice conversation
    is sent during each 125 microseconds slot. The byte corresponding to a given conversation
    is always sent at the same position in each slot.
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: 时间分复用（Time Division Multiplexing, TDM）是一种最初为电话网络定义的静态带宽分配方法。在固定电话网络中，语音通话通常以64
    Kbps的信号传输。因此，一次电话通话每秒生成8 KBytes或每125微秒一个字节。电话通话通常需要在一个单独的线路上复用在一起。例如，在欧洲，三十个64
    Kbps的语音信号通过一个单独的2 Mbps（E1）线路复用。这是通过使用时间分复用（TDM）来实现的。TDM将传输机会划分为槽位。在电话网络中，一个槽位对应125微秒。每个语音信号在每个槽位内部保留一个位置。下面的图示说明了用于携带四个语音通话的链路上的TDM。垂直线代表槽位边界，字母代表不同的语音通话。每个语音通话的字节在每个125微秒的槽位中发送。对应于给定通话的字节总是在每个槽位中的相同位置发送。
- en: '![Figure made with TikZ](../Images/a5ce7017001779fb85df0a821c9dfa33.png)'
  id: totrans-584
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用TikZ制作的图](../Images/a5ce7017001779fb85df0a821c9dfa33.png)'
- en: ''
  id: totrans-585
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 196 Time-division multiplexing
  id: totrans-586
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图196 时间分复用
- en: TDM as shown above can be completely static, i.e. the same conversations always
    share the link, or dynamic. In the latter case, the two endpoints of the link
    must exchange messages specifying which conversation uses which byte inside each
    slot. Thanks to these control messages, it is possible to dynamically add and
    remove voice conversations from a given link.
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: 如上图所示，TDM可以是完全静态的，即相同的通话总是共享链路，也可以是动态的。在后一种情况下，链路的两个端点必须交换消息，指定每个通话在每个槽位内使用哪个字节。得益于这些控制消息，可以动态地向链路添加和删除语音通话。
- en: TDM and FDM are widely used in telephone networks to support fixed bandwidth
    conversations. Using them in Local Area Networks that support computers would
    probably be inefficient. Computers usually do not send information at a fixed
    rate. Instead, they often have an on-off behavior. During the on period, the computer
    tries to send at the highest possible rate, e.g. to transfer a file. During the
    off period, which is often much longer than the on period, the computer does not
    transmit any packet. Using a static allocation scheme for computers attached to
    a LAN would lead to huge inefficiencies, as they would only be able to transmit
    at \(\frac{1}{N}\) of the total bandwidth during their on period, despite the
    fact that the other computers are in their off period and thus do not need to
    transmit any information. The dynamic MAC algorithms discussed in the remainder
    of this chapter aim to solve this problem.
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: TDM和FDM在电话网络中被广泛用于支持固定带宽的通话。在支持计算机的局域网中使用它们可能会效率低下。计算机通常不会以固定速率发送信息。相反，它们通常具有开/关的行为。在开启期间，计算机试图以尽可能高的速率发送信息，例如传输文件。在关闭期间，这通常比开启期间长得多，计算机不发送任何数据包。为连接到局域网的计算机使用静态分配方案会导致巨大的效率低下，因为它们在开启期间只能以\(\frac{1}{N}\)的总带宽进行传输，尽管其他计算机处于关闭期间，因此不需要传输任何信息。本章余下的部分讨论的动态MAC算法旨在解决这个问题。
- en: ALOHA[#](#aloha "Link to this heading")
  id: totrans-589
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ALOHA[#](#aloha "链接到这个标题")
- en: In the 1960s, computers were mainly mainframes with a few dozen terminals attached
    to them. These terminals were usually in the same building as the mainframe and
    were directly connected to it. In some cases, the terminals were installed in
    remote locations and connected through a [modem](../glossary.html#term-modem)
    attached to a [dial-up line](../glossary.html#term-dial-up-line). The university
    of Hawaii chose a different organization. Instead of using telephone lines to
    connect the distant terminals, they developed the first packet radio technology
    [[Abramson1970]](../bibliography.html#abramson1970). Until then, computer networks
    were built on top of either the telephone network or physical cables. ALOHANet
    showed that it is possible to use radio signals to interconnect computers.
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
  zh: 在20世纪60年代，计算机主要是大型机，连接了几十个终端。这些终端通常位于主机的同一栋建筑内，并直接连接到主机。在某些情况下，终端被安装在远程位置，并通过连接到[调制解调器](../glossary.html#term-modem)的[拨号线路](../glossary.html#term-dial-up-line)进行连接。夏威夷大学选择了不同的组织方式。他们没有使用电话线来连接远程终端，而是开发了第一种分组无线电技术[[Abramson1970]](../bibliography.html#abramson1970)。在此之前，计算机网络都是建立在电话网络或物理电缆之上的。ALOHA网证明了使用无线电信号互联计算机是可能的。
- en: The first version of ALOHANet, described in [[Abramson1970]](../bibliography.html#abramson1970),
    operated as follows. First, the terminals and the mainframe exchanged fixed-length
    frames composed of 704 bits. Each frame contained 80 8-bit characters, some control
    bits and parity information to detect transmission errors. Two channels in the
    400 MHz range were reserved for the operation of ALOHANet. The first channel was
    used by the mainframe to send frames to all terminals. The second channel was
    shared among all terminals to send frames to the mainframe. As all terminals share
    the same transmission channel, there is a risk of collision. To deal with this
    problem as well as transmission errors, the mainframe verified the parity bits
    of the received frame and sent an acknowledgment on its channel for each correctly
    received frame. The terminals on the other hand had to retransmit the unacknowledged
    frames. As for TCP, retransmitting these frames immediately upon expiration of
    a fixed timeout is not a good approach as several terminals may retransmit their
    frames at the same time leading to a network collapse. A better approach, but
    still far from perfect, is for each terminal to wait a random amount of time after
    the expiration of its retransmission timeout. This avoids synchronization among
    multiple retransmitting terminals.
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: ALOHANet的第一个版本，如[[Abramson1970]](../bibliography.html#abramson1970)所述，其工作方式如下。首先，终端和主机交换由704位组成的固定长度帧。每个帧包含80个8位字符，一些控制位和奇偶校验信息以检测传输错误。400
    MHz范围内的两个信道被保留用于ALOHANet的操作。第一个信道由主机用于向所有终端发送帧。第二个信道由所有终端共享，用于向主机发送帧。由于所有终端共享相同的传输信道，因此存在碰撞的风险。为了处理这个问题以及传输错误，主机验证接收到的帧的奇偶校验位，并在其信道上为每个正确接收到的帧发送一个确认。另一方面，终端必须重新传输未确认的帧。至于TCP，在固定超时到期后立即重新传输这些帧并不是一个好的方法，因为多个终端可能会同时重新传输它们的帧，从而导致网络崩溃。一个更好的方法，尽管还远非完美，是每个终端在重新传输超时到期后等待一个随机的时间。这避免了多个重新传输终端之间的同步。
- en: The pseudo-code below shows the operation of an ALOHANet terminal. We use this
    python syntax for all Medium Access Control algorithms described in this chapter.
    The algorithm is applied to each new frame that needs to be transmitted. It attempts
    to transmit a frame at most max times (while loop). Each transmission attempt
    is performed as follows. First, the frame is sent. Each frame is protected by
    a timeout. Then, the terminal waits for either a valid acknowledgment frame or
    the expiration of its timeout. If the terminal receives an acknowledgment, the
    frame has been delivered correctly and the algorithm terminates. Otherwise, the
    terminal waits for a random time and attempts to retransmit the frame.
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的伪代码显示了ALOHANet终端的操作。我们使用这种Python语法描述本章中描述的所有介质访问控制算法。该算法应用于需要传输的每个新帧。它尝试最多max次（while循环）传输一个帧。每次传输尝试如下进行。首先，发送帧。每个帧都由一个超时保护。然后，终端等待有效的确认帧或其超时的到期。如果终端收到确认，则帧已正确交付，算法终止。否则，终端等待随机时间并尝试重新传输帧。
- en: '[PRE15]'
  id: totrans-593
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[[Abramson1970]](../bibliography.html#abramson1970) analyzed the performance
    of ALOHANet under particular assumptions and found that ALOHANet worked well when
    the channel was lightly loaded. In this case, the frames are rarely retransmitted
    and the channel traffic, i.e. the total number of (correct and retransmitted)
    frames transmitted per unit of time is close to the channel utilization, i.e.
    the number of correctly transmitted frames per unit of time. Unfortunately, the
    analysis also reveals that the channel utilization reaches its maximum at \(\frac{1}{2
    \times e}=0.186\) times the channel bandwidth. At higher utilization, ALOHANet
    becomes unstable and the network collapses due to collided retransmissions.'
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: '[[Abramson1970]](../bibliography.html#abramson1970)在特定假设下分析了ALOHANet的性能，并发现当信道负载较轻时，ALOHANet工作得很好。在这种情况下，帧很少重新传输，信道流量，即单位时间内传输的（正确和重新传输的）帧的总数接近信道利用率，即单位时间内正确传输的帧的数量。不幸的是，分析还显示，信道利用率在达到其最大值时为信道带宽的\(\frac{1}{2
    \times e}=0.186\)倍。在更高的利用率下，ALOHANet变得不稳定，网络由于碰撞的重新传输而崩溃。'
- en: Note
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Amateur packet radio
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: 业余数据包无线电
- en: Packet radio technologies have evolved in various directions since the first
    experiments performed at the University of Hawaii. The Amateur packet radio service
    developed by amateur radio operators is one of the descendants ALOHANet. Many
    amateur radio operators are very interested in new technologies and they often
    spend countless hours developing new antennas or transceivers. When the first
    personal computers appeared, several amateur radio operators designed radio modems
    and their own datalink layer protocols [[KPD1985]](../bibliography.html#kpd1985)
    [[BNT1997]](../bibliography.html#bnt1997). This network grew and it was possible
    to connect to servers in several European countries by only using packet radio
    relays. Some amateur radio operators also developed TCP/IP protocol stacks that
    were used over the packet radio service. Some parts of the [amateur packet radio
    network](http://www.ampr.org/) are connected to the global Internet and use the
    44.0.0.0/8 IPv4 prefix.
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: 自从在夏威夷大学进行首次实验以来，包无线电技术已经向多个方向发展。由业余无线电操作员开发的业余包无线电服务是ALOHANet的后裔之一。许多业余无线电操作员对新技术非常感兴趣，他们经常花费无数小时开发新的天线或收发器。当第一台个人计算机出现时，几位业余无线电操作员设计了无线电调制解调器和他们自己的数据链路层协议[[KPD1985]](../bibliography.html#kpd1985)
    [[BNT1997]](../bibliography.html#bnt1997)。这个网络不断发展，仅使用包无线电中继就可以连接到几个欧洲国家的服务器。一些业余无线电操作员还开发了在包无线电服务上使用的TCP/IP协议栈。[业余包无线电网络](http://www.ampr.org/)的一些部分连接到全球互联网，并使用44.0.0.0/8
    IPv4前缀。
- en: Many improvements to ALOHANet have been proposed since the publication of [[Abramson1970]](../bibliography.html#abramson1970),
    and this technique, or some of its variants, are still found in wireless networks
    today. The slotted technique proposed in [[Roberts1975]](../bibliography.html#roberts1975)
    is important because it shows that a simple modification can significantly improve
    channel utilization. Instead of allowing all terminals to transmit at any time,
    [[Roberts1975]](../bibliography.html#roberts1975) proposed to divide time into
    slots and allow terminals to transmit only at the beginning of each slot. Each
    slot corresponds to the time required to transmit one fixed size frame. In practice,
    these slots can be imposed by a single clock that is received by all terminals.
    In ALOHANet, it could have been located on the central mainframe. The analysis
    in [[Roberts1975]](../bibliography.html#roberts1975) reveals that this simple
    modification improves the channel utilization by a factor of two.
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
  zh: 自从[[Abramson1970]](../bibliography.html#abramson1970)发表以来，针对ALOHANet的许多改进方案被提出，并且这种技术或其某些变体至今仍存在于无线网络中。[[Roberts1975]](../bibliography.html#roberts1975)提出的时隙技术非常重要，因为它表明简单的修改可以显著提高信道利用率。不是允许所有终端在任何时间传输，[[Roberts1975]](../bibliography.html#roberts1975)提出将时间划分为时隙，并允许终端只在每个时隙的开始传输。每个时隙对应于传输一个固定大小帧所需的时间。在实践中，这些时隙可以通过一个所有终端都能接收到的单一时钟来强制执行。在ALOHANet中，它可能位于中央主框上。[[Roberts1975]](../bibliography.html#roberts1975)的分析表明，这种简单的修改可以将信道利用率提高两倍。
- en: '### Carrier Sense Multiple Access[#](#carrier-sense-multiple-access "Link to
    this heading")'
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
  zh: '### 载波侦听多路访问[#](#carrier-sense-multiple-access "链接到这个标题")'
- en: ALOHA and slotted ALOHA can easily be implemented, but unfortunately, they can
    only be used in networks that are very lightly loaded. Designing a network for
    a very low utilization is possible, but it clearly increases the cost of the network.
    To overcome the problems of ALOHA, many Medium Access Control mechanisms have
    been proposed which improve channel utilization. Carrier Sense Multiple Access
    (CSMA) is a significant improvement compared to ALOHA. CSMA requires all nodes
    to listen to the transmission channel to verify that it is free before transmitting
    a frame [[KT1975]](../bibliography.html#kt1975). When a node senses the channel
    to be busy, it defers its transmission until the channel becomes free again. The
    pseudo-code below provides a more detailed description of the operation of CSMA.
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
  zh: ALOHA和时隙ALOHA可以很容易地实现，但不幸的是，它们只能用于非常轻载的网络。为非常低利用率设计网络是可能的，但这显然会增加网络的成本。为了克服ALOHA的问题，已经提出了许多介质访问控制机制，这些机制提高了信道利用率。与ALOHA相比，载波侦听多路访问（CSMA）是一个显著的改进。CSMA要求所有节点在发送帧之前侦听传输信道以验证其是否空闲[[KT1975]](../bibliography.html#kt1975)。当一个节点侦测到信道繁忙时，它将推迟其传输，直到信道再次空闲。下面的伪代码提供了CSMA操作的更详细描述。
- en: '[PRE16]'
  id: totrans-601
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The above pseudo-code is often called persistent CSMA [[KT1975]](../bibliography.html#kt1975)
    as the terminal will continuously listen to the channel and transmit its frame
    as soon as the channel becomes free. Another important variant of CSMA is the
    non-persistent CSMA [[KT1975]](../bibliography.html#kt1975). The main difference
    between persistent and non-persistent CSMA described in the pseudo-code below
    is that a non-persistent CSMA node does not continuously listen to the channel
    to determine when it becomes free. When a non-persistent CSMA terminal senses
    the transmission channel to be busy, it waits for a random time before sensing
    the channel again. This improves channel utilization compared to persistent CSMA.
    With persistent CSMA, when two terminals sense the channel to be busy, they will
    both transmit (and thus cause a collision) as soon as the channel becomes free.
    With non-persistent CSMA, this synchronization does not occur, as the terminals
    wait a random time after having sensed the transmission channel. However, the
    higher channel utilization achieved by non-persistent CSMA comes at the expense
    of a slightly higher waiting time in the terminals when the network is lightly
    loaded.
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
  zh: 上述伪代码通常被称为持续载波监听多路访问（CSMA）[[KT1975]](../bibliography.html#kt1975)，因为终端将持续监听信道，并在信道空闲时立即发送其帧。CSMA的另一个重要变体是非持续CSMA
    [[KT1975]](../bibliography.html#kt1975)。以下伪代码中描述的持续和非持续CSMA之间的主要区别在于，非持续CSMA节点不会持续监听信道以确定何时空闲。当一个非持续CSMA终端检测到传输信道忙碌时，它会在再次检测信道之前等待一个随机时间。这比持续CSMA提高了信道利用率。在持续CSMA中，当两个终端检测到信道忙碌时，它们将在信道空闲时立即发送（从而引起冲突）。而在非持续CSMA中，这种同步不会发生，因为终端在检测到传输信道后等待一个随机时间。然而，非持续CSMA通过提高信道利用率所获得的收益是以网络轻载时终端等待时间略微增加为代价的。
- en: '[PRE17]'
  id: totrans-603
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[[KT1975]](../bibliography.html#kt1975) analyzes in detail the performance
    of several CSMA variants. Under some assumptions about the transmission channel
    and the traffic, the analysis compares ALOHA, slotted ALOHA, persistent and non-persistent
    CSMA. Under these assumptions, ALOHA achieves a channel utilization of only 18.4%
    of the channel capacity. Slotted ALOHA is able to use 36.6% of this capacity.
    Persistent CSMA improves the utilization by reaching 52.9% of the capacity while
    non-persistent CSMA achieves 81.5% of the channel capacity.'
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
  zh: '[[KT1975]](../bibliography.html#kt1975) 详细分析了几个CSMA变体的性能。在关于传输信道和流量的某些假设下，该分析比较了ALOHA、时隙ALOHA、持续和非持续CSMA。在这些假设下，ALOHA的信道利用率仅为信道容量的18.4%。时隙ALOHA能够使用36.6%的容量。持续CSMA通过达到52.9%的容量来提高利用率，而非持续CSMA实现了信道容量的81.5%。'
- en: '### Carrier Sense Multiple Access with Collision Detection[#](#carrier-sense-multiple-access-with-collision-detection
    "Link to this heading")'
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
  zh: '### 带冲突检测的载波监听多路访问[#](#carrier-sense-multiple-access-with-collision-detection
    "链接到本标题")'
- en: CSMA improves channel utilization compared to ALOHA. However, the performance
    can still be improved, especially in wired networks. Consider the situation of
    two terminals that are connected to the same cable. This cable could, for example,
    be a coaxial cable as in the early days of Ethernet [[Metcalfe1976]](../bibliography.html#metcalfe1976).
    It could also be built with twisted pairs. Before extending CSMA, it is useful
    to understand, more intuitively, how frames are transmitted in such a network
    and how collisions can occur. The figure below illustrates the physical transmission
    of a frame on such a cable. To transmit its frame, host A must send an electrical
    signal on the shared medium. The first step is thus to begin the transmission
    of the electrical signal. This is point (1) in the figure below. This electrical
    signal will travel along the cable. Although electrical signals travel fast, we
    know that information cannot travel faster than the speed of light (i.e. 300.000
    kilometers/second). On a coaxial cable, an electrical signal is slightly slower
    than the speed of light and 200.000 kilometers per second is a reasonable estimation.
    This implies that if the cable has a length of one kilometer, the electrical signal
    will need 5 microseconds to travel from one end of the cable to the other. The
    ends of coaxial cables are equipped with termination points that ensure that the
    electrical signal is not reflected back to its source. This is illustrated at
    point (3) in the figure, where the electrical signal has reached the left endpoint
    and host B. At this point, B starts to receive the frame being transmitted by
    A. Notice that there is a delay between the transmission of a bit on host A and
    its reception by host B. If there were other hosts attached to the cable, they
    would receive the first bit of the frame at slightly different times. As we will
    see later, this timing difference is a key problem for MAC algorithms. At point
    (4), the electrical signal has reached both ends of the cable and occupies it
    completely. Host A continues to transmit the electrical signal until the end of
    the frame. As shown at point (5), when the sending host stops its transmission,
    the electrical signal corresponding to the end of the frame leaves the coaxial
    cable. The channel becomes empty again once the entire electrical signal has been
    removed from the cable.
  id: totrans-606
  prefs: []
  type: TYPE_NORMAL
  zh: CSMA相比ALOHA提高了信道利用率。然而，性能仍然可以进一步提高，尤其是在有线网络中。考虑两个终端连接到同一电缆的情况。例如，这条电缆可以是早期以太网中的同轴电缆
    [[Metcalfe1976]](../bibliography.html#metcalfe1976)。它也可以由双绞线构建。在扩展CSMA之前，了解这样一个网络中帧的传输方式和碰撞如何发生是有用的。下面的图示说明了这样一个电缆上帧的物理传输。为了传输其帧，主机A必须在共享介质上发送一个电信号。因此，第一步是开始传输电信号。这如图下方的点（1）所示。这个电信号将沿着电缆传播。尽管电信号传播得很快，但我们知道信息不能比光速传播得更快（即每秒300,000公里）。在同轴电缆上，电信号略慢于光速，每秒200,000公里是一个合理的估计。这意味着如果电缆长度为一公里，电信号需要5微秒才能从电缆一端传播到另一端。同轴电缆的末端装有终止点，以确保电信号不会反射回其源头。这如图中的点（3）所示，其中电信号已经到达左端点和主机B。此时，B开始接收A正在传输的帧。请注意，在主机A上传输一个比特和主机B接收它之间存在延迟。如果有其他主机连接到电缆上，它们将接收到帧的第一个比特在略微不同的时间。正如我们稍后将会看到的，这种时间差异是MAC算法的一个关键问题。在点（4）处，电信号已经到达电缆的两端并完全占据它。主机A继续传输电信号，直到帧的结束。如图中的点（5）所示，当发送主机停止传输时，对应于帧结束的电信号离开同轴电缆。一旦整个电信号从电缆中移除，信道再次变为空闲。
- en: '[![../_images/frame-bus.png](../Images/ab89b8b4019e54d32dc8e8a85f104ba1.png)](../_images/frame-bus.png)'
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/frame-bus.png](../Images/ab89b8b4019e54d32dc8e8a85f104ba1.png)'
- en: Fig. 197 Frame transmission on a shared bus[#](#id85 "Link to this image")
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
  zh: 图197 共享总线上帧的传输[#](#id85 "链接到这张图片")
- en: Now that we have looked at how a frame is actually transmitted as an electrical
    signal on a shared bus, it is interesting to look in more detail at what happens
    when two hosts transmit a frame at almost the same time. This is illustrated in
    the figure below, where hosts A and B start their transmission at the same time
    (point (1)). At this time, if host C senses the channel, it will consider it to
    be free. This will not last a long time and at point (2) the electrical signals
    from both host A and host B reach host C. The combined electrical signal (shown
    graphically as the superposition of the two curves in the figure) cannot be decoded
    by host C. Host C detects a collision, as it receives a signal that it cannot
    decode. Since host C cannot decode the frames, it cannot determine which hosts
    are sending the colliding frames. Note that host A (and host B) will detect the
    collision after host C (point (3) in figure [Fig. 198](#fig-collision-bus)).
  id: totrans-609
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了帧是如何作为一个电信号在共享总线上实际传输的，那么更详细地看看当两个主机几乎同时发送一个帧时会发生什么，这很有趣。这在上面的图中得到了说明，其中主机A和主机B同时开始传输（点（1））。此时，如果主机C检测到信道，它会认为它是空闲的。但这不会持续太久，在点（2）处，主机A和主机B的电信号都到达了主机C。组合电信号（在图中以两个曲线的叠加形式图形化表示）无法被主机C解码。主机C检测到冲突，因为它接收到了一个无法解码的信号。由于主机C无法解码帧，它无法确定哪些主机正在发送冲突的帧。请注意，主机A（以及主机B）将在主机C之后检测到冲突（如图[图198](#fig-collision-bus)中的点（3））。
- en: '[![../_images/frame-collision.png](../Images/7b88fb2c9cc28c5857f616b145a56cb6.png)](../_images/frame-collision.png)'
  id: totrans-610
  prefs: []
  type: TYPE_NORMAL
  zh: '[![../_images/frame-collision.png](../Images/7b88fb2c9cc28c5857f616b145a56cb6.png)](../_images/frame-collision.png)'
- en: Fig. 198 Frame collision on a shared bus[#](#fig-collision-bus "Link to this
    image")
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
  zh: 图198 共享总线上的帧冲突[#](#fig-collision-bus "链接到这张图片")
- en: As shown above, hosts detect collisions when they receive an electrical signal
    that they cannot decode. In a wired network, a host is able to detect such a collision
    both while it is listening (e.g. like host C in the figure above) and also while
    it is sending its own frame. When a host transmits a frame, it can compare the
    electrical signal that it transmits with the electrical signal that it senses
    on the wire. At points (1) and (2) in the figure above, host A senses only its
    own signal. At point (3), it senses an electrical signal that differs from its
    own signal and can thus detects the collision. At this point, its frame is corrupted
    and it can stop its transmission. The ability to detect collisions while transmitting
    is the starting point for the Carrier Sense Multiple Access with Collision Detection
    (CSMA/CD) Medium Access Control algorithm, which is used in Ethernet networks
    [[Metcalfe1976]](../bibliography.html#metcalfe1976) [[IEEE802.3]](../bibliography.html#ieee802-3)
    . When an Ethernet host detects a collision while it is transmitting, it immediately
    stops its transmission. Compared with pure CSMA, CSMA/CD is an important improvement
    since when collisions occur, they only last until colliding hosts have detected
    it and stopped their transmission. In practice, when a host detects a collision,
    it sends a special jamming signal on the cable to ensure that all hosts have detected
    the collision.
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
  zh: 如上图所示，当主机接收到无法解码的电信号时，它们会检测到冲突。在有线的网络中，主机在监听时（例如上图中的主机C）以及发送自己的帧时，都能够检测到这种冲突。当主机发送一个帧时，它可以比较自己发送的电信号与在电缆上感知到的电信号。在上图中的点（1）和（2）处，主机A只能感知到自己的信号。在点（3）处，它感知到一个与自己的信号不同的电信号，因此可以检测到冲突。在此点，它的帧被损坏，它可以停止传输。在传输过程中检测到冲突的能力是载波侦听多路访问与冲突检测（CSMA/CD）介质访问控制算法的起点，该算法用于以太网网络
    [[Metcalfe1976]](../bibliography.html#metcalfe1976) [[IEEE802.3]](../bibliography.html#ieee802-3)
    。当以太网主机在传输过程中检测到冲突时，它会立即停止传输。与纯CSMA相比，CSMA/CD是一个重要的改进，因为当发生冲突时，它们只会持续到发生冲突的主机检测到并停止传输。在实践中，当主机检测到冲突时，它会在电缆上发送一个特殊的干扰信号，以确保所有主机都检测到冲突。
- en: To better understand these collisions, it is useful to analyze what would be
    the worst collision on a shared bus network. Let us consider a wire with two hosts
    attached at both ends, as shown in the figure below. Host A starts to transmit
    its frame and its electrical signal is propagated on the cable. Its propagation
    time depends on the physical length of the cable and the speed of the electrical
    signal. Let us use \(\tau\) to represent this propagation delay in seconds. Slightly
    less than \(\tau\) seconds after the beginning of the transmission of A’s frame,
    B decides to start transmitting its own frame. After \(\epsilon\) seconds, B senses
    A’s frame, detects the collision and stops transmitting. The beginning of B’s
    frame travels on the cable until it reaches host A. Host A can thus detect the
    collision at time \(\tau-\epsilon+\tau \approx 2\times\tau\). An important point
    to note is that a collision can only occur during the first \(2\times\tau\) seconds
    of its transmission. If a collision did not occur during this period, it cannot
    occur afterwards since the transmission channel is busy after \(\tau\) seconds
    and CSMA/CD hosts sense the transmission channel before transmitting their frame.
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解这些碰撞，分析在共享总线网络中最严重的碰撞情况是有用的。让我们考虑一个两端各连接两个主机的电线，如图下所示。主机A开始传输其帧，其电信号在电缆上传播。其传播时间取决于电缆的物理长度和电信号的速度。让我们用
    \(\tau\) 来表示这种传播延迟（以秒为单位）。在A的帧传输开始后略少于 \(\tau\) 秒，B决定开始传输自己的帧。经过 \(\epsilon\)
    秒后，B检测到A的帧，检测到碰撞并停止传输。B的帧的开始在电缆上传播，直到它到达主机A。因此，主机A可以在 \(\tau-\epsilon+\tau \approx
    2\times\tau\) 时刻检测到碰撞。一个需要注意的重要点是，碰撞只能在传输的前 \(2\times\tau\) 秒内发生。如果在这一时期内没有发生碰撞，那么之后也不会发生，因为
    \(\tau\) 秒后传输通道是忙碌的，并且 CSMA/CD 主机在传输帧之前会检测传输通道。
- en: '[![../_images/frame-collision-worst.png](../Images/cb963f4bef31245667608aad2e590553.png)](../_images/frame-collision-worst.png)'
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/frame-collision-worst.png](../Images/cb963f4bef31245667608aad2e590553.png)'
- en: Fig. 199 The worst collision on a shared bus[#](#id86 "Link to this image")
  id: totrans-615
  prefs: []
  type: TYPE_NORMAL
  zh: 图199 共享总线上的最严重碰撞[#](#id86 "链接到这张图片")
- en: Furthermore, on the wired networks where CSMA/CD is used, collisions are almost
    the only cause of transmission errors that affect frames. Transmission errors
    that only affect a few bits inside a frame seldom occur in these wired networks.
    For this reason, the designers of CSMA/CD chose to completely remove the acknowledgment
    frames in the datalink layer. When a host transmits a frame, it verifies whether
    its transmission has been affected by a collision. If not, given the negligible
    Bit Error Ratio of the underlying network, it assumes that the frame was received
    correctly by its destination. Otherwise the frame is retransmitted after some
    delay.
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在采用 CSMA/CD 的有线网络中，碰撞几乎是影响帧的传输错误的唯一原因。仅影响帧内少数比特的传输错误在这些有线网络中很少发生。因此，CSMA/CD的设计者选择在数据链路层完全删除确认帧。当主机传输一个帧时，它会验证其传输是否受到碰撞的影响。如果没有，考虑到底层网络的几乎可以忽略的比特错误率，它假设帧已被正确接收。否则，帧将在一段时间后重新传输。
- en: Removing acknowledgments is an interesting optimization as it reduces the number
    of frames that are exchanged on the network and the number of frames that need
    to be processed by the hosts. However, to use this optimization, we must ensure
    that all hosts will be able to detect all the collisions that affect their frames.
    The problem is important for short frames. Let us consider two hosts, A and B,
    that are sending a small frame to host C as illustrated in the figure below. If
    the frames sent by A and B are very short, the situation illustrated below may
    occur. Hosts A and B send their frame and stop transmitting (point (1)). When
    the two short frames arrive at the location of host C, they collide and host C
    cannot decode them (point (2)). The two frames are absorbed by the ends of the
    wire. Neither host A nor host B have detected the collision. They both consider
    their frame to have been received correctly by its destination.
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
  zh: 移除致谢是一种有趣的优化方法，因为它减少了网络中交换的帧数以及主机需要处理的帧数。然而，为了使用这种优化，我们必须确保所有主机都能检测到影响其帧的所有冲突。对于短帧来说，这是一个重要的问题。让我们考虑两个主机，A和B，它们正在向主机C发送一个小帧，如图所示。如果A和B发送的帧非常短，下面可能发生的情况如下。主机A和B发送它们的帧并停止传输（点（1））。当两个短帧到达主机C的位置时，它们发生碰撞，主机C无法解码它们（点（2））。这两个帧被线缆的末端吸收。主机A和主机B都没有检测到碰撞。它们都认为它们的帧已经正确地被目的地接收。
- en: '[![../_images/frame-collision-short.png](../Images/9a5d6d727ec45fd15b48e2c3fdc820d7.png)](../_images/frame-collision-short.png)'
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
  zh: '[![../_images/frame-collision-short.png](../Images/9a5d6d727ec45fd15b48e2c3fdc820d7.png)](../_images/frame-collision-short.png)'
- en: Fig. 200 The short-frame collision problem[#](#id87 "Link to this image")
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
  zh: 图200 短帧碰撞问题[#](#id87 "链接到这张图片")
- en: To solve this problem, networks using CSMA/CD require hosts to transmit for
    at least \(2\times\tau\) seconds. Since the network transmission speed is fixed
    for a given network technology, this implies that a technology that uses CSMA/CD
    enforces a minimum frame size. In the most popular CSMA/CD technology, Ethernet,
    \(2\times\tau\) is called the slot time [[4]](#fslottime).
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，使用CSMA/CD的网络要求主机至少传输\(2\times\tau\)秒。由于网络传输速度对于给定的网络技术是固定的，这意味着使用CSMA/CD的技术强制执行最小帧大小。在最受欢迎的CSMA/CD技术以太网中，\(2\times\tau\)被称为时隙时间
    [[4]](#fslottime)。
- en: The last innovation introduced by CSMA/CD is the computation of the retransmission
    timeout. As for ALOHA, this timeout cannot be fixed, otherwise hosts could become
    synchronized and always retransmit at the same time. Setting such a timeout is
    always a compromise between the network access delay and the amount of collisions.
    A short timeout would lead to a low network access delay but with a higher risk
    of collisions. On the other hand, a long timeout would cause a long network access
    delay but a lower risk of collisions. The binary exponential back-off algorithm
    was introduced in CSMA/CD networks to solve this problem.
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
  zh: CSMA/CD最后引入的创新是重传超时的计算。对于ALOHA来说，这个超时不能固定，否则主机可能会同步并总是在同一时间重传。设置这样的超时总是在网络访问延迟和碰撞数量之间做出妥协。超时时间短会导致网络访问延迟低，但碰撞风险高。另一方面，超时时间长会导致网络访问延迟长，但碰撞风险低。二进制指数退避算法被引入到CSMA/CD网络中，以解决这个问题。
- en: 'To understand binary exponential back-off, let us consider a collision caused
    by exactly two hosts. Once it has detected the collision, a host can either retransmit
    its frame immediately or defer its transmission for some time. If each colliding
    host flips a coin to decide whether to retransmit immediately or to defer its
    retransmission, four cases are possible :'
  id: totrans-622
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解二进制指数退避，让我们考虑由恰好两个主机引起的碰撞。一旦检测到碰撞，主机可以立即重传其帧或推迟其传输一段时间。如果每个冲突的主机抛硬币来决定是否立即重传或推迟重传，可能出现四种情况：
- en: Both hosts retransmit immediately and a new collision occurs
  id: totrans-623
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 两个主机立即重传，并发生新的碰撞
- en: ''
  id: totrans-624
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-625
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: The first host retransmits immediately and the second defers its retransmission
  id: totrans-626
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一个主机立即重传，第二个主机推迟其重传
- en: ''
  id: totrans-627
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-628
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: The second host retransmits immediately and the first defers its retransmission
  id: totrans-629
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二个主机立即重传，第一个主机推迟其重传
- en: ''
  id: totrans-630
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-631
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Both hosts defer their retransmission and a new collision occurs
  id: totrans-632
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 两个主机都推迟了重传，并发生了新的碰撞
- en: In the second and third cases, both hosts have flipped different coins. The
    delay chosen by the host that defers its retransmission should be long enough
    to ensure that its retransmission will not collide with the immediate retransmission
    of the other host. However the delay should not be longer than the time necessary
    to avoid the collision, because if both hosts decide to defer their transmission,
    the network will be idle during this delay. The slot time is the optimal delay
    since it is the shortest delay that ensures that the first host will be able to
    retransmit its frame completely without any collision.
  id: totrans-633
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二种和第三种情况下，两个主机都掷了不同的硬币。延迟选择应该足够长，以确保其重传不会与另一个主机的即时重传发生碰撞。然而，延迟不应超过避免碰撞所需的时间，因为如果两个主机都决定推迟它们的传输，网络将在这种延迟期间空闲。时隙时间是最佳延迟，因为它是最短的延迟，可以确保第一个主机能够完全重传其帧而不会发生任何碰撞。
- en: If two hosts are competing, the algorithm above will avoid a second collision
    50% of the time. However, if the network is heavily loaded, several hosts may
    be competing at the same time. In this case, the hosts should be able to automatically
    adapt their retransmission delay. The binary exponential back-off performs this
    adaptation based on the number of collisions that have affected a frame. After
    the first collision, the host flips a coin and waits 0 or 1 slot time. After the
    second collision, it generates a random number and waits 0, 1, 2 or 3 slot times,
    etc. The duration of the waiting time is doubled after each collision. The complete
    pseudo-code for the CSMA/CD algorithm is shown in the figure below.
  id: totrans-634
  prefs: []
  type: TYPE_NORMAL
  zh: 如果两个主机正在竞争，上述算法将避免50%的第二次碰撞。然而，如果网络负载很重，可能同时有几个主机在竞争。在这种情况下，主机应该能够自动调整它们的重传延迟。二进制指数退避根据影响帧的碰撞次数进行这种调整。第一次碰撞后，主机掷硬币并等待0或1个时隙时间。第二次碰撞后，它生成一个随机数并等待0、1、2或3个时隙时间，等等。每次碰撞后，等待时间翻倍。CSMA/CD算法的完整伪代码如图所示。
- en: '[PRE18]'
  id: totrans-635
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The inter-frame delay used in this pseudo-code is a short delay corresponding
    to the time required by a network adapter to switch from transmit to receive mode.
    It is also used to prevent a host from sending a continuous stream of frames without
    leaving any transmission opportunities for other hosts on the network. This contributes
    to the fairness of CSMA/CD. Despite this delay, there are still conditions where
    CSMA/CD is not completely fair [[RY1994]](../bibliography.html#ry1994). Consider
    for example a network with two hosts : a server sending long frames and a client
    sending acknowledgments. Measurements reported in [[RY1994]](../bibliography.html#ry1994)
    have shown that there are situations where the client could suffer from repeated
    collisions that lead it to wait for long periods of time due to the exponential
    back-off algorithm.'
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
  zh: 在此伪代码中使用的帧间延迟是一个短延迟，对应于网络适配器从发送模式切换到接收模式所需的时间。它还用于防止主机发送连续的帧流，而不给网络上的其他主机留下任何传输机会。这有助于CSMA/CD的公平性。尽管有这种延迟，但仍然存在CSMA/CD不完全公平的情况
    [[RY1994]](../bibliography.html#ry1994)。例如，考虑一个有两个主机的网络：一个服务器发送长帧，一个客户端发送确认。[[RY1994]](../bibliography.html#ry1994)中报告的测量结果表明，存在客户端可能遭受重复碰撞的情况，这导致它因指数退避算法而长时间等待。
- en: '### Carrier Sense Multiple Access with Collision Avoidance[#](#carrier-sense-multiple-access-with-collision-avoidance
    "Link to this heading")'
  id: totrans-637
  prefs: []
  type: TYPE_NORMAL
  zh: '### 带有碰撞避免的载波侦听多路访问[#](#carrier-sense-multiple-access-with-collision-avoidance
    "链接到本标题")'
- en: The Carrier Sense Multiple Access with Collision Avoidance (CSMA/CA) Medium
    Access Control algorithm was designed for the popular WiFi wireless network technology
    [[IEEE802.11]](../bibliography.html#ieee802-11). CSMA/CA also senses the transmission
    channel before transmitting a frame. Furthermore, CSMA/CA tries to avoid collisions
    by carefully tuning the timers used by CSMA/CA devices.
  id: totrans-638
  prefs: []
  type: TYPE_NORMAL
  zh: 带有碰撞避免的载波侦听多路访问（CSMA/CA）介质访问控制算法是为流行的WiFi无线网络技术[[IEEE802.11]](../bibliography.html#ieee802-11)设计的。CSMA/CA在发送帧之前也会侦听传输通道。此外，CSMA/CA通过仔细调整CSMA/CA设备使用的计时器来尝试避免碰撞。
- en: CSMA/CA uses acknowledgments like CSMA. Each frame contains a sequence number
    and a CRC. The CRC is used to detect transmission errors while the sequence number
    is used to avoid frame duplication. When a device receives a correct frame, it
    returns a special acknowledgment frame to the sender. CSMA/CA introduces a small
    delay, named Short Inter Frame Spacing (SIFS), between the reception of a frame
    and the transmission of the acknowledgment frame. This delay corresponds to the
    time that is required to switch the radio of a device between the reception and
    transmission modes.
  id: totrans-639
  prefs: []
  type: TYPE_NORMAL
  zh: CSMA/CA 使用类似于 CSMA 的确认。每个帧包含一个序列号和一个 CRC。CRC 用于检测传输错误，而序列号用于避免帧重复。当设备接收到正确的帧时，它会向发送方返回一个特殊的确认帧。CSMA/CA
    在接收帧和发送确认帧之间引入了一个小的延迟，称为 Short Inter Frame Spacing (SIFS)。这个延迟对应于设备在接收和传输模式之间切换无线电所需的时间。
- en: 'Compared to CSMA, CSMA/CA defines more precisely when a device is allowed to
    send a frame. First, CSMA/CA defines two delays : DIFS and EIFS. To send a frame,
    a device must first wait until the channel has been idle for at least the Distributed
    Coordination Function Inter Frame Space (DIFS) if the previous frame was received
    correctly. However, if the previously received frame was corrupted, this indicates
    that there are collisions and the device must sense the channel idle for at least
    the Extended Inter Frame Space (EIFS), with \(SIFS<DIFS<EIFS\). The exact values
    for SIFS, DIFS and EIFS depend on the underlying physical layer [[IEEE802.11]](../bibliography.html#ieee802-11).'
  id: totrans-640
  prefs: []
  type: TYPE_NORMAL
  zh: 与 CSMA 相比，CSMA/CA 更精确地定义了何时允许设备发送帧。首先，CSMA/CA 定义了两个延迟：DIFS 和 EIFS。为了发送帧，设备必须首先等待信道空闲至少
    Distributed Coordination Function Inter Frame Space (DIFS) 时间，如果之前接收到的帧是正确的。然而，如果之前接收到的帧已损坏，这表明存在冲突，设备必须检测信道空闲至少
    Extended Inter Frame Space (EIFS)，其中 \(SIFS<DIFS<EIFS\)。SIFS、DIFS 和 EIFS 的确切值取决于底层物理层
    [[IEEE802.11]](../bibliography.html#ieee802-11)。
- en: The figure below shows the basic operation of CSMA/CA devices. Before transmitting,
    host A verifies that the channel is empty for a long enough period. Then, its
    sends its data frame. After checking the validity of the received frame, the recipient
    sends an acknowledgment frame after a short SIFS delay. Host C, which does not
    participate in the frame exchange, senses the channel to be busy at the beginning
    of the data frame. Host C can use this information to determine how long the channel
    will be busy for. Note that as \(SIFS<DIFS<EIFS\), even a device that would start
    to sense the channel immediately after the last bit of the data frame could not
    decide to transmit its own frame during the transmission of the acknowledgment
    frame.
  id: totrans-641
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了 CSMA/CA 设备的基本操作。在传输之前，主机 A 验证信道是否空闲了足够长的时间。然后，它发送其数据帧。在检查接收到的帧的有效性后，接收方在短暂的
    SIFS 延迟后发送一个确认帧。不参与帧交换的主机 C 在数据帧的开始时检测到信道忙碌。主机 C 可以使用此信息来确定信道将忙碌多长时间。请注意，由于 \(SIFS<DIFS<EIFS\)，即使在数据帧的最后一位之后立即开始检测信道的设备也无法在确认帧传输期间决定发送自己的帧。
- en: '[![../_images/csmaca-1.png](../Images/a384b3211b0772e04aaf1c46baf44b77.png)](../_images/csmaca-1.png)'
  id: totrans-642
  prefs: []
  type: TYPE_NORMAL
  zh: '[![../_images/csmaca-1.png](../Images/a384b3211b0772e04aaf1c46baf44b77.png)](../_images/csmaca-1.png)'
- en: Fig. 201 Operation of a CSMA/CA device[#](#id88 "Link to this image")
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
  zh: 图 201 CSMA/CA 设备的操作[#](#id88 "链接到这张图片")
- en: The main difficulty with CSMA/CA is when two or more devices transmit at the
    same time and cause collisions. This is illustrated in the figure below, assuming
    a fixed timeout after the transmission of a data frame. With CSMA/CA, the timeout
    after the transmission of a data frame is very small, since it corresponds to
    the SIFS plus the time required to transmit the acknowledgment frame.
  id: totrans-644
  prefs: []
  type: TYPE_NORMAL
  zh: CSMA/CA 的主要困难在于两个或更多设备同时传输并引起冲突。这在下图中得到说明，假设在数据帧传输后有一个固定的超时时间。由于 CSMA/CA 在数据帧传输后的超时时间非常小，因为它对应于
    SIFS 加上发送确认帧所需的时间。
- en: '[![../_images/csmaca-2.png](../Images/0dbf88b43018a324dcb149e4a1fe2cae.png)](../_images/csmaca-2.png)'
  id: totrans-645
  prefs: []
  type: TYPE_NORMAL
  zh: '[![../_images/csmaca-2.png](../Images/0dbf88b43018a324dcb149e4a1fe2cae.png)](../_images/csmaca-2.png)'
- en: Fig. 202 Collisions with CSMA/CA[#](#id89 "Link to this image")
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
  zh: 图 202 CSMA/CA 的冲突[#](#id89 "链接到这张图片")
- en: To deal with this problem, CSMA/CA relies on a backoff timer. This backoff timer
    is a random delay that is chosen by each device in a range that depends on the
    number of retransmissions for the current frame. The range grows exponentially
    with the retransmissions as in CSMA/CD. The minimum range for the backoff timer
    is \([0,7*slotTime]\) where the slotTime is a parameter that depends on the underlying
    physical layer. Compared to CSMA/CD’s exponential backoff, there are two important
    differences to notice. First, the initial range for the backoff timer is seven
    times larger. This is because it is impossible in CSMA/CA to detect collisions
    as they happen. With CSMA/CA, a collision may affect the entire frame while with
    CSMA/CD it can only affect the beginning of the frame. Second, a CSMA/CA device
    must regularly sense the transmission channel during its back off timer. If the
    channel becomes busy (i.e. because another device is transmitting), then the back
    off timer must be frozen until the channel becomes free again. Once the channel
    becomes free, the back off timer is restarted. This is in contrast with CSMA/CD
    where the back off is recomputed after each collision. This is illustrated in
    the figure below. Host A chooses a smaller backoff than host C. When C senses
    the channel to be busy, it freezes its backoff timer and only restarts it once
    the channel is free again.
  id: totrans-647
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，CSMA/CA 依赖于一个退避计时器。这个退避计时器是一个随机延迟，由每个设备在一个依赖于当前帧重传次数的范围内选择。范围随着重传次数呈指数增长，就像
    CSMA/CD 一样。退避计时器的最小范围是 \([0,7*slotTime]\)，其中 slotTime 是一个取决于底层物理层的参数。与 CSMA/CD
    的指数退避相比，有两个重要差异需要注意。首先，退避计时器的初始范围是七倍大。这是因为 CSMA/CA 中无法检测到发生的碰撞。与 CSMA/CA 不同，一个碰撞可能会影响整个帧，而与
    CSMA/CD 相比，它只能影响帧的开始部分。其次，一个 CSMA/CA 设备必须在退避计时器期间定期检测传输通道。如果通道变得繁忙（即，因为另一个设备正在传输），则退避计时器必须冻结，直到通道再次空闲。一旦通道空闲，退避计时器重新启动。这与
    CSMA/CD 不同，CSMA/CD 在每次碰撞后重新计算退避。这在下图中得到了说明。主机 A 选择比主机 C 更小的退避。当 C 检测到通道繁忙时，它会冻结其退避计时器，并且只有在通道再次空闲时才重新启动。
- en: '[![../_images/csmaca-3.png](../Images/9634d388481fa8d42a5b4b7de8b205c0.png)](../_images/csmaca-3.png)'
  id: totrans-648
  prefs: []
  type: TYPE_NORMAL
  zh: '[![../_images/csmaca-3.png](../Images/9634d388481fa8d42a5b4b7de8b205c0.png)](../_images/csmaca-3.png)'
- en: Fig. 203 Detailed example with CSMA/CA[#](#id90 "Link to this image")
  id: totrans-649
  prefs: []
  type: TYPE_NORMAL
  zh: 图 203 CSMA/CA 的详细示例[#](#id90 "链接到这张图片")
- en: The pseudo-code below summarizes the operation of a CSMA/CA device. The values
    of the SIFS, DIFS, EIFS and \(slotTime\) depend on the underlying physical layer
    technology [[IEEE802.11]](../bibliography.html#ieee802-11)
  id: totrans-650
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的伪代码总结了 CSMA/CA 设备的操作。SIFS、DIFS、EIFS 和 \(slotTime\) 的值取决于底层物理层技术 [[IEEE802.11]](../bibliography.html#ieee802-11)
- en: '[PRE19]'
  id: totrans-651
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Another problem faced by wireless networks is often called the hidden station
    problem. In a wireless network, radio signals are not always propagated same way
    in all directions. For example, two devices separated by a wall may not be able
    to receive each other’s signal while they could both be receiving the signal produced
    by a third host. This is illustrated in the figure below, but it can happen in
    other environments. For example, two devices that are on different sides of a
    hill may not be able to receive each other’s signal while they are both able to
    receive the signal sent by a station at the top of the hill. Furthermore, the
    radio propagation conditions may change with time. For example, a truck may temporarily
    block the communication between two nearby devices.
  id: totrans-652
  prefs: []
  type: TYPE_NORMAL
  zh: 无线网络面临的另一个问题通常被称为隐藏站问题。在无线网络中，无线电信号并不总是以相同的方式向所有方向传播。例如，被墙壁隔开的两个设备可能无法接收到对方的信号，尽管它们都能接收到由第三个主机产生的信号。这在下图中得到了说明，但这种情况也可能发生在其他环境中。例如，位于山的不同侧的两个设备可能无法接收到对方的信号，尽管它们都能接收到山顶站发送的信号。此外，无线电传播条件可能会随时间变化。例如，一辆卡车可能会暂时阻断两个附近设备之间的通信。
- en: '[![../_images/csmaca-hidden.png](../Images/1dd2db4f7a4f3df51403915d42254672.png)](../_images/csmaca-hidden.png)'
  id: totrans-653
  prefs: []
  type: TYPE_NORMAL
  zh: '[![../_images/csmaca-hidden.png](../Images/1dd2db4f7a4f3df51403915d42254672.png)](../_images/csmaca-hidden.png)'
- en: Fig. 204 The hidden station problem[#](#id91 "Link to this image")
  id: totrans-654
  prefs: []
  type: TYPE_NORMAL
  zh: 图 204 隐藏站问题[#](#id91 "链接到这张图片")
- en: 'To avoid collisions in these situations, CSMA/CA allows devices to reserve
    the transmission channel for some time. This is done by using two control frames
    : Request To Send (RTS) and Clear To Send (CTS). Both are very short frames to
    minimize the risk of collisions. To reserve the transmission channel, a device
    sends a RTS frame to the intended recipient of the data frame. The RTS frame contains
    the duration of the requested reservation. The recipient replies, after a SIFS
    delay, with a CTS frame which also contains the duration of the reservation. As
    the duration of the reservation has been sent in both RTS and CTS, all hosts that
    could collide with either the sender or the reception of the data frame are informed
    of the reservation. They can compute the total duration of the transmission and
    defer their access to the transmission channel until then. This is illustrated
    in the figure below where host A reserves the transmission channel to send a data
    frame to host B. Host C notices the reservation and defers its transmission.'
  id: totrans-655
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免这些情况下的碰撞，CSMA/CA 允许设备保留传输通道一段时间。这是通过使用两个控制帧来完成的：请求发送 (RTS) 和清除发送 (CTS)。这两个帧都非常短，以最大限度地减少碰撞的风险。为了保留传输通道，设备向数据帧的预期接收者发送一个
    RTS 帧。RTS 帧包含请求保留的持续时间。接收者在 SIFS 延迟后回复一个 CTS 帧，该帧也包含保留的持续时间。由于保留的持续时间已在 RTS 和
    CTS 中发送，所有可能与其他发送者或接收数据帧的接收者发生碰撞的主机都会被告知保留情况。它们可以计算传输的总持续时间，并在那时推迟对传输通道的访问。这在下图中得到了说明，其中主机
    A 保留传输通道以向主机 B 发送数据帧。主机 C 注意到保留并推迟其传输。
- en: '[![../_images/csmaca-reserv.png](../Images/d32c0a1c69694ffdbad7f26e535e2135.png)](../_images/csmaca-reserv.png)'
  id: totrans-656
  prefs: []
  type: TYPE_NORMAL
  zh: '![CSMA/CA 保留](../Images/d32c0a1c69694ffdbad7f26e535e2135.png)'
- en: Fig. 205 Reservations with CSMA/CA[#](#id92 "Link to this image")
  id: totrans-657
  prefs: []
  type: TYPE_NORMAL
  zh: 图 205 CSMA/CA 保留[#](#id92 "链接到本图像")
- en: The utilization of the reservations with CSMA/CA is an optimization that is
    useful when collisions are frequent. If there are few collisions, the time required
    to transmit the RTS and CTS frames can become significant and in particular when
    short frames are exchanged. Some devices only turn on RTS/CTS after transmission
    errors.
  id: totrans-658
  prefs: []
  type: TYPE_NORMAL
  zh: 在 CSMA/CA 中使用保留是一种在碰撞频繁时有用的优化。如果碰撞很少，传输 RTS 和 CTS 帧所需的时间可能会变得显著，尤其是在交换短帧时。一些设备仅在传输错误后才会开启
    RTS/CTS。
- en: Deterministic Medium Access Control algorithms[#](#deterministic-medium-access-control-algorithms
    "Link to this heading")
  id: totrans-659
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 确定性介质访问控制算法[#](#deterministic-medium-access-control-algorithms "链接到本标题")
- en: During the 1970s and 1980s, there were huge debates in the networking community
    about the best suited Medium Access Control algorithms for Local Area Networks.
    The optimistic algorithms that we have described until now were relatively easy
    to implement when they were designed. From a performance perspective, mathematical
    models and simulations showed the ability of these optimistic techniques to sustain
    load. However, none of the optimistic techniques are able to guarantee that a
    frame will be delivered within a given delay bound and some applications require
    predictable transmission delays. The deterministic MAC algorithms were considered
    by a fraction of the networking community as the best solution to fulfill the
    needs of Local Area Networks.
  id: totrans-660
  prefs: []
  type: TYPE_NORMAL
  zh: 在 1970 年代和 1980 年代，网络社区就适用于局域网的最佳介质访问控制算法进行了大量辩论。我们至今所描述的乐观算法在设计时相对容易实现。从性能角度来看，数学模型和模拟显示这些乐观技术能够维持负载。然而，没有任何乐观技术能够保证在给定的延迟界限内交付帧，而某些应用程序需要可预测的传输延迟。网络社区中的一部分人认为，确定性介质访问控制算法是满足局域网需求的最佳解决方案。
- en: Both the proponents of the deterministic and the opportunistic techniques lobbied
    to develop standards for Local Area networks that would incorporate their solution.
    Instead of trying to find an impossible compromise between these diverging views,
    the IEEE 802 committee that was chartered to develop Local Area Network standards
    chose to work in parallel on three different LAN technologies and created three
    working groups. The [IEEE 802.3 working group](http://www.ieee802.org/3/) became
    responsible for CSMA/CD. The proponents of deterministic MAC algorithms agreed
    on the basic principle of exchanging special frames called tokens between devices
    to regulate the access to the transmission medium. However, they did not agree
    on the most suitable physical layout for the network. IBM argued in favor of Ring-shaped
    networks while the manufacturing industry, led by General Motors, argued in favor
    of a bus-shaped network. This led to the creation of the [IEEE 802.4 working group](http://www.ieee802.org/4/)
    to standardize Token Bus networks and the [IEEE 802.5 working group](http://www.ieee802.org/5/)
    to standardize Token Ring networks. Although these techniques are not widely used
    anymore today, the principles behind a token-based protocol are still important.
  id: totrans-661
  prefs: []
  type: TYPE_NORMAL
  zh: 决定性技术和机会主义技术的支持者都游说制定适用于局域网的标准化方案，以纳入他们的解决方案。而不是试图在这两种相互矛盾的观点之间找到一个不可能的折衷方案，负责制定局域网标准的IEEE
    802委员会选择并行工作于三种不同的局域网技术，并成立了三个工作组。[IEEE 802.3工作组](http://www.ieee802.org/3/)负责CSMA/CD。确定性MAC算法的支持者就交换称为令牌的特殊帧以调节对传输介质访问的基本原则达成一致。然而，他们并没有就网络最合适的物理布局达成一致。IBM支持环形网络，而由通用汽车领导的制造业则支持总线形网络。这导致了[IEEE
    802.4工作组](http://www.ieee802.org/4/)的成立，以标准化令牌总线网络，以及[IEEE 802.5工作组](http://www.ieee802.org/5/)的成立，以标准化令牌环网络。尽管这些技术今天不再广泛使用，但基于令牌的协议背后的原则仍然很重要。
- en: The IEEE 802.5 Token Ring technology is defined in [[IEEE802.5]](../bibliography.html#ieee802-5).
    We use Token Ring as an example to explain the principles of the token-based MAC
    algorithms in ring-shaped networks. Other ring-shaped networks include the defunct
    FDDI [[Ross1989]](../bibliography.html#ross1989) or Resilient Pack Ring [[DYGU2004]](../bibliography.html#dygu2004)
    . A good survey of the early token ring networks may be found in [[Bux1989]](../bibliography.html#bux1989)
    .
  id: totrans-662
  prefs: []
  type: TYPE_NORMAL
  zh: IEEE 802.5令牌环技术定义在[[IEEE802.5]](../bibliography.html#ieee802-5)。我们以令牌环为例，解释环形网络中基于令牌的MAC算法的原理。其他环形网络包括已废弃的FDDI
    [[Ross1989]](../bibliography.html#ross1989) 或弹性包环 [[DYGU2004]](../bibliography.html#dygu2004)。早期令牌环网络的一个良好综述可以在[[Bux1989]](../bibliography.html#bux1989)中找到。
- en: 'A Token Ring network is composed of a set of stations that are attached to
    a unidirectional ring. The basic principle of the Token Ring MAC algorithm is
    that two types of frames travel on the ring : tokens and data frames. When the
    Token Ring starts, one of the stations sends the token. The token is a small frame
    that represents the authorization to transmit data frames on the ring. To transmit
    a data frame on the ring, a station must first capture the token by removing it
    from the ring. As only one station can capture the token at a time, the station
    that owns the token can safely transmit a data frame on the ring without risking
    collisions. After having transmitted its frame, the station must remove it from
    the ring and resend the token so that other stations can transmit their own frames.'
  id: totrans-663
  prefs: []
  type: TYPE_NORMAL
  zh: 令牌环网络由一组连接到单向环上的站点组成。令牌环MAC算法的基本原理是，两种类型的帧在环上传输：令牌和数据帧。当令牌环启动时，其中一个站点发送令牌。令牌是一个小帧，代表在环上传输数据帧的授权。要传输数据帧到环上，一个站点必须首先通过从环上移除令牌来捕获它。由于一次只能有一个站点捕获令牌，拥有令牌的站点可以安全地在环上传输数据帧，而不会造成冲突。在传输完其帧后，该站点必须将其从环上移除并重新发送令牌，以便其他站点可以传输它们自己的帧。
- en: '[![../_images/token-ring.png](../Images/204991c6fea7862f915a3396c1578736.png)](../_images/token-ring.png)'
  id: totrans-664
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/token-ring.png](../Images/204991c6fea7862f915a3396c1578736.png)'
- en: Fig. 206 A Token Ring network[#](#id93 "Link to this image")
  id: totrans-665
  prefs: []
  type: TYPE_NORMAL
  zh: 图206 令牌环网络[#](#id93 "链接到这张图片")
- en: While the basic principles of the Token Ring are simple, there are several subtle
    implementation details that add complexity to Token Ring networks. To understand
    these details let us analyze the operation of a Token Ring interface on a station.
    A Token Ring interface serves three different purposes. Like other LAN interfaces,
    it must be able to send and receive frames. In addition, a Token Ring interface
    is part of the ring, and as such, it must be able to forward the electrical signal
    that passes on the ring even when its station is powered off.
  id: totrans-666
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然令牌环的基本原理很简单，但有几个细微的实现细节增加了令牌环网络的复杂性。为了理解这些细节，让我们分析一个站上的令牌环接口的操作。令牌环接口有三个不同的用途。像其他局域网接口一样，它必须能够发送和接收帧。此外，令牌环接口是环的一部分，因此它必须能够在其站关闭电源时转发环上传递的电信号。
- en: 'When powered-on, Token Ring interfaces operate in two different modes : listen
    and transmit. When operating in listen mode, a Token Ring interface receives an
    electrical signal from its upstream neighbor on the ring, introduces a delay equal
    to the transmission time of one bit on the ring and regenerates the signal before
    sending it to its downstream neighbor on the ring.'
  id: totrans-667
  prefs: []
  type: TYPE_NORMAL
  zh: 当启动时，令牌环接口以两种不同的模式运行：监听和传输。在监听模式下，令牌环接口从环上的上游邻居接收一个电信号，在环上引入一个等于一个比特传输时间的延迟，并在将其发送到环上的下游邻居之前再生该信号。
- en: The first problem faced by a Token Ring network is that as the token represents
    the authorization to transmit, it must continuously travel on the ring when no
    data frame is being transmitted. Let us assume that a token has been produced
    and sent on the ring by one station. In Token Ring networks, the token is a 24
    bits frame whose structure is shown below.
  id: totrans-668
  prefs: []
  type: TYPE_NORMAL
  zh: 令牌环网络面临的第一问题是，作为传输授权的令牌，在没有数据帧传输时，它必须持续在环上传输。让我们假设一个令牌已经被一个站生成并发送到环上。在令牌环网络中，令牌是一个24比特的帧，其结构如下所示。
- en: '[![../_images/token-ring.svg](../Images/d3fd5c0099436c887eea9ad8ae351d82.png)](../_images/token-ring.svg)'
  id: totrans-669
  prefs: []
  type: TYPE_NORMAL
  zh: '[![../_images/token-ring.svg](../Images/d3fd5c0099436c887eea9ad8ae351d82.png)](../_images/token-ring.svg)'
- en: Fig. 207 802.5 token format[#](#id94 "Link to this image")
  id: totrans-670
  prefs: []
  type: TYPE_NORMAL
  zh: 图. 207 802.5令牌格式[#](#id94 "链接到这张图片")
- en: The token is composed of three fields. First, the Starting Delimiter is the
    marker that indicates the beginning of a frame. The first Token Ring networks
    used Manchester coding and the Starting Delimiter contained both symbols representing
    0 and symbols that do not represent bits. The last field is the Ending Delimiter
    which marks the end of the token. The Access Control field is present in all frames,
    and contains several flags. The most important is the Token bit that is set in
    token frames and reset in other frames.
  id: totrans-671
  prefs: []
  type: TYPE_NORMAL
  zh: 令牌由三个字段组成。首先，起始定界符是表示帧开始的标记。最初的令牌环网络使用曼彻斯特编码，起始定界符包含表示0的符号和不表示比特的符号。最后一个字段是结束定界符，它标记令牌的结束。访问控制字段存在于所有帧中，并包含几个标志。最重要的是令牌位，它在令牌帧中设置，在其他帧中重置。
- en: Let us consider the five station network depicted in figure [A Token Ring network](#fig-tokenring)
    above and assume that station S1 sends a token. If we neglect the propagation
    delay on the inter-station links, as each station introduces a one bit delay,
    the first bit of the frame would return to S1 while it sends the fifth bit of
    the token. If station S1 is powered off at that time, only the first five bits
    of the token will travel on the ring. To avoid this problem, there is a special
    station called the Monitor on each Token Ring. To ensure that the token can travel
    forever on the ring, this Monitor inserts a delay that is equal to at least 24
    bit transmission times. If station S3 was the Monitor in figure [A Token Ring
    network](#fig-tokenring), S1 would have been able to transmit the entire token
    before receiving the first bit of the token from its upstream neighbor.
  id: totrans-672
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑上面图 [A Token Ring network](#fig-tokenring) 所示的五站网络，并假设站S1发送一个令牌。如果我们忽略站间链路上的传播延迟，因为每个站引入一个比特延迟，帧的第一个比特会在发送令牌的第五比特时返回到S1。如果那时站S1关闭电源，只有令牌的前五个比特会在环上传输。为了避免这个问题，每个令牌环上都有一个特殊的站，称为监控站。为了确保令牌可以在环上永远传输，这个监控站插入一个等于至少24比特传输时间的延迟。如果图
    [A Token Ring network](#fig-tokenring) 中的监控站是S3，S1就能在从其上游邻居接收令牌的第一个比特之前发送整个令牌。
- en: Now that we have explained how the token can be forwarded on the ring, let us
    analyze how a station can capture a token to transmit a data frame. For this,
    we need some information about the format of the data frames. An 802.5 data frame
    begins with the Starting Delimiter followed by the Access Control field whose
    Token bit is reset, a Frame Control field that enables the definition of several
    types of frames, destination and source address, a payload, a CRC, the Ending
    Delimiter and a Frame Status field. The format of the Token Ring data frames is
    illustrated below.
  id: totrans-673
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经解释了如何在环上转发令牌，那么让我们分析一下一个站点如何捕获令牌以发送数据帧。为此，我们需要了解一些关于数据帧格式的信息。802.5 数据帧以起始定界符开始，随后是令牌位被重置的访问控制字段，一个允许定义多种类型帧的帧控制字段，目的地址和源地址，有效载荷，CRC，结束定界符和一个帧状态字段。Token
    Ring 数据帧的格式如下所示。
- en: '[![../_images/8025.svg](../Images/9f175bb0486e691ee2c9018db5a42d22.png)](../_images/8025.svg)'
  id: totrans-674
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/8025.svg](../Images/9f175bb0486e691ee2c9018db5a42d22.png)'
- en: Fig. 208 802.5 data frame format[#](#id95 "Link to this image")
  id: totrans-675
  prefs: []
  type: TYPE_NORMAL
  zh: 图 208 802.5 数据帧格式[#](#id95 "链接到这张图片")
- en: To capture a token, a station must operate in Listen mode. In this mode, the
    station receives bits from its upstream neighbor. If the bits correspond to a
    data frame, they must be forwarded to the downstream neighbor. If they correspond
    to a token, the station can capture it and transmit its data frame. Both the data
    frame and the token are encoded as a bit string beginning with the Starting Delimiter
    followed by the Access Control field. When the station receives the first bit
    of a Starting Delimiter, it cannot know whether this is a data frame or a token
    and must forward the entire delimiter to its downstream neighbor. It is only when
    it receives the fourth bit of the Access Control field (i.e. the Token bit) that
    the station knows whether the frame is a data frame or a token. If the Token bit
    is reset, it indicates a data frame and the remaining bits of the data frame must
    be forwarded to the downstream station. Otherwise (Token bit is set), this is
    a token and the station can capture it by resetting the bit that is currently
    in its buffer. Thanks to this modification, the beginning of the token is now
    the beginning of a data frame and the station can switch to Transmit mode and
    send its data frame starting at the fifth bit of the Access Control field. Thus,
    the one-bit delay introduced by each Token Ring station plays a key role in enabling
    the stations to efficiently capture the token.
  id: totrans-676
  prefs: []
  type: TYPE_NORMAL
  zh: 要捕获令牌，站点必须处于监听模式。在此模式下，站点从其上游邻居接收位。如果这些位对应于数据帧，它们必须转发给下游邻居。如果它们对应于令牌，站点可以捕获它并发送其数据帧。数据帧和令牌都编码为以起始定界符开始，随后是访问控制字段的位字符串。当站点接收到起始定界符的第一个位时，它无法知道这是一个数据帧还是一个令牌，必须将整个定界符转发给其下游邻居。只有当它接收到访问控制字段的第四位（即令牌位）时，站点才知道该帧是数据帧还是令牌。如果令牌位被重置，它表示这是一个数据帧，数据帧的其余位必须转发给下游站点。否则（令牌位被设置），这是一个令牌，站点可以通过重置其缓冲区中当前位的位来捕获它。多亏了这个修改，令牌的开始现在就是数据帧的开始，站点可以切换到传输模式，并从访问控制字段的第五位开始发送其数据帧。因此，每个
    Token Ring 站点引入的一个位延迟在使站点能够有效地捕获令牌方面起着关键作用。
- en: After having transmitted its data frame, the station must remain in Transmit
    mode until it has received the last bit of its own data frame. This ensures that
    the bits sent by a station do not remain in the network forever. A data frame
    sent by a station in a Token Ring network passes in front of all stations attached
    to the network. Each station can detect the data frame and analyze the destination
    address to possibly capture the frame.
  id: totrans-677
  prefs: []
  type: TYPE_NORMAL
  zh: 在发送完其数据帧后，站点必须保持在传输模式，直到它接收到自己数据帧的最后一位。这确保了站点发送的位不会永远留在网络中。在 Token Ring 网络中，由站点发送的数据帧会经过网络中连接的所有站点。每个站点都可以检测到数据帧并分析目的地址，以可能捕获该帧。
- en: The text above describes the basic operation of a Token Ring network when all
    stations work correctly. Unfortunately, a real Token Ring network must be able
    to handle various types of anomalies and this increases the complexity of Token
    Ring stations. We briefly list the problems and outline their solutions below.
    A detailed description of the operation of Token Ring stations may be found in
    [[IEEE802.5]](../bibliography.html#ieee802-5). The first problem is when all the
    stations attached to the network start. One of them must bootstrap the network
    by sending the first token. For this, all stations implement a distributed election
    mechanism that is used to select the Monitor. Any station can become a Monitor.
    The Monitor manages the Token Ring network and ensures that it operates correctly.
    Its first role is to introduce a delay of 24 bit transmission times to ensure
    that the token can travel smoothly on the ring. Second, the Monitor sends the
    first token on the ring. It must also verify that the token passes regularly.
    According to the Token Ring standard [[IEEE802.5]](../bibliography.html#ieee802-5),
    a station cannot retain the token to transmit data frames for a duration longer
    than the Token Holding Time (THT) (slightly less than 10 milliseconds). On a network
    containing N stations, the Monitor must receive the token at least every \(N \times
    THT\) seconds. If the Monitor does not receive a token during such a period, it
    cuts the ring for some time and then re-initializes the ring and sends a token.
  id: totrans-678
  prefs: []
  type: TYPE_NORMAL
  zh: 上文描述了当所有站点都正常工作时，令牌环网络的基本操作。不幸的是，一个真实的令牌环网络必须能够处理各种类型的异常，这增加了令牌环站点的复杂性。我们简要列出了一些问题和它们的解决方案。有关令牌环站点操作的详细描述，请参阅[[IEEE802.5]](../bibliography.html#ieee802-5)。第一个问题是当所有连接到网络的站点启动时。其中之一必须通过发送第一个令牌来引导网络。为此，所有站点都实现了一种分布式选举机制，用于选择监控器。任何站点都可以成为监控器。监控器管理令牌环网络并确保其正确运行。它的第一个角色是引入24位传输时间的延迟，以确保令牌可以在环上平稳地传输。其次，监控器在环上发送第一个令牌。它还必须验证令牌是否定期通过。根据令牌环标准[[IEEE802.5]](../bibliography.html#ieee802-5)，一个站点不能保留令牌超过令牌保持时间（THT）（略小于10毫秒）来传输数据帧。在一个包含N个站点的网络中，监控器必须至少每\(N
    \times THT\)秒接收一次令牌。如果监控器在这样一个时间段内没有收到令牌，它将切断一段时间，然后重新初始化环并发送令牌。
- en: Several other anomalies may occur in a Token Ring network. For example, a station
    could capture a token and be powered off before having resent the token. Another
    station could have captured the token, sent its data frame and be powered off
    before receiving all of its data frame. In this case, the bit string corresponding
    to the end of a frame would remain in the ring without being removed by its sender.
    Several techniques are defined in [[IEEE802.5]](../bibliography.html#ieee802-5)
    to allow the Monitor to handle all these problems. If unfortunately, the Monitor
    fails, another station will be elected to become the new Monitor.
  id: totrans-679
  prefs: []
  type: TYPE_NORMAL
  zh: 在令牌环网络中可能发生其他一些异常。例如，一个站点可能在重新发送令牌之前捕获令牌并关闭电源。另一个站点可能在收到所有数据帧之前捕获令牌、发送其数据帧并关闭电源。在这种情况下，对应于帧结束的比特串将保留在环中，而不会被其发送者移除。[[IEEE802.5]](../bibliography.html#ieee802-5)中定义了多种技术，允许监控器处理所有这些问题。如果不幸的是监控器失败，另一台站点将被选为新的监控器。
- en: Congestion control[#](#congestion-control "Link to this heading")
  id: totrans-680
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**拥塞控制**[#](#congestion-control "链接到本标题")'
- en: Most networks contain links having different bandwidth. Some hosts can use low
    bandwidth wireless networks. Some servers are attached via 10 Gbps interfaces
    and inter-router links may vary from a few tens of kilobits per second up to hundred
    Gbps. Despite these huge differences in performance, any host should be able to
    efficiently exchange segments with a high-end server.
  id: totrans-681
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数网络包含具有不同带宽的链路。一些主机可以使用低带宽无线网络。一些服务器通过10 Gbps接口连接，路由器之间的链路可能从每秒几十千比特到百吉比特不等。尽管这些性能差异巨大，任何主机都应该能够与高端服务器高效地交换段。
- en: To understand this problem better, let us consider the scenario shown in the
    figure below, where a server (A) attached to a 10 Mbps link needs to reliably
    transfer segments to another computer (C) through a path that contains a 2 Mbps
    link.
  id: totrans-682
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解这个问题，让我们考虑以下图中的场景，其中一台连接到10 Mbps链路的服务器（A）需要通过包含2 Mbps链路的路径可靠地将段传输到另一台计算机（C）。
- en: '![Figure made with TikZ](../Images/437492f9ed4cdc7e563973c918bb6989.png)'
  id: totrans-683
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用TikZ制作的图](../Images/437492f9ed4cdc7e563973c918bb6989.png)'
- en: ''
  id: totrans-684
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 209 Reliable transport with heterogeneous links
  id: totrans-685
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图209. 具有异构链路的可靠传输
- en: In this network, the segments sent by the server reach router R1. R1 forwards
    the segments towards router R2. Router R1 can potentially receive segments at
    10 Mbps, but it can only forward them at 2 Mbps to router R2 and then to host
    C. Router R1 includes buffers that allow it to store the packets that cannot immediately
    be forwarded to their destination. To understand the operation of a reliable transport
    protocol in this environment, let us consider a simplified model of this network
    where host A is attached to a 10 Mbps link to a queue that represents the buffers
    of router R1. This queue is emptied at a rate of 2 Mbps.
  id: totrans-686
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个网络中，服务器发送的数据段到达路由器R1。R1将数据段转发到路由器R2。路由器R1可以以10 Mbps的速度接收数据段，但它只能以2 Mbps的速度将它们转发到路由器R2，然后到主机C。路由器R1包括缓冲区，允许它存储那些不能立即转发到其目标的数据包。为了理解在这种环境中可靠传输协议的操作，让我们考虑这个网络的简化模型，其中主机A连接到一个10
    Mbps的链路到一个表示路由器R1缓冲区的队列。这个队列以2 Mbps的速度清空。
- en: '[![../_images/tcp-self-clocking.png](../Images/84e88a885a2921ce9a2b332adc09db01.png)](../_images/tcp-self-clocking.png)'
  id: totrans-687
  prefs: []
  type: TYPE_NORMAL
  zh: '[![../_images/tcp-self-clocking.png](../Images/84e88a885a2921ce9a2b332adc09db01.png)](../_images/tcp-self-clocking.png)'
- en: Fig. 210 Self clocking[#](#id97 "Link to this image")
  id: totrans-688
  prefs: []
  type: TYPE_NORMAL
  zh: 图210 自时钟[#](#id97 "链接到这张图片")
- en: Let us consider that host A uses a window of three segments. It thus sends three
    back-to-back segments at 10 Mbps and then waits for an acknowledgment. Host A
    stops sending segments when its window is full. These segments reach the buffers
    of router R1. The first segment stored in this buffer is sent by router R1 at
    a rate of 2 Mbps to the destination host. Upon reception of this segment, the
    destination sends an acknowledgment. This acknowledgment allows host A to transmit
    a new segment. This segment is stored in the buffers of router R1 while it is
    transmitting the second segment that was sent by host A… Thus, after the transmission
    of the first window of segments, the reliable transport protocol sends one data
    segment after the reception of each acknowledgment returned by the destination.
    In practice, the acknowledgments sent by the destination serve as a kind of clock
    that allows the sending host to adapt its transmission rate to the rate at which
    segments are received by the destination. This self-clocking is the first mechanism
    that allows a window-based reliable transport protocol to adapt to heterogeneous
    networks [[Jacobson1988]](../bibliography.html#jacobson1988). It depends on the
    availability of buffers to store the segments that have been sent by the sender
    but have not yet been transmitted to the destination.
  id: totrans-689
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑主机A使用三个数据段大小的窗口。因此，它以10 Mbps的速度连续发送三个数据段，然后等待确认。当主机A的窗口满时，它停止发送数据段。这些数据段到达路由器R1的缓冲区。在这个缓冲区中存储的第一个数据段以2
    Mbps的速度由路由器R1发送到目标主机。在接收到这个数据段后，目标主机发送一个确认。这个确认允许主机A传输一个新的数据段。这个数据段在路由器R1传输由主机A发送的第二个数据段时存储在缓冲区中……因此，在传输第一窗口的数据段之后，可靠的传输协议在接收到目标主机返回的每个确认后发送一个数据段。在实践中，目标主机发送的确认充当一种时钟，允许发送主机调整其传输速率以适应目标主机接收数据段的速度。这种自时钟是允许基于窗口的可靠传输协议适应异构网络的第一种机制[[Jacobson1988]](../bibliography.html#jacobson1988)。它依赖于缓冲区的可用性来存储已由发送方发送但尚未传输到目标的数据段。
- en: However, transport protocols are not only used in this environment. In the global
    Internet, a large number of hosts send segments to a large number of receivers.
    For example, let us consider the network depicted below which is similar to the
    one discussed in [[Jacobson1988]](../bibliography.html#jacobson1988) and [**RFC
    896**](https://datatracker.ietf.org/doc/html/rfc896.html). In this network, we
    assume that the buffers of the router are infinite to ensure that no packet is
    lost.
  id: totrans-690
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，传输协议不仅用于这种环境。在全球互联网中，大量主机向大量接收者发送数据段。例如，让我们考虑以下网络，它与[[Jacobson1988]](../bibliography.html#jacobson1988)和[**RFC
    896**](https://datatracker.ietf.org/doc/html/rfc896.html)中讨论的网络相似。在这个网络中，我们假设路由器的缓冲区是无限的，以确保没有数据包丢失。
- en: '![Figure made with TikZ](../Images/0f464428bb4f3f9bf9d9d1dbaafd389d.png)'
  id: totrans-691
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用TikZ制作的图](../Images/0f464428bb4f3f9bf9d9d1dbaafd389d.png)'
- en: ''
  id: totrans-692
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 211 The congestion collapse problem
  id: totrans-693
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图211 拥塞崩溃问题
- en: If many senders are attached to the left part of the network above, they all
    send a window full of segments. These segments are stored in the buffers of the
    router before being transmitted towards their destination. If there are many senders
    on the left part of the network, the occupancy of the buffers quickly grows. A
    consequence of the buffer occupancy is that the round-trip-time, measured by the
    transport protocol, between the sender and the receiver increases. Consider a
    network where 10,000 bits segments are sent. When the buffer is empty, such a
    segment requires 1 millisecond to be transmitted on the 10 Mbps link and 5 milliseconds
    to be the transmitted on the 2 Mbps link. Thus, the measured round-trip-time measured
    is roughly 6 milliseconds if we ignore the propagation delay on the links. If
    the buffer contains 100 segments, the round-trip-time becomes \(1+100 \times 5+
    5\) milliseconds as new segments are only transmitted on the 2 Mbps link once
    all previous segments have been transmitted. Unfortunately, if the reliable transport
    protocol uses a retransmission timer and performs go-back-n to recover from transmission
    errors it will retransmit a full window of segments. This increases the occupancy
    of the buffer and the delay through the buffer… Furthermore, the buffer may store
    and send on the low bandwidth links several retransmissions of the same segment.
    This problem is called congestion collapse. It occurred several times during the
    late 1980s on the Internet [[Jacobson1988]](../bibliography.html#jacobson1988).
  id: totrans-694
  prefs: []
  type: TYPE_NORMAL
  zh: 如果许多发送器连接到上述网络的左侧部分，它们都会发送一个满窗口的段。这些段在传输到目的地之前被存储在路由器的缓冲区中。如果网络左侧有许多发送器，缓冲区的占用率会迅速增长。缓冲区占用的一个后果是，由传输协议测量的发送器和接收器之间的往返时间增加。考虑一个发送10,000位段的网络。当缓冲区为空时，这样的段在10
    Mbps链路上传输需要1毫秒，在2 Mbps链路上传输需要5毫秒。因此，如果我们忽略链路上的传播延迟，测量的往返时间大约是6毫秒。如果缓冲区包含100个段，往返时间变为
    \(1+100 \times 5+ 5\) 毫秒，因为只有在所有之前的段都传输完毕后，新的段才会通过2 Mbps链路传输。不幸的是，如果可靠的传输协议使用重传计时器并执行回退-n来从传输错误中恢复，它将重传一个完整的窗口段。这增加了缓冲区的占用率和通过缓冲区的延迟……此外，缓冲区可能在低带宽链路上存储和发送相同段的多个重传。这个问题被称为拥塞崩溃。在20世纪80年代末的互联网上发生了几次这种情况
    [[Jacobson1988]](../bibliography.html#jacobson1988)。
- en: The congestion collapse is a problem that all heterogeneous networks face. Different
    mechanisms have been proposed in the scientific literature to avoid or control
    network congestion. Some of them have been implemented and deployed in real networks.
    To understand this problem in more detail, let us first consider a simple network
    with two hosts attached to a high bandwidth link that are sending segments to
    destination C attached to a low bandwidth link as depicted below.
  id: totrans-695
  prefs: []
  type: TYPE_NORMAL
  zh: 拥塞崩溃是所有异构网络都面临的问题。科学文献中已经提出了不同的机制来避免或控制网络拥塞。其中一些已经在实际网络中得到实施和部署。为了更详细地了解这个问题，让我们先考虑一个简单的网络，其中有两个主机连接到高带宽链路，它们向连接到低带宽链路的C目的地发送段，如下所示。
- en: '![Figure made with TikZ](../Images/81b044c15b073243b51b376b5d57bf3d.png)'
  id: totrans-696
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用TikZ制作的图](../Images/81b044c15b073243b51b376b5d57bf3d.png)'
- en: ''
  id: totrans-697
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 212 The congestion problem
  id: totrans-698
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图. 212 拥塞问题
- en: To avoid congestion collapse, the hosts must regulate their transmission rate
    [[5]](#fcredit) by using a congestion control mechanism. Such a mechanism can
    be implemented in the transport layer or in the network layer. In TCP/IP networks,
    it is implemented in the transport layer, but other technologies such as Asynchronous
    Transfer Mode (ATM) or Frame Relay include congestion control mechanisms in lower
    layers.
  id: totrans-699
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免拥塞崩溃，主机必须通过使用拥塞控制机制来调节它们的传输速率 [[5]](#fcredit)。这样的机制可以在传输层或网络层实现。在TCP/IP网络中，它是在传输层实现的，但其他技术如异步传输模式（ATM）或帧中继在较低层包含了拥塞控制机制。
- en: 'Let us first consider the simple problem of a set of \(i\) hosts that share
    a single bottleneck link as shown in the example above. In this network, the congestion
    control scheme must achieve the following objectives [[CJ1989]](../bibliography.html#cj1989)
    :'
  id: totrans-700
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先考虑一个简单的例子，其中一组 \(i\) 个主机共享一个瓶颈链路，如上例所示。在这个网络中，拥塞控制方案必须实现以下目标 [[CJ1989]](../bibliography.html#cj1989)：
- en: The congestion control scheme must avoid congestion. In practice, this means
    that the bottleneck link cannot be overloaded. If \(r_i(t)\) is the transmission
    rate allocated to host \(i\) at time \(t\) and \(R\) the bandwidth of the bottleneck
    link, then the congestion control scheme should ensure that, on average, \(\forall{t}
    \sum{r_i(t)} \le R\).
  id: totrans-701
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 控制拥塞的方案必须避免拥塞。在实践中，这意味着瓶颈链路不能过载。如果 \(r_i(t)\) 是在时间 \(t\) 分配给主机 \(i\) 的传输速率，而
    \(R\) 是瓶颈链路的带宽，那么拥塞控制方案应确保，平均而言，\(\forall{t} \sum{r_i(t)} \le R\)。
- en: ''
  id: totrans-702
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-703
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: The congestion control scheme must be efficient. The bottleneck link is usually
    both a shared and an expensive resource. Usually, bottleneck links are wide area
    links that are much more expensive to upgrade than the local area networks. The
    congestion control scheme should ensure that such links are efficiently used.
    Mathematically, the control scheme should ensure that \(\forall{t} \sum{r_i(t)}
    \approx R\).
  id: totrans-704
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 控制拥塞的方案必须高效。瓶颈链路通常是共享且昂贵的资源。通常，瓶颈链路是广域链路，其升级成本远高于局域网。拥塞控制方案应确保这些链路得到有效利用。从数学上讲，控制方案应确保
    \(\forall{t} \sum{r_i(t)} \approx R\)。
- en: ''
  id: totrans-705
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-706
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The congestion control scheme should be fair. Most congestion schemes aim at
    achieving max-min fairness. An allocation of transmission rates to sources is
    said to be max-min fair if :'
  id: totrans-707
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 控制拥塞的方案应该是公平的。大多数拥塞方案的目标是达到最大最小公平性。如果将传输速率分配给源头的分配被认为是最大最小公平的，那么：
- en: ''
  id: totrans-708
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-709
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-710
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: no link in the network is congested
  id: totrans-711
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络中没有任何链路拥塞
- en: ''
  id: totrans-712
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-713
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: the rate allocated to source \(j\) cannot be increased without decreasing the
    rate allocated to a source \(i\) whose allocation is smaller than the rate allocated
    to source \(j\) [[Leboudec2008]](../bibliography.html#leboudec2008) .
  id: totrans-714
  prefs:
  - PREF_BQ
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分配给源 \(j\) 的速率不能增加，除非减少分配给分配小于源 \(j\) 的速率的源 \(i\) [[Leboudec2008]](../bibliography.html#leboudec2008)
    。
- en: Depending on the network, a max-min fair allocation may not always exist. In
    practice, max-min fairness is an ideal objective that cannot necessarily be achieved.
    When there is a single bottleneck link as in the example above, max-min fairness
    implies that each source should be allocated the same transmission rate.
  id: totrans-715
  prefs: []
  type: TYPE_NORMAL
  zh: 根据网络的不同，最大最小公平分配可能并不总是存在。在实践中，最大最小公平性是一个理想的目标，可能无法实现。当存在单个瓶颈链路，如上述示例中，最大最小公平性意味着每个源头应分配相同的传输速率。
- en: To visualize the different rate allocations, it is useful to consider the graph
    shown below. In this graph, we plot on the x-axis (resp. y-axis) the rate allocated
    to host B (resp. A). A point in the graph \((r_B,r_A)\) corresponds to a possible
    allocation of the transmission rates. Since there is a 2 Mbps bottleneck link
    in this network, the graph can be divided into two regions. The lower left part
    of the graph contains all allocations \((r_B,r_A)\) such that the bottleneck link
    is not congested (\(r_A+r_B<2\)). The right border of this region is the efficiency
    line, i.e. the set of allocations that completely utilize the bottleneck link
    (\(r_A+r_B=2\)). Finally, the fairness line is the set of fair allocations.
  id: totrans-716
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可视化不同的速率分配，考虑下面的图是有用的。在这个图中，我们在 x 轴（分别 y 轴）上绘制分配给主机 B（分别 A）的速率。图中的点 \((r_B,r_A)\)
    对应于可能的传输速率分配。由于这个网络中有一个 2 Mbps 的瓶颈链路，因此图可以分为两个区域。图的左下部分包含所有不拥塞的分配 \((r_B,r_A)\)，即瓶颈链路不拥塞（\(r_A+r_B<2\)）。这个区域的右边是效率线，即完全利用瓶颈链路的分配集（\(r_A+r_B=2\)）。最后，公平线是公平分配的集合。
- en: '[![../_images/congestion-rates.png](../Images/9ccea874ced3496fad9f847266e5e96a.png)](../_images/congestion-rates.png)'
  id: totrans-717
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/congestion-rates.png](../Images/9ccea874ced3496fad9f847266e5e96a.png)'
- en: Fig. 213 Possible allocated transmission rates[#](#id100 "Link to this image")
  id: totrans-718
  prefs: []
  type: TYPE_NORMAL
  zh: 图 213 可能的传输速率分配[#](#id100 "链接到这张图片")
- en: As shown in the graph above, a rate allocation may be fair but not efficient
    (e.g. \(r_A=0.7,r_B=0.7\)), fair and efficient ( e.g. \(r_A=1,r_B=1\)) or efficient
    but not fair (e.g. \(r_A=1.5,r_B=0.5\)). Ideally, the allocation should be both
    fair and efficient. Unfortunately, maintaining such an allocation with fluctuations
    in the number of flows that use the network is a challenging problem. Furthermore,
    there might be several thousands flows that pass through the same link [[6]](#fflowslink).
  id: totrans-719
  prefs: []
  type: TYPE_NORMAL
  zh: 如上图所示，速率分配可能是公平但不高效的（例如 \(r_A=0.7,r_B=0.7\)），公平且高效（例如 \(r_A=1,r_B=1\)）或高效但不公平（例如
    \(r_A=1.5,r_B=0.5\)）。理想情况下，分配应该是公平且高效的。不幸的是，在流量的数量波动中保持这样的分配是一个具有挑战性的问题。此外，可能有数千个流量通过相同的链路
    [[6]](#fflowslink)。
- en: To deal with these fluctuations in demand, which result in fluctuations in the
    available bandwidth, computer networks use a congestion control scheme. This congestion
    control scheme should achieve the three objectives listed above. Some congestion
    control schemes rely on a close cooperation between the end hosts and the routers,
    while others are mainly implemented on the end hosts with limited support from
    the routers.
  id: totrans-720
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理这些需求波动，这些波动导致可用带宽波动，计算机网络使用拥塞控制方案。这个拥塞控制方案应该实现上述三个目标。一些拥塞控制方案依赖于终端主机和路由器之间的紧密合作，而其他方案主要在终端主机上实现，并从路由器获得有限的支持。
- en: A congestion control scheme can be modeled as an algorithm that adapts the transmission
    rate (\(r_i(t)\)) of host \(i\) based on the feedback received from the network.
    Different types of feedback are possible. The simplest scheme is a binary feedback
    [[CJ1989]](../bibliography.html#cj1989) [[Jacobson1988]](../bibliography.html#jacobson1988)
    where the hosts simply learn whether the network is congested or not. Some congestion
    control schemes allow the network to regularly send an allocated transmission
    rate in Mbps to each host [[BF1995]](../bibliography.html#bf1995).
  id: totrans-721
  prefs: []
  type: TYPE_NORMAL
  zh: 拥塞控制方案可以建模为一个算法，该算法根据从网络收到的反馈调整主机 \(i\) 的传输速率 (\(r_i(t)\))。可能的反馈类型有很多。最简单的方案是二进制反馈
    [[CJ1989]](../bibliography.html#cj1989) [[Jacobson1988]](../bibliography.html#jacobson1988)，其中主机只需学习网络是否拥塞。一些拥塞控制方案允许网络定期以
    Mbps 的速率向每个主机发送分配的传输速率 [[BF1995]](../bibliography.html#bf1995)。
- en: Let us focus on the binary feedback scheme which is the most widely used today.
    Intuitively, the congestion control scheme should decrease the transmission rate
    of a host when congestion has been detected in the network, in order to avoid
    congestion collapse. Furthermore, the hosts should increase their transmission
    rate when the network is not congested. Otherwise, the hosts would not be able
    to efficiently utilize the network. The rate allocated to each host fluctuates
    with time, depending on the feedback received from the network. Figure [Fig. 214](#fig-congestion-rates)
    illustrates the evolution of the transmission rates allocated to two hosts in
    our simple network. Initially, two hosts have a low allocation, but this is not
    efficient. The allocations increase until the network becomes congested. At this
    point, the hosts decrease their transmission rate to avoid congestion collapse.
    If the congestion control scheme works well, after some time the allocations should
    become both fair and efficient.
  id: totrans-722
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们关注目前最广泛使用的二进制反馈方案。直观上，拥塞控制方案应在检测到网络拥塞时降低主机的传输速率，以避免拥塞崩溃。此外，当网络不拥塞时，主机应增加其传输速率。否则，主机将无法有效地利用网络。分配给每个主机的速率会随着时间波动，这取决于从网络收到的反馈。图[图
    214](#fig-congestion-rates)展示了在我们简单网络中分配给两个主机的传输速率的演变。最初，两个主机的分配较低，但这并不高效。分配会增加到网络拥塞。在此点，主机降低其传输速率以避免拥塞崩溃。如果拥塞控制方案工作良好，经过一段时间后，分配应该既公平又高效。
- en: '[![../_images/congestion-rates-evolution.png](../Images/26c6fbe274fb53fd9009bee48fcdb53e.png)](../_images/congestion-rates-evolution.png)'
  id: totrans-723
  prefs: []
  type: TYPE_NORMAL
  zh: '[![../_images/congestion-rates-evolution.png](../Images/26c6fbe274fb53fd9009bee48fcdb53e.png)](../_images/congestion-rates-evolution.png)'
- en: Fig. 214 Evolution of the transmission rates[#](#fig-congestion-rates "Link
    to this image")
  id: totrans-724
  prefs: []
  type: TYPE_NORMAL
  zh: 图 214 传输速率的演变[#](#fig-congestion-rates "链接到这张图片")
- en: Various types of rate adaption algorithms are possible. [Dah Ming Chiu](https://home.ie.cuhk.edu.hk/~dmchiu/)
    and [Raj Jain](https://www.cse.wustl.edu/~jain/) have analyzed, in [[CJ1989]](../bibliography.html#cj1989),
    different types of algorithms that can be used by a source to adapt its transmission
    rate to the feedback received from the network. Intuitively, such a rate adaptation
    algorithm increases the transmission rate when the network is not congested (ensure
    that the network is efficiently used) and decrease the transmission rate when
    the network is congested (to avoid congestion collapse).
  id: totrans-725
  prefs: []
  type: TYPE_NORMAL
  zh: 可能存在各种类型的速率调整算法。Dah Ming Chiu 和 Raj Jain 在 [[CJ1989]](../bibliography.html#cj1989)
    中分析了不同类型的算法，这些算法可以由源端使用来调整其传输速率以适应从网络收到的反馈。直观上，这种速率调整算法在网络不拥塞时增加传输速率（确保网络被有效使用），在网络拥塞时降低传输速率（以避免拥塞崩溃）。
- en: 'The simplest form of feedback that the network can send to a source is a binary
    feedback (the network is congested or not congested). In this case, a linear rate
    adaptation algorithm can be expressed as :'
  id: totrans-726
  prefs: []
  type: TYPE_NORMAL
  zh: 网络可以向源发送的最简单形式的反馈是二进制反馈（网络是否拥塞）。在这种情况下，一个线性速率自适应算法可以表示为：
- en: \(rate(t+1)=\alpha_C + \beta_C rate(t)\) when the network is congested
  id: totrans-727
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当网络拥塞时，\(rate(t+1)=\alpha_C + \beta_C rate(t)\)
- en: ''
  id: totrans-728
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-729
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: \(rate(t+1)=\alpha_N + \beta_N rate(t)\) when the network is *not* congested
  id: totrans-730
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当网络**不**拥塞时，\(rate(t+1)=\alpha_N + \beta_N rate(t)\)
- en: With a linear adaption algorithm, \(\alpha_C,\alpha_N, \beta_C\) and \(\beta_N\)
    are constants. The analysis of [[CJ1989]](../bibliography.html#cj1989) shows that
    to be fair and efficient, such a binary rate adaption mechanism must rely on Additive
    Increase and Multiplicative Decrease. When the network is not congested, the hosts
    should slowly increase their transmission rate (\(\beta_N=1~and~\alpha_N>0\)).
    When the network is congested, the hosts must multiplicatively decrease their
    transmission rate (\(\beta_C < 1~and~\alpha_C = 0\)). Such an AIMD rate adaptation
    algorithm can be implemented by the pseudo-code below.
  id: totrans-731
  prefs: []
  type: TYPE_NORMAL
  zh: 在线性自适应算法中，\(\alpha_C,\alpha_N, \beta_C\) 和 \(\beta_N\) 是常数。[[CJ1989]](../bibliography.html#cj1989)
    的分析表明，为了公平和高效，这种二进制速率自适应机制必须依赖于加性增加和乘性减少。当网络不拥塞时，主机应缓慢增加它们的传输速率（\(\beta_N=1~and~\alpha_N>0\)）。当网络拥塞时，主机必须乘性减少它们的传输速率（\(\beta_C
    < 1~and~\alpha_C = 0\)）。这样的 AIMD 速率自适应算法可以通过以下伪代码实现。
- en: '[PRE20]'
  id: totrans-732
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Note
  id: totrans-733
  prefs: []
  type: TYPE_NORMAL
  zh: 备注
- en: Which binary feedback ?
  id: totrans-734
  prefs: []
  type: TYPE_NORMAL
  zh: 哪种二进制反馈？
- en: Two types of binary feedback are possible in computer networks. A first solution
    is to rely on implicit feedback. This is the solution chosen for TCP. TCP’s congestion
    control scheme [[Jacobson1988]](../bibliography.html#jacobson1988) does not require
    any cooperation from the router. It only assumes that they use buffers and that
    they discard packets when there is congestion. TCP uses the segment losses as
    an indication of congestion. When there are no losses, the network is assumed
    to be not congested. This implies that congestion is the main cause of packet
    losses. This is true in wired networks, but unfortunately not always true in wireless
    networks. Another solution is to rely on explicit feedback. This is the solution
    proposed in the DECBit congestion control scheme [[RJ1995]](../bibliography.html#rj1995)
    and used in Frame Relay and ATM networks. This explicit feedback can be implemented
    in two ways. A first solution would be to define a special message that could
    be sent by routers to hosts when they are congested. Unfortunately, generating
    such messages may increase the amount of congestion in the network. Such a congestion
    indication packet is thus discouraged [**RFC 1812**](https://datatracker.ietf.org/doc/html/rfc1812.html).
    A better approach is to allow the intermediate routers to indicate, in the packets
    that they forward, their current congestion status. Binary feedback can be encoded
    by using one bit in the packet header. With such a scheme, congested routers set
    a special bit in the packets that they forward while non-congested routers leave
    this bit unmodified. The destination host returns the congestion status of the
    network in the acknowledgments that it sends. Details about such a solution in
    IP networks may be found in [**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html).
    Unfortunately, as of this writing, this solution is still not deployed despite
    its potential benefits.
  id: totrans-735
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机网络中可能存在两种类型的二进制反馈。第一种解决方案是依赖于隐式反馈。这是 TCP 所选择的解决方案。TCP 的拥塞控制方案 [[Jacobson1988]](../bibliography.html#jacobson1988)
    不需要来自路由器的任何合作。它只假设它们使用缓冲区，并在拥塞时丢弃数据包。TCP 使用段丢失作为拥塞的指示。当没有丢失时，网络被认为是未拥塞的。这意味着拥塞是数据包丢失的主要原因。这在有线网络中是正确的，但不幸的是，在无线网络中并不总是如此。另一种解决方案是依赖于显式反馈。这是
    DECBit 拥塞控制方案 [[RJ1995]](../bibliography.html#rj1995) 提出的解决方案，并在帧中继和 ATM 网络中使用。这种显式反馈可以通过两种方式实现。第一种解决方案是定义一种特殊消息，当路由器拥塞时可以发送给主机。不幸的是，生成此类消息可能会增加网络中的拥塞量。因此，这种拥塞指示数据包是不被鼓励的
    [**RFC 1812**](https://datatracker.ietf.org/doc/html/rfc1812.html)。更好的方法是允许中间路由器在它们转发的数据包中指示它们当前的拥塞状态。二进制反馈可以通过在数据包头部使用一个比特来编码。在这种方案中，拥塞路由器在它们转发的数据包中设置一个特殊的比特，而非拥塞路由器则不修改此比特。目标主机在其发送的确认中返回网络的拥塞状态。有关
    IP 网络中此类解决方案的详细信息，请参阅 [**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)。不幸的是，截至本文撰写时，尽管这种解决方案具有潜在的好处，但它仍未部署。
- en: Congestion control with a window-based transport protocol[#](#congestion-control-with-a-window-based-transport-protocol
    "Link to this heading")
  id: totrans-736
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于窗口的传输协议的拥塞控制[#](#congestion-control-with-a-window-based-transport-protocol
    "链接到本标题")
- en: AIMD controls congestion by adjusting the transmission rate of the sources in
    reaction to the current congestion level. If the network is not congested, the
    transmission rate increases. If congestion is detected, the transmission rate
    is multiplicatively decreased. In practice, directly adjusting the transmission
    rate can be difficult since it requires the utilization of fine grained timers.
    In reliable transport protocols, an alternative is to dynamically adjust the sending
    window. This is the solution chosen for protocols like TCP and SCTP that will
    be described in more details later. To understand how window-based protocols can
    adjust their transmission rate, let us consider the very simple scenario of a
    reliable transport protocol that uses go-back-n. Consider the very simple scenario
    shown in figure [Fig. 215](#fig-bottleneck).
  id: totrans-737
  prefs: []
  type: TYPE_NORMAL
  zh: AIMD通过根据当前拥塞水平调整源传输速率来控制拥塞。如果网络没有拥塞，传输速率会增加。如果检测到拥塞，传输速率会乘性减少。在实践中，直接调整传输速率可能很困难，因为它需要使用细粒度计时器。在可靠的传输协议中，一个替代方案是动态调整发送窗口。这是TCP和SCTP等协议所选择的解决方案，这些协议将在稍后更详细地描述。为了了解基于窗口的协议如何调整它们的传输速率，让我们考虑一个非常简单的可靠传输协议场景，该协议使用回退n。考虑图[图215](#fig-bottleneck)中显示的非常简单的场景。
- en: '![Figure made with TikZ](../Images/fba8d6b7380280ee70f3550fb599fb9f.png)'
  id: totrans-738
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用TikZ制作的图](../Images/fba8d6b7380280ee70f3550fb599fb9f.png)'
- en: ''
  id: totrans-739
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 215 A simple network with hosts sharing a bottleneck link
  id: totrans-740
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图215 一个简单的网络，主机共享一个瓶颈链路
- en: The links between the hosts and the routers have a bandwidth of 1 Mbps while
    the link between the two routers has a bandwidth of 500 Kbps. There is no significant
    propagation delay in this network. For simplicity, assume that hosts A and B send
    1000 bits packets. The transmission of such a packet on a host-router (resp. router-router
    ) link requires 1 msec (resp. 2 msec). If there is no traffic in the network,
    the round-trip-time measured by host A to reach D is slightly larger than 4 msec.
    Let us observe the flow of packets with different window sizes to understand the
    relationship between sending window and transmission rate.
  id: totrans-741
  prefs: []
  type: TYPE_NORMAL
  zh: 主机和路由器之间的链路带宽为1 Mbps，而两个路由器之间的链路带宽为500 Kbps。在这个网络中没有显著的传播延迟。为了简单起见，假设主机A和B发送1000比特的数据包。这样的数据包在主机-路由器（分别路由器-路由器）链路上的传输需要1毫秒（分别2毫秒）。如果没有网络流量，主机A测量到D的往返时间略大于4毫秒。让我们观察不同窗口大小的数据包流，以了解发送窗口和传输速率之间的关系。
- en: Consider first a window of one segment. This segment takes 4 msec to reach host
    D. The destination replies with an acknowledgment and the next segment can be
    transmitted. With such a sending window, the transmission rate is roughly 250
    segments per second or 250 Kbps. This is illustrated in figure [Fig. 216](#fig-gbn-win-1)
    where each square of the grid corresponds to one millisecond.
  id: totrans-742
  prefs: []
  type: TYPE_NORMAL
  zh: 首先考虑一个段的窗口。这个段需要4毫秒才能到达主机D。目的地用一个确认回复，然后可以传输下一个段。在这样的发送窗口下，传输速率大约是每秒250个段或250
    Kbps。这如图[图216](#fig-gbn-win-1)所示，其中网格的每个方格对应于一毫秒。
- en: '![Figure made with TikZ](../Images/fb17e125cf960286b8258b6251471572.png)'
  id: totrans-743
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用TikZ制作的图](../Images/fb17e125cf960286b8258b6251471572.png)'
- en: ''
  id: totrans-744
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 216 Go-back-n transfer from A to D, window of one segment
  id: totrans-745
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图216 从A到D的回退n传输，窗口为一个段
- en: Consider now a window of two segments. Host A can send two segments within 2
    msec on its 1 Mbps link. If the first segment is sent at time \(t_{0}\), it reaches
    host D at \(t_{0}+4\). Host D replies with an acknowledgment that opens the sending
    window on host A and enables it to transmit a new segment. In the meantime, the
    second segment was buffered by router R1. It reaches host D at \(t_{0}+6\) and
    an acknowledgment is returned. With a window of two segments, host A transmits
    at roughly 500 Kbps, i.e. the transmission rate of the bottleneck link.
  id: totrans-746
  prefs: []
  type: TYPE_NORMAL
  zh: 现在考虑一个由两个段组成的窗口。主机A可以在其1 Mbps链路上在2毫秒内发送两个段。如果第一个段在时间\(t_{0}\)发送，它将在\(t_{0}+4\)时到达主机D。主机D用一个确认回复，这个确认打开主机A的发送窗口并允许它传输一个新的段。与此同时，第二个段被路由器R1缓冲。它将在\(t_{0}+6\)时到达主机D，并返回一个确认。在两个段的窗口中，主机A以大约500
    Kbps的速度传输，即瓶颈链路的传输速率。
- en: '![Figure made with TikZ](../Images/972780cbffde5435003f04c4edfabc56.png)'
  id: totrans-747
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用TikZ制作的图](../Images/972780cbffde5435003f04c4edfabc56.png)'
- en: ''
  id: totrans-748
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 217 Go-back-n transfer from A to D, window of two segments
  id: totrans-749
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图217 从A到D的回退n传输，窗口为两个段
- en: Our last example is a window of four segments. These segments are sent at \(t_{0}\),
    \(t_{0}+1\), \(t_{0}+2\) and \(t_{0}+3\). The first segment reaches host D at
    \(t_{0}+4\). Host D replies to this segment by sending an acknowledgment that
    enables host A to transmit its fifth segment. This segment reaches router R1 at
    \(t_{0}+5\). At that time, router R1 is transmitting the third segment to router
    R2 and the fourth segment is still in its buffers. At time \(t_{0}+6\), host D
    receives the second segment and returns the corresponding acknowledgment. This
    acknowledgment enables host A to send its sixth segment. This segment reaches
    router R1 at roughly \(t_{0}+7\). At that time, the router starts to transmit
    the fourth segment to router R2. Since link R1-R2 can only sustain 500 Kbps, packets
    will accumulate in the buffers of R1. On average, there will be two packets waiting
    in the buffers of R1. The presence of these two packets will induce an increase
    of the round-trip-time as measured by the transport protocol. While the first
    segment was acknowledged within 4 msec, the fifth segment (data(4)) that was transmitted
    at time \(t_{0}+4\) is only acknowledged at time \(t_{0}+11\). On average, the
    sender transmits at 500 Kbps, but the utilization of a large window induces a
    longer delay through the network.
  id: totrans-750
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的最后一个例子是四个段的窗口。这些段在 \(t_{0}\)，\(t_{0}+1\)，\(t_{0}+2\) 和 \(t_{0}+3\) 时发送。第一个段在
    \(t_{0}+4\) 时到达主机 D。主机 D 通过发送一个确认来回复这个段，这个确认使得主机 A 能够发送它的第五个段。这个段在 \(t_{0}+5\)
    时到达路由器 R1。那时，路由器 R1 正在将第三个段传输到路由器 R2，第四个段仍然在其缓冲区中。在 \(t_{0}+6\) 时，主机 D 接收到第二个段并返回相应的确认。这个确认使得主机
    A 能够发送它的第六个段。这个段大约在 \(t_{0}+7\) 时到达路由器 R1。那时，路由器开始将第四个段传输到路由器 R2。由于 R1-R2 链路只能支持
    500 Kbps，数据包将积累在 R1 的缓冲区中。平均来说，将有两个数据包在 R1 的缓冲区中等待。这两个数据包的存在将导致传输协议测量的往返时间增加。虽然第一个段在
    4 毫秒内得到了确认，但 \(t_{0}+4\) 时发送的第五个段（数据(4)）直到 \(t_{0}+11\) 才得到确认。平均来说，发送者以 500 Kbps
    的速度发送数据，但大窗口的使用通过网络引入了更长的延迟。
- en: '![Figure made with TikZ](../Images/6fac88cb38e8b98800e49c18ffa34a0c.png)'
  id: totrans-751
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用 TikZ 制作的图](../Images/6fac88cb38e8b98800e49c18ffa34a0c.png)'
- en: ''
  id: totrans-752
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 218 Go-back-n transfer from A to D, window of four segments
  id: totrans-753
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图 218 从 A 到 D 的回退-n 传输，四个段的窗口
- en: From the above example, we can adjust the transmission rate by adjusting the
    sending window of a reliable transport protocol. A reliable transport protocol
    cannot send data faster than \(\frac{window}{rtt}\) segments per second where
    \(window\) is the current sending window. To control the transmission rate, we
    introduce a congestion window. This congestion window limits the sending window.
    At any time, the sending window is restricted to \(\min(swin,cwin)\), where swin
    is the sending window and cwin the current congestion window. Of course, the window
    is further constrained by the receive window advertised by the remote peer. With
    the utilization of a congestion window, a simple reliable transport protocol that
    uses fixed size segments could implement AIMD as follows.
  id: totrans-754
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面的例子中，我们可以通过调整可靠传输协议的发送窗口来调整传输速率。一个可靠的传输协议不能以每秒 \(\frac{window}{rtt}\) 个段的速度发送数据，其中
    \(window\) 是当前的发送窗口。为了控制传输速率，我们引入了一个拥塞窗口。这个拥塞窗口限制了发送窗口。在任何时候，发送窗口都被限制在 \(\min(swin,cwin)\)，其中
    swin 是发送窗口，cwin 是当前的拥塞窗口。当然，窗口还受到远程对端宣布的接收窗口的限制。通过使用拥塞窗口，一个使用固定大小段的简单可靠传输协议可以如下实现
    AIMD。
- en: For the Additive Increase part our simple protocol would simply increase its
    congestion window by one segment every round-trip-time. The Multiplicative Decrease
    part of AIMD could be implemented by halving the congestion window when congestion
    is detected. For simplicity, we assume that congestion is detected thanks to a
    binary feedback and that no segments are lost. We will discuss in more details
    how losses affect a real transport protocol like TCP in later sections.
  id: totrans-755
  prefs: []
  type: TYPE_NORMAL
  zh: 对于增量增加部分，我们的简单协议会在每个往返时间增加一个段。AIMD 的乘性减少部分可以通过检测到拥塞时将拥塞窗口减半来实现。为了简化，我们假设拥塞是通过二进制反馈检测到的，并且没有段丢失。我们将在后面的章节中更详细地讨论损失如何影响像
    TCP 这样的实际传输协议。
- en: A congestion control scheme for our simple transport protocol could be implemented
    as follows.
  id: totrans-756
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的简单传输协议，可以实施以下拥塞控制方案。
- en: '[PRE21]'
  id: totrans-757
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: In the above pseudocode, cwin contains the congestion window stored as a real
    number of segments. This congestion window is updated upon the arrival of each
    acknowledgment and when congestion is detected. For simplicity, we assume that
    cwin is stored as a floating point number but only full segments can be transmitted.
  id: totrans-758
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述伪代码中，cwin 包含存储为段的实际数值的拥塞窗口。在收到每个确认以及检测到拥塞时更新拥塞窗口。为了简单起见，我们假设 cwin 以浮点数存储，但只能传输完整的段。
- en: As an illustration, let us consider the network scenario above and assume that
    the router implements the DECBit binary feedback scheme [[RJ1995]](../bibliography.html#rj1995).
    This scheme uses a form of Forward Explicit Congestion Notification and a router
    marks the congestion bit in arriving packets when its buffer contains one or more
    packets. In figure [Fig. 219](#fig-gbn-decbit), we use a * to indicate a marked
    packet.
  id: totrans-759
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明，让我们考虑上述网络场景，并假设路由器实现了 DECBit 二进制反馈方案 [[RJ1995]](../bibliography.html#rj1995)。该方案使用一种前向显式拥塞通知，当路由器的缓冲区包含一个或多个数据包时，路由器会在到达的数据包中标记拥塞位。在图
    [图 219](#fig-gbn-decbit) 中，我们用 * 来表示标记的数据包。
- en: '![Figure made with TikZ](../Images/2b9761249f9ab8572a0fc4b3416b6752.png)'
  id: totrans-760
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用 TikZ 制作的可视化](../Images/2b9761249f9ab8572a0fc4b3416b6752.png)'
- en: ''
  id: totrans-761
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 219 Go-back-n transfer from A to D, with AIMD congestion control and DecBit
    binary feedback scheme
  id: totrans-762
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图 219 从 A 到 D 的 Go-back-n 传输，带有 AIMD 拥塞控制和 DecBit 二进制反馈方案
- en: When the connection starts, its congestion window is set to one segment. Segment
    S0 is sent an acknowledgment at roughly \(t_{0}+4\). The congestion window is
    increased by one segment and S1 and S2 are transmitted at time \(t_{0}+4\) and
    \(t_{0}+5\). The corresponding acknowledgments are received at times \(t_{0}+8\)
    and \(t_{0}+10\). Upon reception of this last acknowledgment, the congestion window
    reaches 3 and segments can be sent (S4 and S5). When segment S6 reaches router
    R1, its buffers already contain S5. The packet containing S6 is thus marked to
    inform the sender of the congestion. Note that the sender will only notice the
    congestion once it receives the corresponding acknowledgment at \(t_{0}+18\).
    In the meantime, the congestion window continues to increase. At \(t_{0}+16\),
    upon reception of the acknowledgment for S5, it reaches 4. When congestion is
    detected, the congestion window is decreased down to 2. This explains the idle
    time between the reception of the acknowledgment for S*6 and the transmission
    of S10.
  id: totrans-763
  prefs: []
  type: TYPE_NORMAL
  zh: 当连接开始时，其拥塞窗口被设置为一段。在约 \(t_{0}+4\) 时，向段 S0 发送一个确认。拥塞窗口增加一段，S1 和 S2 在 \(t_{0}+4\)
    和 \(t_{0}+5\) 时刻传输。相应的确认在 \(t_{0}+8\) 和 \(t_{0}+10\) 时刻收到。在收到最后一个确认后，拥塞窗口达到 3，可以发送段（S4
    和 S5）。当段 S6 到达路由器 R1 时，其缓冲区已包含 S5。因此，包含 S6 的数据包被标记以通知发送者拥塞情况。请注意，发送者只有在收到 \(t_{0}+18\)
    时刻的相应确认后才会注意到拥塞。在此期间，拥塞窗口继续增加。在 \(t_{0}+16\)，在收到 S5 的确认后，它达到 4。当检测到拥塞时，拥塞窗口减少到
    2。这解释了从收到 S*6 的确认到发送 S10 之间的空闲时间。
- en: In practice, a router is connected to multiple input links. Figure [Fig. 220](#fig-2hosts-bottleneck)
    shows an example with two hosts.
  id: totrans-764
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，路由器连接到多个输入链路。图 [图 220](#fig-2hosts-bottleneck) 展示了一个包含两个主机的示例。
- en: '![Figure made with TikZ](../Images/54044b2beb542c9ff304fe654e7cbe2e.png)'
  id: totrans-765
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用 TikZ 制作的可视化](../Images/54044b2beb542c9ff304fe654e7cbe2e.png)'
- en: ''
  id: totrans-766
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 220 A simple network with hosts sharing a bottleneck
  id: totrans-767
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图 220 具有主机共享瓶颈的简单网络
- en: ''
  id: totrans-768
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Figure made with TikZ](../Images/14805061572e2ea7a08e10338a022ff8.png)'
  id: totrans-769
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用 TikZ 制作的可视化](../Images/14805061572e2ea7a08e10338a022ff8.png)'
- en: ''
  id: totrans-770
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 221 Sharing the bottleneck link between different inputs
  id: totrans-771
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图 221 不同输入之间的瓶颈链路共享
- en: In general, the links have a non-zero delay. This is illustrated in the figure
    below where a delay has been added on the link between R and C.
  id: totrans-772
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，链路具有非零延迟。下面的图示中，在 R 和 C 之间的链路上添加了延迟。
- en: '![Figure made with TikZ](../Images/515eaae674689b5424d8fbcf3dfe9c0e.png)'
  id: totrans-773
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用 TikZ 制作的可视化](../Images/515eaae674689b5424d8fbcf3dfe9c0e.png)'
- en: ''
  id: totrans-774
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 222 Sharing the bottleneck link between different inputs
  id: totrans-775
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图 222 不同输入之间的瓶颈链路共享
- en: '### Congestion control[#](#tcpcongestion "Link to this heading")'
  id: totrans-776
  prefs: []
  type: TYPE_NORMAL
  zh: '### 拥塞控制[#](#tcpcongestion "链接到本标题")'
- en: In an internetwork, i.e. a networking composed of different types of networks
    (such as the Internet), congestion control could be implemented either in the
    network layer or the transport layer. The congestion problem was clearly identified
    in the later 1980s and the researchers who developed techniques to solve the problem
    opted for a solution in the transport layer. Adding congestion control to the
    transport layer makes sense since this layer provides a reliable data transfer
    and avoiding congestion is a factor in this reliable delivery. The transport layer
    already deals with heterogeneous networks thanks to its self-clocking property
    that we have already described. In this section, we explain how congestion control
    has been added to TCP and how this mechanism could be improved in the future.
  id: totrans-777
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个互联网中，即由不同类型的网络（如互联网）组成的网络，拥塞控制可以在网络层或传输层实现。拥塞问题在20世纪80年代后期被清楚地识别出来，开发了解决该问题技术的研究人员选择了传输层解决方案。在传输层添加拥塞控制是有意义的，因为这一层提供可靠的数据传输，避免拥塞是这种可靠交付的一个因素。由于我们已经描述的自时钟特性，传输层已经处理了异构网络。在本节中，我们解释了拥塞控制是如何添加到TCP的，以及这种机制如何在未来得到改进。
- en: The TCP congestion control scheme was initially proposed by [Van Jacobson](https://en.wikipedia.org/wiki/Van_Jacobson)
    in [[Jacobson1988]](../bibliography.html#jacobson1988). The current specification
    may be found in [**RFC 5681**](https://datatracker.ietf.org/doc/html/rfc5681.html).
    TCP relies on Additive Increase and Multiplicative Decrease (AIMD). To implement
    [AIMD](../glossary.html#term-AIMD), a TCP host must be able to control its transmission
    rate. A first approach would be to use timers and adjust their expiration times
    in function of the rate imposed by [AIMD](../glossary.html#term-AIMD). Unfortunately,
    maintaining such timers for a large number of TCP connections can be difficult.
    Instead, [Van Jacobson](https://en.wikipedia.org/wiki/Van_Jacobson) noted that
    the rate of TCP congestion can be artificially controlled by constraining its
    sending window. A TCP connection cannot send data faster than \(\frac{window}{rtt}\)
    where \(window\) is the minimum between the host’s sending window and the window
    advertised by the receiver.
  id: totrans-778
  prefs: []
  type: TYPE_NORMAL
  zh: TCP拥塞控制方案最初由[Van Jacobson](https://en.wikipedia.org/wiki/Van_Jacobson)在[[Jacobson1988]](../bibliography.html#jacobson1988)中提出。当前规范可以在[**RFC
    5681**](https://datatracker.ietf.org/doc/html/rfc5681.html)中找到。TCP依赖于增量增加和乘性减少（AIMD）。为了实现[A
    IMD](../glossary.html#term-AIMD)，TCP主机必须能够控制其传输速率。一种方法是通过定时器并调整它们的过期时间，以适应[A IMD](../glossary.html#term-AIMD)施加的速率。不幸的是，维护大量TCP连接的此类定时器可能很困难。相反，[Van
    Jacobson](https://en.wikipedia.org/wiki/Van_Jacobson)指出，可以通过限制其发送窗口来人为地控制TCP拥塞的速率。TCP连接的发送速率不能超过\(\frac{window}{rtt}\)，其中\(window\)是主机发送窗口和接收者广告窗口之间的最小值。
- en: TCP’s congestion control scheme is based on a congestion window. The current
    value of the congestion window (cwnd) is stored in the TCB of each TCP connection
    and the window that can be used by the sender is constrained by \(\min(cwnd,rwin,swin)\)
    where \(swin\) is the current sending window and \(rwin\) the last received receive
    window. The Additive Increase part of the TCP congestion control increments the
    congestion window by [MSS](../glossary.html#term-MSS) bytes every round-trip-time.
    In the TCP literature, this phase is often called the congestion avoidance phase.
    The Multiplicative Decrease part of the TCP congestion control divides the current
    value of the congestion window once congestion has been detected.
  id: totrans-779
  prefs: []
  type: TYPE_NORMAL
  zh: TCP的拥塞控制方案基于一个拥塞窗口。拥塞窗口（cwnd）的当前值存储在每个TCP连接的TCB中，发送者可以使用的窗口由\(\min(cwnd,rwin,swin)\)约束，其中\(swin\)是当前发送窗口，\(rwin\)是最后接收到的接收窗口。TCP拥塞控制的增量增加部分在每个往返时间通过[MSS](../glossary.html#term-MSS)字节增加拥塞窗口。在TCP文献中，这个阶段通常被称为拥塞避免阶段。TCP拥塞控制的乘性减少部分在检测到拥塞后，将当前拥塞窗口的值除以一次。
- en: 'When a TCP connection begins, the sending host does not know whether the part
    of the network that it uses to reach the destination is congested or not. To avoid
    causing too much congestion, it must start with a small congestion window. [[Jacobson1988]](../bibliography.html#jacobson1988)
    recommends an initial window of MSS bytes. As the additive increase part of the
    TCP congestion control scheme increments the congestion window by MSS bytes every
    round-trip-time, the TCP connection may have to wait many round-trip-times before
    being able to efficiently use the available bandwidth. This is especially important
    in environments where the \(bandwidth \times rtt\) product is high. To avoid waiting
    too many round-trip-times before reaching a congestion window that is large enough
    to efficiently utilize the network, the TCP congestion control scheme includes
    the slow-start algorithm. The objective of the TCP slow-start phase is to quickly
    reach an acceptable value for the cwnd. During slow-start, the congestion window
    is doubled every round-trip-time. The slow-start algorithm uses an additional
    variable in the TCB : ssthresh (slow-start threshold). The ssthresh is an estimation
    of the last value of the cwnd that did not cause congestion. It is initialized
    at the sending window and is updated after each congestion event.'
  id: totrans-780
  prefs: []
  type: TYPE_NORMAL
  zh: 当TCP连接开始时，发送主机不知道它用来到达目的地的网络部分是否拥塞。为了避免造成过多的拥塞，它必须从一个小的拥塞窗口开始。[[Jacobson1988]](../bibliography.html#jacobson1988)建议初始窗口为MSS字节。由于TCP拥塞控制方案的累加增加部分在每个往返时间增加MSS字节，TCP连接可能需要等待多个往返时间才能有效地使用可用带宽。这在带宽乘以往返时间（\(bandwidth
    \times rtt\)）乘积较高的环境中尤为重要。为了避免在达到足够大的拥塞窗口以有效地利用网络之前等待过多的往返时间，TCP拥塞控制方案包括慢启动算法。TCP慢启动阶段的目标是快速达到cwnd的可接受值。在慢启动期间，拥塞窗口在每个往返时间翻倍。慢启动算法在TCB中使用了一个额外的变量：ssthresh（慢启动阈值）。ssthresh是对未引起拥塞的cwnd最后值的估计。它初始化为发送窗口，并在每次拥塞事件后更新。
- en: 'A key question that must be answered by any congestion control scheme is how
    congestion is detected. The first implementations of the TCP congestion control
    scheme opted for a simple and pragmatic approach : packet losses indicate congestion.
    If the network is congested, router buffers are full and packets are discarded.
    In wired networks, packet losses are mainly caused by congestion. In wireless
    networks, packets can be lost due to transmission errors and for other reasons
    that are independent of congestion. TCP already detects segment losses to ensure
    a reliable delivery. The TCP congestion control scheme distinguishes between two
    types of congestion :'
  id: totrans-781
  prefs: []
  type: TYPE_NORMAL
  zh: 任何拥塞控制方案都必须回答的一个关键问题是如何检测拥塞。TCP拥塞控制方案的第一种实现选择了简单而实用的方法：数据包丢失表示拥塞。如果网络拥塞，路由器缓冲区将满，数据包将被丢弃。在有线网络中，数据包丢失主要是由拥塞引起的。在无线网络中，数据包可能由于传输错误或其他与拥塞无关的原因而丢失。TCP已经检测到数据段丢失以确保可靠传输。TCP拥塞控制方案区分了两种类型的拥塞：
- en: mild congestion. TCP considers that the network is lightly congested if it receives
    three duplicate acknowledgments and performs a fast retransmit. If the fast retransmit
    is successful, this implies that only one segment has been lost. In this case,
    TCP performs multiplicative decrease and the congestion window is divided by 2.
    The slow-start threshold is set to the new value of the congestion window.
  id: totrans-782
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 轻度拥塞。如果TCP收到三个重复的确认并执行快速重传，TCP认为网络轻度拥塞。如果快速重传成功，这意味着只有一个数据段丢失。在这种情况下，TCP执行乘性减少，并将拥塞窗口除以2。慢启动阈值设置为新的拥塞窗口值。
- en: ''
  id: totrans-783
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-784
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: severe congestion. TCP considers that the network is severely congested when
    its retransmission timer expires. In this case, TCP retransmits the first segment,
    sets the slow-start threshold to 50% of the congestion window. The congestion
    window is reset to its initial value and TCP performs a slow-start.
  id: totrans-785
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 严重拥塞。当TCP的重传计时器超时时，TCP认为网络严重拥塞。在这种情况下，TCP会重传第一个数据段，将慢启动阈值设置为拥塞窗口的50%。拥塞窗口重置为其初始值，TCP执行慢启动。
- en: The figure below illustrates the evolution of the congestion window when there
    is severe congestion. At the beginning of the connection, the sender performs
    slow-start until the first segments are lost and the retransmission timer expires.
    At this time, the ssthresh is set to half of the current congestion window and
    the congestion window is reset at one segment. The lost segments are retransmitted
    as the sender again performs slow-start until the congestion window reaches the
    sshtresh. It then switches to congestion avoidance and the congestion window increases
    linearly until segments are lost and the retransmission timer expires.
  id: totrans-786
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了在严重拥塞情况下拥塞窗口的演变。在连接开始时，发送方执行慢启动，直到第一个数据包丢失并且重传计时器到期。此时，ssthresh 设置为当前拥塞窗口的一半，拥塞窗口重置为一个数据包。丢失的数据包被重传，发送方再次执行慢启动，直到拥塞窗口达到
    ssthresh。然后切换到拥塞避免，拥塞窗口线性增加，直到数据包丢失并且重传计时器到期。
- en: '[![../_images/tcp-congestion-severe.png](../Images/8bb9ad90fd07bc82d9cba2b40a1481a6.png)](../_images/tcp-congestion-severe.png)'
  id: totrans-787
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/tcp-congestion-severe.png](../Images/8bb9ad90fd07bc82d9cba2b40a1481a6.png)(../_images/tcp-congestion-severe.png)'
- en: Fig. 223 Evaluation of the TCP congestion window with severe congestion[#](#id109
    "Link to this image")
  id: totrans-788
  prefs: []
  type: TYPE_NORMAL
  zh: 图 223 严重拥塞下 TCP 拥塞窗口的评估[#](#id109 "链接到这张图片")
- en: The figure below illustrates the evolution of the congestion window when the
    network is lightly congested and all lost segments can be retransmitted using
    fast retransmit. The sender begins with a slow-start. A segment is lost but successfully
    retransmitted by a fast retransmit. The congestion window is divided by 2 and
    the sender immediately enters congestion avoidance as this was a mild congestion.
  id: totrans-789
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了在网络轻微拥塞且所有丢失的数据包都可以使用快速重传重新传输时，拥塞窗口的演变。发送方从慢启动开始。一个数据包丢失，但通过快速重传成功重传。由于这是轻微的拥塞，拥塞窗口减半，发送方立即进入拥塞避免状态。
- en: '[![../_images/tcp-congestion-mild.png](../Images/118024671401b1ade2c8daa21527e64f.png)](../_images/tcp-congestion-mild.png)'
  id: totrans-790
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/tcp-congestion-mild.png](../Images/118024671401b1ade2c8daa21527e64f.png)(../_images/tcp-congestion-mild.png)'
- en: Fig. 224 Evaluation of the TCP congestion window when the network is lightly
    congested[#](#id110 "Link to this image")
  id: totrans-791
  prefs: []
  type: TYPE_NORMAL
  zh: 图 224 轻微拥塞下 TCP 拥塞窗口的评估[#](#id110 "链接到这张图片")
- en: Most TCP implementations update the congestion window when they receive an acknowledgment.
    If we assume that the receiver acknowledges each received segment and the sender
    only sends MSS sized segments, the TCP congestion control scheme can be implemented
    using the simplified pseudo-code [[7]](#fwrap) below. This pseudocode includes
    the optimization proposed in [**RFC 3042**](https://datatracker.ietf.org/doc/html/rfc3042.html)
    that allows a sender to send new unsent data upon reception of the first or second
    duplicate acknowledgment. The reception of each of these acknowledgments indicates
    that one segment has left the network and thus additional data can be sent without
    causing more congestion. Note that the congestion window is *not* increased upon
    reception of these first duplicate acknowledgments.
  id: totrans-792
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数 TCP 实现会在收到确认时更新拥塞窗口。如果我们假设接收方确认每个接收到的数据包，并且发送方只发送 MSS 大小的数据包，则可以使用以下简化的伪代码
    [[7]](#fwrap) 实现 TCP 拥塞控制方案。此伪代码包括在 [**RFC 3042**](https://datatracker.ietf.org/doc/html/rfc3042.html)
    中提出的优化，允许发送方在收到第一个或第二个重复确认后发送新的未发送数据。接收这些确认中的每一个都表明一个数据包已经离开网络，因此可以发送更多数据而不会造成更多拥塞。请注意，在收到这些第一个重复确认时，拥塞窗口不会增加。
- en: '[PRE22]'
  id: totrans-793
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Furthermore when a TCP connection has been idle for more than its current retransmission
    timer, it should reset its congestion window to the congestion window size that
    it uses when the connection begins, as it no longer knows the current congestion
    state of the network.
  id: totrans-794
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，当 TCP 连接空闲时间超过其当前重传计时器时，它应将其拥塞窗口重置为连接开始时使用的拥塞窗口大小，因为它不再知道网络的当前拥塞状态。
- en: Note
  id: totrans-795
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Initial congestion window
  id: totrans-796
  prefs: []
  type: TYPE_NORMAL
  zh: 初始拥塞窗口
- en: The original TCP congestion control mechanism proposed in [[Jacobson1988]](../bibliography.html#jacobson1988)
    recommended that each TCP connection should begin by setting \(cwnd=MSS\). However,
    in today’s higher bandwidth networks, using such a small initial congestion window
    severely affects the performance for short TCP connections, such as those used
    by web servers. In 2002, [**RFC 3390**](https://datatracker.ietf.org/doc/html/rfc3390.html)
    allowed an initial congestion window of about 4 KBytes, which corresponds to 3
    segments in many environments. Recently, researchers from Google proposed to further
    increase the initial window up to 15 KBytes [[DRC+2010]](../bibliography.html#drc-2010).
    The measurements that they collected show that this increase would not significantly
    increase congestion but would significantly reduce the latency of short HTTP responses.
    Unsurprisingly, the chosen initial window corresponds to the average size of an
    HTTP response from a search engine. This proposed modification has been adopted
    in [**RFC 6928**](https://datatracker.ietf.org/doc/html/rfc6928.html) and TCP
    implementations support it.
  id: totrans-797
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [[Jacobson1988]](../bibliography.html#jacobson1988) 中提出的原始TCP拥塞控制机制建议每个TCP连接应从设置
    \(cwnd=MSS\) 开始。然而，在今天的宽带网络中，使用如此小的初始拥塞窗口严重影响了短TCP连接的性能，例如那些由Web服务器使用的连接。2002年，[**RFC
    3390**](https://datatracker.ietf.org/doc/html/rfc3390.html) 允许初始拥塞窗口约为4 KBytes，这在许多环境中对应于3个段。最近，谷歌的研究人员提出了将初始窗口进一步增加到15
    KBytes [[DRC+2010]](../bibliography.html#drc-2010)。他们收集的测量数据显示，这种增加不会显著增加拥塞，但会显著减少短HTTP响应的延迟。不出所料，所选的初始窗口对应于搜索引擎的HTTP响应的平均大小。这种提出的修改已在
    [**RFC 6928**](https://datatracker.ietf.org/doc/html/rfc6928.html) 中被采用，并且TCP实现支持它。
- en: Controlling congestion without losing data[#](#controlling-congestion-without-losing-data
    "Link to this heading")
  id: totrans-798
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 无数据丢失地控制拥塞[#](#controlling-congestion-without-losing-data "链接到这个标题")
- en: In today’s Internet, congestion is controlled by regularly sending packets at
    a higher rate than the network capacity. These packets fill the buffers of the
    routers and are eventually discarded. But shortly after, TCP senders retransmit
    packets containing exactly the same data. This is potentially a waste of resources
    since these successive retransmissions consume resources upstream of the router
    that discards the packets. Packet losses are not the only signal to detect congestion
    inside the network. An alternative is to allow routers to explicitly indicate
    their current level of congestion when forwarding packets. This approach was proposed
    in the late 1980s [[RJ1995]](../bibliography.html#rj1995) and used in some networks.
    Unfortunately, it took almost a decade before the Internet community agreed to
    consider this approach. In the mean time, a large number of TCP implementations
    and routers were deployed on the Internet.
  id: totrans-799
  prefs: []
  type: TYPE_NORMAL
  zh: 在今天的互联网中，通过定期以高于网络容量的速率发送数据包来控制拥塞。这些数据包填满了路由器的缓冲区，最终被丢弃。但不久之后，TCP发送者会重新发送包含完全相同数据的数据包。这可能导致资源的浪费，因为这些连续的重传消耗了丢弃数据包的路由器上游的资源。数据包丢失并不是检测网络内部拥塞的唯一信号。一种替代方案是允许路由器在转发数据包时明确地指示其当前的拥塞水平。这种方法在20世纪80年代末被提出
    [[RJ1995]](../bibliography.html#rj1995) 并在一些网络中使用。不幸的是，在互联网社区几乎经过十年才同意考虑这种方法。在此期间，大量的TCP实现和路由器被部署在互联网上。
- en: As explained earlier, Explicit Congestion Notification [**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)
    improves the detection of congestion by allowing routers to explicitly mark packets
    when they are lightly congested. In theory, a single bit in the packet header
    [[RJ1995]](../bibliography.html#rj1995) is sufficient to support this congestion
    control scheme. When a host receives a marked packet, it returns the congestion
    information to the source that adapts its transmission rate accordingly. Although
    the idea is relatively simple, deploying it on the entire Internet has proven
    to be challenging [[KNT2013]](../bibliography.html#knt2013). It is interesting
    to analyze the different factors that have hindered the deployment of this technique.
  id: totrans-800
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，显式拥塞通知 [**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)
    通过允许路由器在轻微拥塞时明确标记数据包来提高拥塞检测。理论上，数据包头部的一个比特 [[RJ1995]](../bibliography.html#rj1995)
    就足以支持这种拥塞控制方案。当一个主机收到标记的数据包时，它会将拥塞信息返回给源主机，源主机据此调整其传输速率。尽管这个想法相对简单，但在整个互联网上部署它已被证明是具有挑战性的
    [[KNT2013]](../bibliography.html#knt2013)。分析阻碍这种技术部署的不同因素是很有趣的。
- en: The first difficulty in adding Explicit Congestion Notification (ECN) in TCP/IP
    network was to modify the format of the network packet and transport segment headers
    to carry the required information. In the network layer, one bit was required
    to allow the routers to mark the packets they forward during congestion periods.
    In the IP network layer, this bit is called the Congestion Experienced (CE) bit
    and is part of the packet header. However, using a single bit to mark packets
    is not sufficient. Consider a simple scenario with two sources, one congested
    router and one destination. Assume that the first sender and the destination support
    ECN, but not the second sender. If the router is congested it will mark packets
    from both senders. The first sender will react to the packet markings by reducing
    its transmission rate. However since the second sender does not support ECN, it
    will not react to the markings. Furthermore, this sender could continue to increase
    its transmission rate, which would lead to more packets being marked and the first
    source would decrease again its transmission rate, … In the end, the sources that
    implement ECN are penalized compared to the sources that do not implement it.
    This unfairness issue is a major hurdle to widely deploy ECN on the public Internet
    [[8]](#fprivate). The solution proposed in [**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)
    to deal with this problem is to use a second bit in the network packet header.
    This bit, called the ECN-capable transport (ECT) bit, indicates whether the packet
    contains a segment produced by a transport protocol that supports ECN or not.
    Transport protocols that support ECN set the ECT bit in all packets. When a router
    is congested, it first verifies whether the ECT bit is set. In this case, the
    CE bit of the packet is set to indicate congestion. Otherwise, the packet is discarded.
    This eases the deployment of ECN [[9]](#fecnnonce).
  id: totrans-801
  prefs: []
  type: TYPE_NORMAL
  zh: 在TCP/IP网络中添加显式拥塞通知（ECN）的第一个困难是修改网络数据包和传输段头的格式，以便携带所需的信息。在网络层，需要一个比特位来允许路由器在拥塞期间标记它们转发的数据包。在IP网络层，这个比特位被称为拥塞经历（CE）比特位，是数据包头部的一部分。然而，使用单个比特位来标记数据包是不够的。考虑一个有两个源、一个拥塞路由器和目标节点的简单场景。假设第一个发送器和目标节点支持ECN，而第二个发送器不支持。如果路由器拥塞，它将标记来自两个发送器的数据包。第一个发送器将通过降低其传输速率来对数据包标记做出反应。然而，由于第二个发送器不支持ECN，它不会对标记做出反应。此外，这个发送器可能会继续增加其传输速率，这将导致更多数据包被标记，而第一个源节点将再次降低其传输速率，……最终，实施ECN的源节点与未实施ECN的源节点相比会受到惩罚。这种不公平问题是在公共互联网上广泛部署ECN的主要障碍
    [[8]](#fprivate)。在[**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)中提出的解决这个问题的方案是在网络数据包头部使用第二个比特位。这个比特位被称为ECN能力传输（ECT）比特位，它指示数据包是否包含由支持ECN的传输协议产生的段。支持ECN的传输协议在所有数据包中设置ECT比特位。当路由器拥塞时，它首先验证ECT比特位是否被设置。在这种情况下，数据包的CE比特位被设置为指示拥塞。否则，数据包将被丢弃。这简化了ECN的部署
    [[9]](#fecnnonce)。
- en: 'The second difficulty is how to allow the receiver to inform the sender of
    the reception of network packets marked with the CE bit. In reliable transport
    protocols like TCP and SCTP, the acknowledgments can be used to provide this feedback.
    For TCP, two options were possible : change some bits in the TCP segment header
    or define a new TCP option to carry this information. The designers of ECN opted
    for reusing spare bits in the TCP header. More precisely, two TCP flags have been
    added in the TCP header to support ECN. The ECN-Echo (ECE) is set in the acknowledgments
    when the CE was set in packets received on the forward path.'
  id: totrans-802
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个困难是如何让接收器通知发送器接收了带有CE比特位标记的网络数据包。在TCP和SCTP等可靠传输协议中，可以通过确认来提供这种反馈。对于TCP，有两种可能的选择：更改TCP段头中的某些比特位或定义一个新的TCP选项来携带此信息。ECN的设计者选择了重用TCP头部的空闲比特位。更确切地说，在TCP头部中增加了两个标志来支持ECN。当接收到的数据包上的CE被设置时，ECN回声（ECE）在确认中设置。
- en: '[![../_images/tcp-enc.svg](../Images/0b92b95f1c0dadde63905a28574e87cb.png)](../_images/tcp-enc.svg)'
  id: totrans-803
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/tcp-enc.svg](../Images/0b92b95f1c0dadde63905a28574e87cb.png)(../_images/tcp-enc.svg)'
- en: Fig. 225 The TCP flags[#](#id111 "Link to this image")
  id: totrans-804
  prefs: []
  type: TYPE_NORMAL
  zh: 图225 TCP标志[#](#id111 "链接到这张图片")
- en: The third difficulty is to allow an ECN-capable sender to detect whether the
    remote host also supports ECN. This is a classical negotiation of extensions to
    a transport protocol. In TCP, this could have been solved by defining a new TCP
    option used during the three-way handshake. To avoid wasting space in the TCP
    options, the designers of ECN opted in [**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)
    for using the ECN-Echo and CWR bits in the TCP header to perform this negotiation.
    In the end, the result is the same with fewer bits exchanged.
  id: totrans-805
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个困难是允许一个支持 ECN 的发送者检测远程主机是否也支持 ECN。这是一个经典的传输协议扩展的协商。在 TCP 中，这可以通过在三次握手期间定义一个新的
    TCP 选项来解决。为了避免在 TCP 选项中浪费空间，ECN 的设计者在 [**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)
    中选择了使用 TCP 头部的 ECN-Echo 和 CWR 位来进行这种协商。最终，结果是相同的，但交换的位数更少。
- en: Thanks to the ECT, CE and ECE, routers can mark packets during congestion and
    receivers can return the congestion information back to the TCP senders. However,
    these three bits are not sufficient to allow a server to reliably send the ECE
    bit to a TCP sender. TCP acknowledgments are not sent reliably. A TCP acknowledgment
    always contains the next expected sequence number. Since TCP acknowledgments are
    cumulative, the loss of one acknowledgment is recovered by the correct reception
    of a subsequent acknowledgment.
  id: totrans-806
  prefs: []
  type: TYPE_NORMAL
  zh: 多亏了 ECT、CE 和 ECE，路由器可以在拥塞期间标记数据包，接收器可以将拥塞信息返回给 TCP 发送者。然而，这三个位不足以允许服务器可靠地将 ECE
    位发送给 TCP 发送者。TCP 确认不是可靠发送的。TCP 确认总是包含下一个期望的序列号。由于 TCP 确认是累积的，一个确认的丢失可以通过后续正确接收的确认来恢复。
- en: If TCP acknowledgments are overloaded to carry the ECE bit, the situation is
    different. Consider the example shown in the figure below. A client sends packets
    to a server through a router. In the example below, the first packet is marked.
    The server returns an acknowledgment with the ECE bit set. Unfortunately, this
    acknowledgment is lost and never reaches the client. Shortly after, the server
    sends a data segment that also carries a cumulative acknowledgment. This acknowledgment
    confirms the reception of the data to the client, but it did not receive the congestion
    information through the ECE bit.
  id: totrans-807
  prefs: []
  type: TYPE_NORMAL
  zh: 如果将 TCP 确认过载用于携带 ECE 位，情况就不同了。考虑下面图中的示例。一个客户端通过路由器向服务器发送数据包。在下面的示例中，第一个数据包被标记。服务器返回一个设置了
    ECE 位的确认。不幸的是，这个确认丢失了，并且从未到达客户端。不久之后，服务器发送了一个也携带累积确认的数据段。这个确认确认了数据已到达客户端，但它没有通过
    ECE 位收到拥塞信息。
- en: '![msc {'
  id: totrans-808
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![msc {'
- en: client [label="client", linecolour=black],
  id: totrans-809
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 客户端 [label="客户端", linecolour=black],
- en: router [label="router", linecolour=black],
  id: totrans-810
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 路由器 [label="路由器", linecolour=black],
- en: server [label="server", linecolour=black];
  id: totrans-811
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 服务器 [label="服务器", linecolour=black];
- en: ''
  id: totrans-812
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: client=>router [ label = "data[seq=1,ECT=1,CE=0]", arcskip="1" ];
  id: totrans-813
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 客户端=>路由器 [ label = "data[seq=1,ECT=1,CE=0]", arcskip="1" ];
- en: router=>server [ label = "data[seq=1,ECT=1,CE=1]", arcskip="1"];
  id: totrans-814
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 路由器=>服务器 [ label = "data[seq=1,ECT=1,CE=1]", arcskip="1"];
- en: '|||;'
  id: totrans-815
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '|||;'
- en: server=>router [ label = "ack=2,ECE=1", arcskip="1" ];
  id: totrans-816
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 服务器=>路由器 [ label = "ack=2,ECE=1", arcskip="1" ];
- en: router -x client [label="ack=2,ECE=1", arcskip="1" ];
  id: totrans-817
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 路由器 -x 客户端 [label="ack=2,ECE=1", arcskip="1" ];
- en: '|||;'
  id: totrans-818
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '|||;'
- en: server=>router [ label = "data[seq=x,ack=2,ECE=0,ECT=1,CE=0]", arcskip="1" ];
  id: totrans-819
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 服务器=>路由器 [ label = "data[seq=x,ack=2,ECE=0,ECT=1,CE=0]", arcskip="1" ];
- en: router=>client [ label = "data[seq=x,ack=2,ECE=0,ECT=1,CE=0]", arcskip="1"];
  id: totrans-820
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 路由器=>客户端 [ label = "data[seq=x,ack=2,ECE=0,ECT=1,CE=0]", arcskip="1"];
- en: '|||;'
  id: totrans-821
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '|||;'
- en: client->server [linecolour=white];
  id: totrans-822
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 客户端->服务器 [linecolour=white];
- en: '}](../Images/d2ed1589241adeb9e699082587d1916d.png)<map id="700c52eed1dd99ea5abd5216ffd2e044e6fee931"
    name="700c52eed1dd99ea5abd5216ffd2e044e6fee931"></map>'
  id: totrans-823
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '}](../Images/d2ed1589241adeb9e699082587d1916d.png)<map id="700c52eed1dd99ea5abd5216ffd2e044e6fee931"
    name="700c52eed1dd99ea5abd5216ffd2e044e6fee931"></map>'
- en: 'To solve this problem, [**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)
    uses an additional bit in the TCP header : the Congestion Window Reduced (CWR)
    bit.'
  id: totrans-824
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，[**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)
    在 TCP 头部使用了一个额外的位：拥塞窗口减少 (CWR) 位。
- en: '![msc {'
  id: totrans-825
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![msc {'
- en: client [label="client", linecolour=black],
  id: totrans-826
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 客户端 [label="客户端", linecolour=black],
- en: router [label="router", linecolour=black],
  id: totrans-827
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 路由器 [label="路由器", linecolour=black],
- en: server [label="server", linecolour=black];
  id: totrans-828
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 服务器 [label="服务器", linecolour=black];
- en: client=>router [ label = "data[seq=1,ECT=1,CE=0]", arcskip="1" ];
  id: totrans-829
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 客户端=>路由器 [ label = "data[seq=1,ECT=1,CE=0]", arcskip="1" ];
- en: router=>server [ label = "data[seq=1,ECT=1,CE=1]", arcskip="1"];
  id: totrans-830
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 路由器=>服务器 [ label = "data[seq=1,ECT=1,CE=1]", arcskip="1"];
- en: '|||;'
  id: totrans-831
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '|||;'
- en: server=>router [ label = "ack=2,ECE=1", arcskip="1" ];
  id: totrans-832
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 服务器=>路由器 [ label = "ack=2,ECE=1", arcskip="1" ];
- en: router -x client [label="ack=2,ECE=1", arcskip="1" ];
  id: totrans-833
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 路由器 -x 客户端 [label="ack=2,ECE=1", arcskip="1" ];
- en: '|||;'
  id: totrans-834
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '|||;'
- en: server=>router [ label = "data[seq=x,ack=2,ECE=1,ECT=1,CE=0]", arcskip="1" ];
  id: totrans-835
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 服务器=>路由器 [ label = "data[seq=x,ack=2,ECE=1,ECT=1,CE=0]", arcskip="1" ];
- en: router=>client [ label = "data[seq=x,ack=2,ECE=1,ECT=1,CE=0]", arcskip="1"];
  id: totrans-836
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 路由器=>客户端 [ label = "data[seq=x,ack=2,ECE=1,ECT=1,CE=0]", arcskip="1"];
- en: '|||;'
  id: totrans-837
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '|||;'
- en: client=>router [ label = "data[seq=1,ECT=1,CE=0,CWR=1]", arcskip="1" ];
  id: totrans-838
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 客户端=>路由器 [ label = "data[seq=1,ECT=1,CE=0,CWR=1]", arcskip="1" ];
- en: router=>server [ label = "data[seq=1,ECT=1,CE=1,CWR=1]", arcskip="1"];
  id: totrans-839
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 路由器=>服务器 [ label = "data[seq=1,ECT=1,CE=1,CWR=1]", arcskip="1"];
- en: '|||;'
  id: totrans-840
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '|||;'
- en: client->server [linecolour=white];
  id: totrans-841
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 客户端->服务器 [linecolour=white];
- en: '}](../Images/36533b7c4d47ba50cac29ebf6ebcc1f1.png)<map id="d60c580a7379dbdd26f90fd2eead54f832ee6ad6"
    name="d60c580a7379dbdd26f90fd2eead54f832ee6ad6"></map>'
  id: totrans-842
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '}](../Images/36533b7c4d47ba50cac29ebf6ebcc1f1.png)<map id="d60c580a7379dbdd26f90fd2eead54f832ee6ad6"
    name="d60c580a7379dbdd26f90fd2eead54f832ee6ad6"></map>'
- en: The CWR bit of the TCP header provides some form of acknowledgment for the ECE
    bit. When a TCP receiver detects a packet marked with the CE bit, it sets the
    ECE bit in all segments that it returns to the sender. Upon reception of an acknowledgment
    with the ECE bit set, the sender reduces its congestion window to reflect a mild
    congestion and sets the CWR bit. This bit remains set as long as the segments
    received contained the ECE bit set. A sender should only react once per round-trip-time
    to marked packets.
  id: totrans-843
  prefs: []
  type: TYPE_NORMAL
  zh: TCP头部的CWR位为ECE位提供了一种确认形式。当TCP接收方检测到一个标记了CE位的包时，它会将其返回给发送方的所有段中的ECE位设置为1。在收到设置了ECE位的确认后，发送方将其拥塞窗口减少以反映轻微的拥塞，并设置CWR位。只要接收到的段包含设置了ECE位的位，该位就会保持设置状态。发送方应该只在往返时间内对标记的包做出一次反应。
- en: 'The last point that needs to be discussed about Explicit Congestion Notification
    is the algorithm that is used by routers to detect congestion. On a router, congestion
    manifests itself by the number of packets that are stored inside the router buffers.
    As explained earlier, we need to distinguish between two types of routers :'
  id: totrans-844
  prefs: []
  type: TYPE_NORMAL
  zh: 关于显式拥塞通知需要讨论的最后一个问题是路由器用来检测拥塞的算法。在路由器上，拥塞通过路由器缓冲区中存储的数据包数量来体现。正如之前所解释的，我们需要区分两种类型的路由器：
- en: routers that have a single FIFO queue
  id: totrans-845
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拥有一个单独FIFO队列的路由器
- en: ''
  id: totrans-846
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-847
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: routers that have several queues served by a round-robin scheduler
  id: totrans-848
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由轮询调度器服务多个队列的路由器
- en: Routers that use a single queue measure their buffer occupancy as the number
    of bytes of packets stored in the queue [[10]](#fslot). A first method to detect
    congestion is to measure the instantaneous buffer occupancy and consider the router
    to be congested as soon as this occupancy is above a threshold. Typical values
    of the threshold could be 40% of the total buffer. Measuring the instantaneous
    buffer occupancy is simple since it only requires one counter. However, this value
    is fragile from a control viewpoint since it changes frequently. A better solution
    is to measure the *average* buffer occupancy and consider the router to be congested
    when this average occupancy is too high. Random Early Detection (RED) [[FJ1993]](../bibliography.html#fj1993)
    is an algorithm that was designed to support Explicit Congestion Notification.
    In addition to measuring the average buffer occupancy, it also uses probabilistic
    marking. When the router is congested, the arriving packets are marked with a
    probability that increases with the average buffer occupancy. The main advantage
    of using probabilistic marking instead of marking all arriving packets is that
    flows will be marked in proportion of the number of packets that they transmit.
    If the router marks 10% of the arriving packets when congested, then a large flow
    that sends hundred packets per second will be marked 10 times while a flow that
    only sends one packet per second will not be marked. This probabilistic marking
    allows marking packets in proportion of their usage of the network resources.
  id: totrans-849
  prefs: []
  type: TYPE_NORMAL
  zh: 使用单个队列的路由器将它们的缓冲区占用量测量为队列中存储的数据包字节数 [[10]](#fslot)。检测拥塞的第一个方法是通过测量瞬时缓冲区占用率，一旦这个占用率超过一个阈值，就认为路由器处于拥塞状态。阈值的典型值可能是总缓冲区的40%。测量瞬时缓冲区占用率很简单，因为它只需要一个计数器。然而，从控制角度来看，这个值是脆弱的，因为它会频繁变化。一个更好的解决方案是测量*平均*缓冲区占用率，并在这个平均占用率过高时认为路由器处于拥塞状态。随机早期检测（RED）[[FJ1993]](../bibliography.html#fj1993)
    是一个旨在支持显式拥塞通知的算法。除了测量平均缓冲区占用率外，它还使用概率标记。当路由器拥塞时，到达的数据包会以随平均缓冲区占用率增加的概率被标记。使用概率标记而不是标记所有到达数据包的主要优点是，流量将被按它们传输的数据包数量成比例地标记。如果路由器在拥塞时标记了10%的到达数据包，那么每秒发送一百个数据包的大流量将被标记10次，而每秒只发送一个数据包的流量则不会被标记。这种概率标记允许按数据包对网络资源的使用比例进行标记。
- en: If the router uses several queues served by a scheduler, the situation is different.
    If a large and a small flow are competing for bandwidth, the scheduler will already
    favor the small flow that is not using its fair share of the bandwidth. The queue
    for the small flow will be almost empty while the queue for the large flow will
    build up. On routers using such schedulers, a good way of marking the packets
    is to set a threshold on the occupancy of each queue and mark the packets that
    arrive in a particular queue as soon as its occupancy is above the configured
    threshold.
  id: totrans-850
  prefs: []
  type: TYPE_NORMAL
  zh: 如果路由器使用由调度器服务的多个队列，情况就不同了。如果一个大型流量和一个小型流量在争夺带宽，调度器已经会偏向于使用带宽份额不足的小流量。小型流量的队列几乎会为空，而大型流量的队列则会逐渐增加。在采用此类调度器的路由器上，标记数据包的一个好方法是设置每个队列的占用率阈值，并在特定队列的占用率超过配置的阈值时标记到达该队列的数据包。
- en: Modeling TCP congestion control[#](#modeling-tcp-congestion-control "Link to
    this heading")
  id: totrans-851
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模型化TCP拥塞控制[#](#modeling-tcp-congestion-control "链接到这个标题")
- en: Thanks to its congestion control scheme, TCP adapts its transmission rate to
    the losses that occur in the network. Intuitively, the TCP transmission rate decreases
    when the percentage of losses increases. Researchers have proposed detailed models
    that allow the prediction of the throughput of a TCP connection when losses occur
    [[MSMO1997]](../bibliography.html#msmo1997) . To have some intuition about the
    factors that affect the performance of TCP, let us consider a very simple model.
    Its assumptions are not completely realistic, but it gives us good intuition without
    requiring complex mathematics.
  id: totrans-852
  prefs: []
  type: TYPE_NORMAL
  zh: 多亏了其拥塞控制方案，TCP能够根据网络中发生的损失调整其传输速率。直观地说，当损失百分比增加时，TCP的传输速率会降低。研究人员已经提出了详细的模型，可以预测TCP连接在发生损失时的吞吐量
    [[MSMO1997]](../bibliography.html#msmo1997)。为了对影响TCP性能的因素有所了解，让我们考虑一个非常简单的模型。它的假设并不完全现实，但它能给我们提供良好的直觉，而不需要复杂的数学。
- en: This model considers a hypothetical TCP connection that suffers from equally
    spaced segment losses. If \(p\) is the segment loss ratio, then the TCP connection
    successfully transfers \(\frac{1}{p}-1\) segments and the next segment is lost.
    If we ignore the slow-start at the beginning of the connection, TCP in this environment
    is always in congestion avoidance as there are only isolated losses that can be
    recovered by using fast retransmit. The evolution of the congestion window is
    thus as shown in the figure below. Note that the x-axis of this figure represents
    time measured in units of one round-trip-time, which is supposed to be constant
    in the model, and the y-axis represents the size of the congestion window measured
    in MSS-sized segments.
  id: totrans-853
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型考虑了一个假设的TCP连接，该连接遭受均匀分布的段丢失。如果 \(p\) 是段丢失率，则TCP连接成功传输 \(\frac{1}{p}-1\) 个段，下一个段丢失。如果我们忽略连接开始时的慢启动，由于只有可以通过快速重传恢复的孤立损失，因此在此环境中TCP始终处于拥塞避免状态。因此，拥塞窗口的演变如图所示。请注意，此图的x轴表示以往返时间为单位的测量时间，在模型中应保持恒定，而y轴表示以MSS大小的段测量的拥塞窗口大小。
- en: '[![../_images/tcp-congestion-regular.png](../Images/aba5ecafe63f482ae07b7a280f8f3275.png)](../_images/tcp-congestion-regular.png)'
  id: totrans-854
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/tcp-congestion-regular.png](../Images/aba5ecafe63f482ae07b7a280f8f3275.png)'
- en: Fig. 226 Evolution of the congestion window with regular losses[#](#id112 "Link
    to this image")
  id: totrans-855
  prefs: []
  type: TYPE_NORMAL
  zh: 图226 常规损失下的拥塞窗口演变[#](#id112 "链接到此图像")
- en: 'As the losses are equally spaced, the congestion window always starts at some
    value (\(\frac{W}{2}\)), and is incremented by one MSS every round-trip-time until
    it reaches twice this value (W). At this point, a segment is retransmitted and
    the cycle starts again. If the congestion window is measured in MSS-sized segments,
    a cycle lasts \(\frac{W}{2}\) round-trip-times. The bandwidth of the TCP connection
    is the number of bytes that have been transmitted during a given period of time.
    During a cycle, the number of segments that are sent on the TCP connection is
    equal to the area of the yellow trapeze in the figure. Its area is thus :'
  id: totrans-856
  prefs: []
  type: TYPE_NORMAL
  zh: 由于损失是均匀分布的，拥塞窗口始终从某个值（\(\frac{W}{2}\)）开始，并在每个往返时间内增加一个MSS，直到达到这个值的两倍（W）。在此点，一个段被重传，周期重新开始。如果以MSS大小的段来衡量拥塞窗口，则一个周期持续
    \(\frac{W}{2}\) 个往返时间。TCP连接的带宽是在给定时间段内已传输的字节数。在一个周期内，TCP连接上发送的段数等于图中黄色梯形的面积。因此，其面积为：
- en: \(area=(\frac{W}{2})^2 + \frac{1}{2} \times (\frac{W}{2})^2 = \frac{3 \times
    W^2}{8}\)
  id: totrans-857
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: \(面积=(\frac{W}{2})^2 + \frac{1}{2} \times (\frac{W}{2})^2 = \frac{3 \times W^2}{8}\)
- en: 'However, given the regular losses that we consider, the number of segments
    that are sent between two losses (i.e. during a cycle) is by definition equal
    to \(\frac{1}{p}\). Thus, \(W=\sqrt{\frac{8}{3 \times p}}=\frac{k}{\sqrt{p}}\).
    The throughput (in bytes per second) of the TCP connection is equal to the number
    of segments transmitted divided by the duration of the cycle :'
  id: totrans-858
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，考虑到我们考虑的常规损失，两个损失之间发送的段数（即在周期内）根据定义等于 \(\frac{1}{p}\)。因此，\(W=\sqrt{\frac{8}{3
    \times p}}=\frac{k}{\sqrt{p}}\)。TCP连接的吞吐量（以每秒字节数计算）等于发送的段数除以周期的持续时间：
- en: \(Throughput=\frac{area \times MSS}{time} = \frac{ \frac{3 \times W^2}{8}}{\frac{W}{2}
    \times rtt}\) or, after having eliminated W, \(Throughput=\sqrt{\frac{3}{2}} \times
    \frac{MSS}{rtt \times \sqrt{p}}\)
  id: totrans-859
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: \(Throughput=\frac{面积 \times MSS}{时间} = \frac{ \frac{3 \times W^2}{8}}{\frac{W}{2}
    \times rtt}\) 或者，在消除W之后，\(Throughput=\sqrt{\frac{3}{2}} \times \frac{MSS}{rtt
    \times \sqrt{p}}\)
- en: 'More detailed models and the analysis of simulations have shown that a first
    order model of the TCP throughput when losses occur was \(Throughput \approx \frac{k
    \times MSS}{rtt \times \sqrt{p}}\). This is an important result which shows that
    :'
  id: totrans-860
  prefs: []
  type: TYPE_NORMAL
  zh: 更详细的模型和模拟分析表明，当发生损失时，TCP吞吐量的第一阶模型为 \(Throughput \approx \frac{k \times MSS}{rtt
    \times \sqrt{p}}\)。这是一个重要的结果，它表明：
- en: TCP connections with a small round-trip-time can achieve a higher throughput
    than TCP connections having a longer round-trip-time when losses occur. This implies
    that the TCP congestion control scheme is not completely fair since it favors
    the connections that have the shorter round-trip-times.
  id: totrans-861
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当发生损失时，具有较短往返时间的TCP连接的吞吐量可以比具有较长往返时间的TCP连接的吞吐量更高。这表明TCP拥塞控制方案并不完全公平，因为它有利于具有较短的往返时间的连接。
- en: ''
  id: totrans-862
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-863
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: TCP connections that use a large MSS can achieve a higher throughput that the
    TCP connections that use a shorter MSS. This creates another source of unfairness
    between TCP connections. However, it should be noted that today most hosts are
    using almost the same MSS, roughly 1460 bytes.
  id: totrans-864
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用较大MSS的TCP连接可以达到比使用较短MSS的TCP连接更高的吞吐量。这为TCP连接之间创造了另一个不公平的来源。然而，应该注意的是，如今大多数主机几乎都使用相同大小的MSS，大约为1460字节。
- en: In general, the maximum throughput that can be achieved by a TCP connection
    depends on its maximum window size and the round-trip-time if there are no losses.
    If there are losses, it depends on the MSS, the round-trip-time and the loss ratio.
  id: totrans-865
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，在没有丢失的情况下，TCP连接可以达到的最大吞吐量取决于其最大窗口大小和往返时间。如果有丢失，则取决于MSS、往返时间和丢失率。
- en: \(Throughput<\min(\frac{window}{rtt},\frac{k \times MSS}{rtt \times \sqrt{p}})\)
  id: totrans-866
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: \(Throughput<\min(\frac{window}{rtt},\frac{k \times MSS}{rtt \times \sqrt{p}})\)
- en: Note
  id: totrans-867
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The TCP congestion control zoo
  id: totrans-868
  prefs: []
  type: TYPE_NORMAL
  zh: TCP拥塞控制动物园
- en: 'The first TCP congestion control scheme was proposed by [Van Jacobson](https://en.wikipedia.org/wiki/Van_Jacobson)
    in [[Jacobson1988]](../bibliography.html#jacobson1988). In addition to writing
    the scientific paper, [Van Jacobson](https://en.wikipedia.org/wiki/Van_Jacobson)
    also implemented the slow-start and congestion avoidance schemes in release 4.3
    Tahoe of the BSD Unix distributed by the University of Berkeley. Later, he improved
    the congestion control by adding the fast retransmit and the fast recovery mechanisms
    in the Reno release of 4.3 BSD Unix. Since then, many researchers have proposed,
    simulated and implemented modifications to the TCP congestion control scheme.
    Some of these modifications are still used today, e.g. :'
  id: totrans-869
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个TCP拥塞控制方案是由[Van Jacobson](https://en.wikipedia.org/wiki/Van_Jacobson)在[[Jacobson1988]](../bibliography.html#jacobson1988)提出的。除了撰写科学论文外，[Van
    Jacobson](https://en.wikipedia.org/wiki/Van_Jacobson)还在伯克利大学分发的BSD Unix的4.3 Tahoe版本中实现了慢启动和拥塞避免方案。后来，他在4.3
    BSD Unix的Reno版本中通过添加快速重传和快速恢复机制来改进拥塞控制。从那时起，许多研究人员提出了、模拟并实现了对TCP拥塞控制方案的修改。其中一些修改至今仍在使用，例如：
- en: NewReno ([**RFC 3782**](https://datatracker.ietf.org/doc/html/rfc3782.html)),
    which was proposed as an improvement of the fast recovery mechanism in the Reno
    implementation.
  id: totrans-870
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: NewReno ([**RFC 3782**](https://datatracker.ietf.org/doc/html/rfc3782.html))，作为Reno实现中快速恢复机制的改进而提出。
- en: ''
  id: totrans-871
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-872
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: TCP Vegas, which uses changes in the round-trip-time to estimate congestion
    in order to avoid it [[BOP1994]](../bibliography.html#bop1994). This is one of
    the examples of the delay-based congestion control algorithms. A Vegas sender
    continuously measures the evolution of the round-trip-time and slows down when
    the round-trip-time increases significantly. This enables Vegas to prevent congestion
    when used alone. Unfortunately, if Vegas senders compete with more aggressive
    TCP congestion control schemes that only react to losses, Vegas senders may have
    difficulties to use their fair share of the available bandwidth.
  id: totrans-873
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: TCP Vegas，它使用往返时间的变化来估计拥塞以避免它 [[BOP1994]](../bibliography.html#bop1994)。这是基于延迟的拥塞控制算法的例子之一。Vegas发送器持续测量往返时间的演变，并在往返时间显著增加时减速。这使得Vegas在单独使用时能够防止拥塞。不幸的是，如果Vegas发送器与仅对丢失做出反应的更具侵略性的TCP拥塞控制方案竞争，Vegas发送器可能难以使用其应有的带宽份额。
- en: ''
  id: totrans-874
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-875
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: CUBIC, which was designed for high bandwidth links and is the default congestion
    control scheme in Linux since the Linux 2.6.19 kernel [[HRX2008]](../bibliography.html#hrx2008).
    It is now used by several operating systems and is becoming the default congestion
    control scheme [**RFC 8312**](https://datatracker.ietf.org/doc/html/rfc8312.html).
    A key difference between CUBIC and the TCP congestion control scheme described
    in this chapter is that CUBIC is much more aggressive when probing the network.
    Instead of relying on additive increase after a fast recovery, a CUBIC sender
    adjusts its congestion by using a cubic function. Thanks to this function, the
    congestion windows grows faster. This is particularly important in high-bandwidth
    delay networks.
  id: totrans-876
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: CUBIC，专为高带宽链路设计，自Linux 2.6.19内核以来一直是Linux的默认拥塞控制方案 [[HRX2008]](../bibliography.html#hrx2008)。现在它被几个操作系统使用，并正在成为默认的拥塞控制方案
    [**RFC 8312**](https://datatracker.ietf.org/doc/html/rfc8312.html)。CUBIC与本章中描述的TCP拥塞控制方案的一个关键区别是，CUBIC在探测网络时更为激进。它不是在快速恢复后依赖加性增长，而是通过使用立方函数来调整拥塞。多亏了这个函数，拥塞窗口增长得更快。这在高带宽延迟网络中尤为重要。
- en: ''
  id: totrans-877
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-878
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: BBR, which is being developed by Google researchers and is included in recent
    Linux kernels [[CCG+2016]](../bibliography.html#ccg-2016). BBR periodically estimates
    the available bandwidth and the round-trip-times. To adapt to changes in network
    conditions, BBR regularly tries to send at 1.25 times the current bandwidth. This
    enables BBR senders to probe the network, but can also cause large amount of losses.
    Recent scientific articles indicate that BBR is unfair to other congestion control
    schemes in specific conditions [[WMSS2019]](../bibliography.html#wmss2019).
  id: totrans-879
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: BBR，由谷歌研究人员开发，并包含在最近的 Linux 内核中 [[CCG+2016]](../bibliography.html#ccg-2016)。BBR
    定期估计可用带宽和往返时间。为了适应网络条件的变化，BBR 定期尝试以当前带宽的 1.25 倍发送数据。这使 BBR 发送者能够探测网络，但也可能导致大量损失。最近的科学文章表明，在特定条件下
    BBR 对其他拥塞控制方案不公平 [[WMSS2019]](../bibliography.html#wmss2019)。
- en: A wide range of congestion control schemes have been proposed in the scientific
    literature and several of them have been widely deployed. A detailed comparison
    of these congestion control schemes is outside the scope of this chapter. A recent
    survey paper describing many of the implemented TCP congestion control schemes
    may be found in [[TKU2019]](../bibliography.html#tku2019).
  id: totrans-880
  prefs: []
  type: TYPE_NORMAL
  zh: 科学文献中提出了广泛的拥塞控制方案，其中一些已被广泛部署。这些拥塞控制方案的详细比较超出了本章的范围。一篇最近的研究综述描述了许多已实现的 TCP 拥塞控制方案，可以在
    [[TKU2019]](../bibliography.html#tku2019) 中找到。
- en: Footnotes
  id: totrans-881
  prefs: []
  type: TYPE_NORMAL
  zh: 脚注
- en: Footnotes
  id: totrans-882
  prefs: []
  type: TYPE_NORMAL
  zh: 脚注
- en: Congestion control with a window-based transport protocol[#](#congestion-control-with-a-window-based-transport-protocol
    "Link to this heading")
  id: totrans-883
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于窗口传输协议的拥塞控制[#](#congestion-control-with-a-window-based-transport-protocol
    "链接到本标题")
- en: AIMD controls congestion by adjusting the transmission rate of the sources in
    reaction to the current congestion level. If the network is not congested, the
    transmission rate increases. If congestion is detected, the transmission rate
    is multiplicatively decreased. In practice, directly adjusting the transmission
    rate can be difficult since it requires the utilization of fine grained timers.
    In reliable transport protocols, an alternative is to dynamically adjust the sending
    window. This is the solution chosen for protocols like TCP and SCTP that will
    be described in more details later. To understand how window-based protocols can
    adjust their transmission rate, let us consider the very simple scenario of a
    reliable transport protocol that uses go-back-n. Consider the very simple scenario
    shown in figure [Fig. 215](#fig-bottleneck).
  id: totrans-884
  prefs: []
  type: TYPE_NORMAL
  zh: AIMD 通过对当前拥塞水平做出反应来调整源传输速率以控制拥塞。如果网络没有拥塞，传输速率会增加。如果检测到拥塞，传输速率会乘性降低。在实践中，直接调整传输速率可能很困难，因为它需要使用细粒度计时器。在可靠的传输协议中，一种替代方法是动态调整发送窗口。这是
    TCP 和 SCTP 等协议所选择的解决方案，这些协议将在稍后更详细地描述。为了了解基于窗口的协议如何调整它们的传输速率，让我们考虑一个非常简单的可靠传输协议场景，该协议使用
    go-back-n。考虑图 [图. 215](#fig-bottleneck) 中所示非常简单的场景。
- en: '![Figure made with TikZ](../Images/fba8d6b7380280ee70f3550fb599fb9f.png)'
  id: totrans-885
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用 TikZ 制作的图](../Images/fba8d6b7380280ee70f3550fb599fb9f.png)'
- en: ''
  id: totrans-886
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 215 A simple network with hosts sharing a bottleneck link
  id: totrans-887
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图. 215 一个具有主机共享瓶颈链路的基本网络
- en: The links between the hosts and the routers have a bandwidth of 1 Mbps while
    the link between the two routers has a bandwidth of 500 Kbps. There is no significant
    propagation delay in this network. For simplicity, assume that hosts A and B send
    1000 bits packets. The transmission of such a packet on a host-router (resp. router-router
    ) link requires 1 msec (resp. 2 msec). If there is no traffic in the network,
    the round-trip-time measured by host A to reach D is slightly larger than 4 msec.
    Let us observe the flow of packets with different window sizes to understand the
    relationship between sending window and transmission rate.
  id: totrans-888
  prefs: []
  type: TYPE_NORMAL
  zh: 主机与路由器之间的链路带宽为 1 Mbps，而两个路由器之间的链路带宽为 500 Kbps。在这个网络中没有显著的传播延迟。为了简单起见，假设主机 A
    和 B 发送 1000 比特的分组。在主机-路由器（分别. 路由器-路由器）链路上传输这样的分组需要 1 毫秒（分别. 2 毫秒）。如果没有网络流量，主机
    A 测量的往返时间略大于 4 毫秒。让我们观察不同窗口大小的分组流，以了解发送窗口与传输速率之间的关系。
- en: Consider first a window of one segment. This segment takes 4 msec to reach host
    D. The destination replies with an acknowledgment and the next segment can be
    transmitted. With such a sending window, the transmission rate is roughly 250
    segments per second or 250 Kbps. This is illustrated in figure [Fig. 216](#fig-gbn-win-1)
    where each square of the grid corresponds to one millisecond.
  id: totrans-889
  prefs: []
  type: TYPE_NORMAL
  zh: 首先考虑一个包含一个段的窗口。这个段需要4毫秒才能到达主机D。目标主机回复一个确认信息，然后下一个段可以被传输。在这样的发送窗口下，传输速率大约是每秒250个段或250
    Kbps。这如图[图. 216](#fig-gbn-win-1)所示，其中网格的每个方格对应于1毫秒。
- en: '![Figure made with TikZ](../Images/fb17e125cf960286b8258b6251471572.png)'
  id: totrans-890
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用TikZ制作的图](../Images/fb17e125cf960286b8258b6251471572.png)'
- en: ''
  id: totrans-891
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 216 Go-back-n transfer from A to D, window of one segment
  id: totrans-892
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图. 216 从A到D的Go-back-n传输，一个段的窗口
- en: Consider now a window of two segments. Host A can send two segments within 2
    msec on its 1 Mbps link. If the first segment is sent at time \(t_{0}\), it reaches
    host D at \(t_{0}+4\). Host D replies with an acknowledgment that opens the sending
    window on host A and enables it to transmit a new segment. In the meantime, the
    second segment was buffered by router R1. It reaches host D at \(t_{0}+6\) and
    an acknowledgment is returned. With a window of two segments, host A transmits
    at roughly 500 Kbps, i.e. the transmission rate of the bottleneck link.
  id: totrans-893
  prefs: []
  type: TYPE_NORMAL
  zh: 现在考虑一个包含两个段的窗口。主机A可以在其1 Mbps链路上在2毫秒内发送两个段。如果第一个段在时间\(t_{0}\)发送，它将在\(t_{0}+4\)时到达主机D。主机D回复一个确认信息，这个确认信息打开主机A的发送窗口，并允许它传输一个新的段。同时，第二个段被路由器R1缓冲。它将在\(t_{0}+6\)时到达主机D，并返回一个确认信息。在两个段的窗口下，主机A的传输速率大约是500
    Kbps，即瓶颈链路的传输速率。
- en: '![Figure made with TikZ](../Images/972780cbffde5435003f04c4edfabc56.png)'
  id: totrans-894
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用TikZ制作的图](../Images/972780cbffde5435003f04c4edfabc56.png)'
- en: ''
  id: totrans-895
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 217 Go-back-n transfer from A to D, window of two segments
  id: totrans-896
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图. 217 从A到D的Go-back-n传输，两个段的窗口
- en: Our last example is a window of four segments. These segments are sent at \(t_{0}\),
    \(t_{0}+1\), \(t_{0}+2\) and \(t_{0}+3\). The first segment reaches host D at
    \(t_{0}+4\). Host D replies to this segment by sending an acknowledgment that
    enables host A to transmit its fifth segment. This segment reaches router R1 at
    \(t_{0}+5\). At that time, router R1 is transmitting the third segment to router
    R2 and the fourth segment is still in its buffers. At time \(t_{0}+6\), host D
    receives the second segment and returns the corresponding acknowledgment. This
    acknowledgment enables host A to send its sixth segment. This segment reaches
    router R1 at roughly \(t_{0}+7\). At that time, the router starts to transmit
    the fourth segment to router R2. Since link R1-R2 can only sustain 500 Kbps, packets
    will accumulate in the buffers of R1. On average, there will be two packets waiting
    in the buffers of R1. The presence of these two packets will induce an increase
    of the round-trip-time as measured by the transport protocol. While the first
    segment was acknowledged within 4 msec, the fifth segment (data(4)) that was transmitted
    at time \(t_{0}+4\) is only acknowledged at time \(t_{0}+11\). On average, the
    sender transmits at 500 Kbps, but the utilization of a large window induces a
    longer delay through the network.
  id: totrans-897
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的最后一个例子是一个包含四个段的窗口。这些段在\(t_{0}\)，\(t_{0}+1\)，\(t_{0}+2\)和\(t_{0}+3\)时发送。第一个段在\(t_{0}+4\)时到达主机D。主机D通过发送一个确认信息来回复这个段，这个确认信息使得主机A能够发送它的第五个段。这个段在\(t_{0}+5\)时到达路由器R1。那时，路由器R1正在将第三个段传输到路由器R2，第四个段仍然在其缓冲区中。在\(t_{0}+6\)时，主机D收到第二个段并返回相应的确认信息。这个确认信息使得主机A能够发送它的第六个段。这个段在大约\(t_{0}+7\)时到达路由器R1。那时，路由器开始将第四个段传输到路由器R2。由于R1-R2链路只能支持500
    Kbps，数据包将会在R1的缓冲区中积累。平均来说，将有两个数据包在R1的缓冲区中等待。这两个数据包的存在将导致传输协议测量的往返时间的增加。虽然第一个段在4毫秒内得到了确认，但在\(t_{0}+4\)时发送的第五个段（数据(4)）直到\(t_{0}+11\)才得到确认。平均来说，发送方的传输速率为500
    Kbps，但大窗口的使用通过网络引入了更长的延迟。
- en: '![Figure made with TikZ](../Images/6fac88cb38e8b98800e49c18ffa34a0c.png)'
  id: totrans-898
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用TikZ制作的图](../Images/6fac88cb38e8b98800e49c18ffa34a0c.png)'
- en: ''
  id: totrans-899
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 218 Go-back-n transfer from A to D, window of four segments
  id: totrans-900
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图. 218 从A到D的Go-back-n传输，四个段的窗口
- en: From the above example, we can adjust the transmission rate by adjusting the
    sending window of a reliable transport protocol. A reliable transport protocol
    cannot send data faster than \(\frac{window}{rtt}\) segments per second where
    \(window\) is the current sending window. To control the transmission rate, we
    introduce a congestion window. This congestion window limits the sending window.
    At any time, the sending window is restricted to \(\min(swin,cwin)\), where swin
    is the sending window and cwin the current congestion window. Of course, the window
    is further constrained by the receive window advertised by the remote peer. With
    the utilization of a congestion window, a simple reliable transport protocol that
    uses fixed size segments could implement AIMD as follows.
  id: totrans-901
  prefs: []
  type: TYPE_NORMAL
  zh: 从上述示例中，我们可以通过调整可靠传输协议的发送窗口来调整传输速率。可靠传输协议不能以每秒超过 \(\frac{window}{rtt}\) 段的速度发送数据，其中
    \(window\) 是当前发送窗口。为了控制传输速率，我们引入了拥塞窗口。此拥塞窗口限制了发送窗口。在任何时候，发送窗口都受到 \(\min(swin,cwin)\)
    的限制，其中 swin 是发送窗口，cwin 是当前的拥塞窗口。当然，窗口还受到远程对端宣布的接收窗口的进一步限制。利用拥塞窗口，使用固定大小段的简单可靠传输协议可以如下实现AIMD。
- en: For the Additive Increase part our simple protocol would simply increase its
    congestion window by one segment every round-trip-time. The Multiplicative Decrease
    part of AIMD could be implemented by halving the congestion window when congestion
    is detected. For simplicity, we assume that congestion is detected thanks to a
    binary feedback and that no segments are lost. We will discuss in more details
    how losses affect a real transport protocol like TCP in later sections.
  id: totrans-902
  prefs: []
  type: TYPE_NORMAL
  zh: 对于增量增加部分，我们的简单协议将简单地在每个往返时间增加一个段。AIMD的乘性减少部分可以通过检测到拥塞时将拥塞窗口减半来实现。为了简单起见，我们假设由于二进制反馈而检测到拥塞，并且没有数据包丢失。我们将在后面的章节中更详细地讨论损失如何影响像TCP这样的实际传输协议。
- en: A congestion control scheme for our simple transport protocol could be implemented
    as follows.
  id: totrans-903
  prefs: []
  type: TYPE_NORMAL
  zh: 为我们简单的传输协议实现拥塞控制方案可以如下进行。
- en: '[PRE23]'
  id: totrans-904
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: In the above pseudocode, cwin contains the congestion window stored as a real
    number of segments. This congestion window is updated upon the arrival of each
    acknowledgment and when congestion is detected. For simplicity, we assume that
    cwin is stored as a floating point number but only full segments can be transmitted.
  id: totrans-905
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述伪代码中，cwin包含存储为段数的拥塞窗口。此拥塞窗口在收到每个确认以及检测到拥塞时更新。为了简单起见，我们假设cwin存储为浮点数，但只能传输完整的段。
- en: As an illustration, let us consider the network scenario above and assume that
    the router implements the DECBit binary feedback scheme [[RJ1995]](../bibliography.html#rj1995).
    This scheme uses a form of Forward Explicit Congestion Notification and a router
    marks the congestion bit in arriving packets when its buffer contains one or more
    packets. In figure [Fig. 219](#fig-gbn-decbit), we use a * to indicate a marked
    packet.
  id: totrans-906
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明，让我们考虑上述网络场景，并假设路由器实现了DECBit二进制反馈方案 [[RJ1995]](../bibliography.html#rj1995)。此方案使用一种前向显式拥塞通知，当路由器的缓冲区包含一个或多个数据包时，路由器会在到达的数据包中标记拥塞位。在图[图219](#fig-gbn-decbit)中，我们用*来表示标记的数据包。
- en: '![Figure made with TikZ](../Images/2b9761249f9ab8572a0fc4b3416b6752.png)'
  id: totrans-907
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用TikZ制作的图](../Images/2b9761249f9ab8572a0fc4b3416b6752.png)'
- en: ''
  id: totrans-908
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 219 Go-back-n transfer from A to D, with AIMD congestion control and DecBit
    binary feedback scheme
  id: totrans-909
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图219 从A到D的Go-back-n传输，使用AIMD拥塞控制和DecBit二进制反馈方案
- en: When the connection starts, its congestion window is set to one segment. Segment
    S0 is sent an acknowledgment at roughly \(t_{0}+4\). The congestion window is
    increased by one segment and S1 and S2 are transmitted at time \(t_{0}+4\) and
    \(t_{0}+5\). The corresponding acknowledgments are received at times \(t_{0}+8\)
    and \(t_{0}+10\). Upon reception of this last acknowledgment, the congestion window
    reaches 3 and segments can be sent (S4 and S5). When segment S6 reaches router
    R1, its buffers already contain S5. The packet containing S6 is thus marked to
    inform the sender of the congestion. Note that the sender will only notice the
    congestion once it receives the corresponding acknowledgment at \(t_{0}+18\).
    In the meantime, the congestion window continues to increase. At \(t_{0}+16\),
    upon reception of the acknowledgment for S5, it reaches 4. When congestion is
    detected, the congestion window is decreased down to 2. This explains the idle
    time between the reception of the acknowledgment for S*6 and the transmission
    of S10.
  id: totrans-910
  prefs: []
  type: TYPE_NORMAL
  zh: 当连接开始时，其拥塞窗口设置为一段。S0 段在大约 \(t_{0}+4\) 时发送确认。拥塞窗口增加一段，S1 和 S2 在 \(t_{0}+4\) 和
    \(t_{0}+5\) 时传输。相应的确认在 \(t_{0}+8\) 和 \(t_{0}+10\) 时收到。在接收到最后一个确认后，拥塞窗口达到 3，可以发送段（S4
    和 S5）。当段 S6 达到路由器 R1 时，其缓冲区已包含 S5。包含 S6 的数据包因此被标记以通知发送者拥塞。请注意，发送者只有在接收到 \(t_{0}+18\)
    时的相应确认后才会注意到拥塞。在此期间，拥塞窗口继续增加。在 \(t_{0}+16\)，在接收到 S5 的确认后，它达到 4。当检测到拥塞时，拥塞窗口降低到
    2。这解释了从接收到 S*6 的确认到传输 S10 之间的空闲时间。
- en: In practice, a router is connected to multiple input links. Figure [Fig. 220](#fig-2hosts-bottleneck)
    shows an example with two hosts.
  id: totrans-911
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，路由器连接到多个输入链路。图 [图 220](#fig-2hosts-bottleneck) 展示了两个主机的一个示例。
- en: '![Figure made with TikZ](../Images/54044b2beb542c9ff304fe654e7cbe2e.png)'
  id: totrans-912
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用 TikZ 制作的图](../Images/54044b2beb542c9ff304fe654e7cbe2e.png)'
- en: ''
  id: totrans-913
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 220 A simple network with hosts sharing a bottleneck
  id: totrans-914
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图 220 一个简单的网络，主机共享瓶颈
- en: ''
  id: totrans-915
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Figure made with TikZ](../Images/14805061572e2ea7a08e10338a022ff8.png)'
  id: totrans-916
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用 TikZ 制作的图](../Images/14805061572e2ea7a08e10338a022ff8.png)'
- en: ''
  id: totrans-917
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 221 Sharing the bottleneck link between different inputs
  id: totrans-918
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图 221 不同输入之间共享瓶颈链路
- en: In general, the links have a non-zero delay. This is illustrated in the figure
    below where a delay has been added on the link between R and C.
  id: totrans-919
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，链路具有非零延迟。这在下图中得到了说明，其中在 R 和 C 之间的链路上添加了延迟。
- en: '![Figure made with TikZ](../Images/515eaae674689b5424d8fbcf3dfe9c0e.png)'
  id: totrans-920
  prefs:
  - PREF_BQ
  type: TYPE_IMG
  zh: '![使用 TikZ 制作的图](../Images/515eaae674689b5424d8fbcf3dfe9c0e.png)'
- en: ''
  id: totrans-921
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fig. 222 Sharing the bottleneck link between different inputs
  id: totrans-922
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 图 222 不同输入之间共享瓶颈链路
- en: '### Congestion control[#](#tcpcongestion "Link to this heading")'
  id: totrans-923
  prefs: []
  type: TYPE_NORMAL
  zh: '### 拥塞控制[#](#tcpcongestion "链接到这个标题")'
- en: In an internetwork, i.e. a networking composed of different types of networks
    (such as the Internet), congestion control could be implemented either in the
    network layer or the transport layer. The congestion problem was clearly identified
    in the later 1980s and the researchers who developed techniques to solve the problem
    opted for a solution in the transport layer. Adding congestion control to the
    transport layer makes sense since this layer provides a reliable data transfer
    and avoiding congestion is a factor in this reliable delivery. The transport layer
    already deals with heterogeneous networks thanks to its self-clocking property
    that we have already described. In this section, we explain how congestion control
    has been added to TCP and how this mechanism could be improved in the future.
  id: totrans-924
  prefs: []
  type: TYPE_NORMAL
  zh: 在互联网（即由不同类型的网络（如互联网）组成的网络）中，拥塞控制可以在网络层或传输层实现。拥塞问题在 20 世纪 80 年代后期得到了明确识别，开发了解决该问题技术的研究人员选择了在传输层解决方案。在传输层添加拥塞控制是有意义的，因为这一层提供可靠的数据传输，避免拥塞是这种可靠交付的一个因素。由于我们已经描述的自时钟特性，传输层已经处理了异构网络。在本节中，我们解释了拥塞控制是如何添加到
    TCP 的，以及这种机制如何在未来得到改进。
- en: The TCP congestion control scheme was initially proposed by [Van Jacobson](https://en.wikipedia.org/wiki/Van_Jacobson)
    in [[Jacobson1988]](../bibliography.html#jacobson1988). The current specification
    may be found in [**RFC 5681**](https://datatracker.ietf.org/doc/html/rfc5681.html).
    TCP relies on Additive Increase and Multiplicative Decrease (AIMD). To implement
    [AIMD](../glossary.html#term-AIMD), a TCP host must be able to control its transmission
    rate. A first approach would be to use timers and adjust their expiration times
    in function of the rate imposed by [AIMD](../glossary.html#term-AIMD). Unfortunately,
    maintaining such timers for a large number of TCP connections can be difficult.
    Instead, [Van Jacobson](https://en.wikipedia.org/wiki/Van_Jacobson) noted that
    the rate of TCP congestion can be artificially controlled by constraining its
    sending window. A TCP connection cannot send data faster than \(\frac{window}{rtt}\)
    where \(window\) is the minimum between the host’s sending window and the window
    advertised by the receiver.
  id: totrans-925
  prefs: []
  type: TYPE_NORMAL
  zh: TCP拥塞控制方案最初由[Van Jacobson](https://en.wikipedia.org/wiki/Van_Jacobson)在[[Jacobson1988]](../bibliography.html#jacobson1988)中提出。当前规范可以在[**RFC
    5681**](https://datatracker.ietf.org/doc/html/rfc5681.html)中找到。TCP依赖于增量增加和乘性减少（AIMD）。为了实现[AIMD](../glossary.html#term-AIMD)，TCP主机必须能够控制其传输速率。一种方法是通过定时器并根据[AIMD](../glossary.html#term-AIMD)施加的速率调整它们的过期时间。不幸的是，维护大量TCP连接的此类定时器可能很困难。相反，[Van
    Jacobson](https://en.wikipedia.org/wiki/Van_Jacobson)指出，可以通过限制其发送窗口来人为地控制TCP拥塞的速率。TCP连接的发送数据速率不能超过\(\frac{window}{rtt}\)，其中\(window\)是主机发送窗口和接收者广告窗口之间的最小值。
- en: TCP’s congestion control scheme is based on a congestion window. The current
    value of the congestion window (cwnd) is stored in the TCB of each TCP connection
    and the window that can be used by the sender is constrained by \(\min(cwnd,rwin,swin)\)
    where \(swin\) is the current sending window and \(rwin\) the last received receive
    window. The Additive Increase part of the TCP congestion control increments the
    congestion window by [MSS](../glossary.html#term-MSS) bytes every round-trip-time.
    In the TCP literature, this phase is often called the congestion avoidance phase.
    The Multiplicative Decrease part of the TCP congestion control divides the current
    value of the congestion window once congestion has been detected.
  id: totrans-926
  prefs: []
  type: TYPE_NORMAL
  zh: TCP的拥塞控制方案基于一个拥塞窗口。拥塞窗口（cwnd）的当前值存储在每个TCP连接的TCB中，发送者可以使用的窗口由\(\min(cwnd,rwin,swin)\)约束，其中\(swin\)是当前发送窗口，\(rwin\)是最后接收到的接收窗口。TCP拥塞控制的增量增加部分在每个往返时间通过增加[MSS](../glossary.html#term-MSS)字节来增加拥塞窗口。在TCP文献中，这个阶段通常被称为拥塞避免阶段。TCP拥塞控制的乘性减少部分在检测到拥塞后，将当前拥塞窗口的值除以一次。
- en: 'When a TCP connection begins, the sending host does not know whether the part
    of the network that it uses to reach the destination is congested or not. To avoid
    causing too much congestion, it must start with a small congestion window. [[Jacobson1988]](../bibliography.html#jacobson1988)
    recommends an initial window of MSS bytes. As the additive increase part of the
    TCP congestion control scheme increments the congestion window by MSS bytes every
    round-trip-time, the TCP connection may have to wait many round-trip-times before
    being able to efficiently use the available bandwidth. This is especially important
    in environments where the \(bandwidth \times rtt\) product is high. To avoid waiting
    too many round-trip-times before reaching a congestion window that is large enough
    to efficiently utilize the network, the TCP congestion control scheme includes
    the slow-start algorithm. The objective of the TCP slow-start phase is to quickly
    reach an acceptable value for the cwnd. During slow-start, the congestion window
    is doubled every round-trip-time. The slow-start algorithm uses an additional
    variable in the TCB : ssthresh (slow-start threshold). The ssthresh is an estimation
    of the last value of the cwnd that did not cause congestion. It is initialized
    at the sending window and is updated after each congestion event.'
  id: totrans-927
  prefs: []
  type: TYPE_NORMAL
  zh: 当TCP连接开始时，发送主机不知道它用来到达目的地的网络部分是否拥塞。为了避免造成过多的拥塞，它必须从一个小的拥塞窗口开始。[[Jacobson1988]](../bibliography.html#jacobson1988)建议一个初始窗口为MSS字节。由于TCP拥塞控制方案的累加增加部分在每个往返时间增加MSS字节的拥塞窗口，TCP连接可能需要等待多个往返时间才能有效地使用可用带宽。这在带宽乘以往返时间（\(bandwidth
    \times rtt\)）产品较高的环境中尤为重要。为了避免在达到足够大的拥塞窗口以有效地利用网络之前等待过多的往返时间，TCP拥塞控制方案包括慢启动算法。TCP慢启动阶段的目标是快速达到cwnd的可接受值。在慢启动期间，拥塞窗口在每个往返时间翻倍。慢启动算法在TCB中使用一个额外的变量：ssthresh（慢启动阈值）。ssthresh是对未引起拥塞的cwnd最后值的估计。它初始化为发送窗口，并在每次拥塞事件后更新。
- en: 'A key question that must be answered by any congestion control scheme is how
    congestion is detected. The first implementations of the TCP congestion control
    scheme opted for a simple and pragmatic approach : packet losses indicate congestion.
    If the network is congested, router buffers are full and packets are discarded.
    In wired networks, packet losses are mainly caused by congestion. In wireless
    networks, packets can be lost due to transmission errors and for other reasons
    that are independent of congestion. TCP already detects segment losses to ensure
    a reliable delivery. The TCP congestion control scheme distinguishes between two
    types of congestion :'
  id: totrans-928
  prefs: []
  type: TYPE_NORMAL
  zh: 任何拥塞控制方案都必须回答的一个关键问题是如何检测拥塞。TCP拥塞控制方案的第一种实现选择了简单而实用的方法：数据包丢失表示拥塞。如果网络拥塞，路由器缓冲区将满，数据包将被丢弃。在有线网络中，数据包丢失主要是由拥塞引起的。在无线网络中，数据包可能由于传输错误或其他与拥塞无关的原因而丢失。TCP已经检测到段丢失以确保可靠交付。TCP拥塞控制方案区分两种类型的拥塞：
- en: mild congestion. TCP considers that the network is lightly congested if it receives
    three duplicate acknowledgments and performs a fast retransmit. If the fast retransmit
    is successful, this implies that only one segment has been lost. In this case,
    TCP performs multiplicative decrease and the congestion window is divided by 2.
    The slow-start threshold is set to the new value of the congestion window.
  id: totrans-929
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 轻度拥塞。TCP认为如果它收到三个重复的确认并且执行快速重传，则网络轻微拥塞。如果快速重传成功，这意味着只有一个数据段丢失。在这种情况下，TCP执行乘性减少，拥塞窗口除以2。慢启动阈值设置为拥塞窗口的新值。
- en: ''
  id: totrans-930
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-931
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: severe congestion. TCP considers that the network is severely congested when
    its retransmission timer expires. In this case, TCP retransmits the first segment,
    sets the slow-start threshold to 50% of the congestion window. The congestion
    window is reset to its initial value and TCP performs a slow-start.
  id: totrans-932
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 严重拥塞。当TCP的重传计时器超时时，TCP认为网络严重拥塞。在这种情况下，TCP重传第一个数据段，将慢启动阈值设置为拥塞窗口的50%。拥塞窗口重置为其初始值，TCP执行慢启动。
- en: The figure below illustrates the evolution of the congestion window when there
    is severe congestion. At the beginning of the connection, the sender performs
    slow-start until the first segments are lost and the retransmission timer expires.
    At this time, the ssthresh is set to half of the current congestion window and
    the congestion window is reset at one segment. The lost segments are retransmitted
    as the sender again performs slow-start until the congestion window reaches the
    sshtresh. It then switches to congestion avoidance and the congestion window increases
    linearly until segments are lost and the retransmission timer expires.
  id: totrans-933
  prefs: []
  type: TYPE_NORMAL
  zh: 下图说明了在严重拥塞时拥塞窗口的演变。在连接开始时，发送方执行慢启动，直到第一个段丢失并且重传计时器到期。此时，ssthresh 设置为当前拥塞窗口的一半，拥塞窗口重置为一个段。丢失的段在发送方再次执行慢启动并使拥塞窗口达到
    ssthresh 时被重传。然后它切换到拥塞避免，拥塞窗口线性增加，直到段丢失并且重传计时器到期。
- en: '[![../_images/tcp-congestion-severe.png](../Images/8bb9ad90fd07bc82d9cba2b40a1481a6.png)](../_images/tcp-congestion-severe.png)'
  id: totrans-934
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/tcp-congestion-severe.png](../Images/8bb9ad90fd07bc82d9cba2b40a1481a6.png)(../_images/tcp-congestion-severe.png)'
- en: Fig. 223 Evaluation of the TCP congestion window with severe congestion[#](#id109
    "Link to this image")
  id: totrans-935
  prefs: []
  type: TYPE_NORMAL
  zh: 图 223 严重拥塞时 TCP 拥塞窗口的评估[#](#id109 "链接到这张图片")
- en: The figure below illustrates the evolution of the congestion window when the
    network is lightly congested and all lost segments can be retransmitted using
    fast retransmit. The sender begins with a slow-start. A segment is lost but successfully
    retransmitted by a fast retransmit. The congestion window is divided by 2 and
    the sender immediately enters congestion avoidance as this was a mild congestion.
  id: totrans-936
  prefs: []
  type: TYPE_NORMAL
  zh: 下图说明了在网络轻微拥塞时拥塞窗口的演变，并且所有丢失的段都可以使用快速重传重新传输。发送方从慢启动开始。一个段丢失，但通过快速重传成功重传。由于这是轻微的拥塞，拥塞窗口减半，发送方立即进入拥塞避免状态。
- en: '[![../_images/tcp-congestion-mild.png](../Images/118024671401b1ade2c8daa21527e64f.png)](../_images/tcp-congestion-mild.png)'
  id: totrans-937
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/tcp-congestion-mild.png](../Images/118024671401b1ade2c8daa21527e64f.png)(../_images/tcp-congestion-mild.png)'
- en: Fig. 224 Evaluation of the TCP congestion window when the network is lightly
    congested[#](#id110 "Link to this image")
  id: totrans-938
  prefs: []
  type: TYPE_NORMAL
  zh: 图 224 网络轻微拥塞时 TCP 拥塞窗口的评估[#](#id110 "链接到这张图片")
- en: Most TCP implementations update the congestion window when they receive an acknowledgment.
    If we assume that the receiver acknowledges each received segment and the sender
    only sends MSS sized segments, the TCP congestion control scheme can be implemented
    using the simplified pseudo-code [[7]](#fwrap) below. This pseudocode includes
    the optimization proposed in [**RFC 3042**](https://datatracker.ietf.org/doc/html/rfc3042.html)
    that allows a sender to send new unsent data upon reception of the first or second
    duplicate acknowledgment. The reception of each of these acknowledgments indicates
    that one segment has left the network and thus additional data can be sent without
    causing more congestion. Note that the congestion window is *not* increased upon
    reception of these first duplicate acknowledgments.
  id: totrans-939
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数 TCP 实现会在收到确认时更新拥塞窗口。如果我们假设接收方确认每个接收到的段，并且发送方只发送 MSS 大小的段，则可以使用以下简化的伪代码 [[7]](#fwrap)
    实现 TCP 拥塞控制方案。此伪代码包括在 [**RFC 3042**](https://datatracker.ietf.org/doc/html/rfc3042.html)
    中提出的优化，允许发送方在收到第一个或第二个重复确认后发送新的未发送数据。接收这些确认中的每一个都表明一个段已经离开网络，因此可以发送额外的数据而不会造成更多的拥塞。请注意，在收到这些第一个重复确认时，拥塞窗口**不会**增加。
- en: '[PRE24]'
  id: totrans-940
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Furthermore when a TCP connection has been idle for more than its current retransmission
    timer, it should reset its congestion window to the congestion window size that
    it uses when the connection begins, as it no longer knows the current congestion
    state of the network.
  id: totrans-941
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，当 TCP 连接空闲时间超过其当前重传计时器时，它应将其拥塞窗口重置为连接开始时使用的拥塞窗口大小，因为它不再知道网络的当前拥塞状态。
- en: Note
  id: totrans-942
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Initial congestion window
  id: totrans-943
  prefs: []
  type: TYPE_NORMAL
  zh: 初始拥塞窗口
- en: The original TCP congestion control mechanism proposed in [[Jacobson1988]](../bibliography.html#jacobson1988)
    recommended that each TCP connection should begin by setting \(cwnd=MSS\). However,
    in today’s higher bandwidth networks, using such a small initial congestion window
    severely affects the performance for short TCP connections, such as those used
    by web servers. In 2002, [**RFC 3390**](https://datatracker.ietf.org/doc/html/rfc3390.html)
    allowed an initial congestion window of about 4 KBytes, which corresponds to 3
    segments in many environments. Recently, researchers from Google proposed to further
    increase the initial window up to 15 KBytes [[DRC+2010]](../bibliography.html#drc-2010).
    The measurements that they collected show that this increase would not significantly
    increase congestion but would significantly reduce the latency of short HTTP responses.
    Unsurprisingly, the chosen initial window corresponds to the average size of an
    HTTP response from a search engine. This proposed modification has been adopted
    in [**RFC 6928**](https://datatracker.ietf.org/doc/html/rfc6928.html) and TCP
    implementations support it.
  id: totrans-944
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [[Jacobson1988]](../bibliography.html#jacobson1988) 中提出的原始TCP拥塞控制机制建议每个TCP连接应从设置
    \(cwnd=MSS\) 开始。然而，在今天的宽带网络中，使用如此小的初始拥塞窗口严重影响了短TCP连接的性能，例如那些由Web服务器使用的连接。2002年，[**RFC
    3390**](https://datatracker.ietf.org/doc/html/rfc3390.html) 允许初始拥塞窗口约为4 KBytes，这在许多环境中对应于3个段。最近，谷歌的研究人员提出了将初始窗口进一步增加到15
    KBytes [[DRC+2010]](../bibliography.html#drc-2010)。他们收集的测量数据显示，这种增加不会显著增加拥塞，但会显著减少短HTTP响应的延迟。不出所料，所选的初始窗口对应于搜索引擎的HTTP响应的平均大小。这种提出的修改已在
    [**RFC 6928**](https://datatracker.ietf.org/doc/html/rfc6928.html) 中被采用，并且TCP实现支持它。
- en: Controlling congestion without losing data[#](#controlling-congestion-without-losing-data
    "Link to this heading")
  id: totrans-945
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 无数据丢失地控制拥塞[#](#controlling-congestion-without-losing-data "链接到这个标题")
- en: In today’s Internet, congestion is controlled by regularly sending packets at
    a higher rate than the network capacity. These packets fill the buffers of the
    routers and are eventually discarded. But shortly after, TCP senders retransmit
    packets containing exactly the same data. This is potentially a waste of resources
    since these successive retransmissions consume resources upstream of the router
    that discards the packets. Packet losses are not the only signal to detect congestion
    inside the network. An alternative is to allow routers to explicitly indicate
    their current level of congestion when forwarding packets. This approach was proposed
    in the late 1980s [[RJ1995]](../bibliography.html#rj1995) and used in some networks.
    Unfortunately, it took almost a decade before the Internet community agreed to
    consider this approach. In the mean time, a large number of TCP implementations
    and routers were deployed on the Internet.
  id: totrans-946
  prefs: []
  type: TYPE_NORMAL
  zh: 在今天的互联网中，通过定期以高于网络容量的速率发送数据包来控制拥塞。这些数据包填满了路由器的缓冲区，最终被丢弃。但不久之后，TCP发送者会重新发送包含完全相同数据的数据包。这可能导致资源的浪费，因为这些连续的重传消耗了丢弃数据包的路由器上游的资源。数据包丢失并不是检测网络内部拥塞的唯一信号。一种替代方案是允许路由器在转发数据包时明确地指示其当前的拥塞水平。这种方法在20世纪80年代末被提出
    [[RJ1995]](../bibliography.html#rj1995) 并在一些网络中使用。不幸的是，在互联网社区几乎经过十年才同意考虑这种方法。在此期间，大量的TCP实现和路由器被部署在互联网上。
- en: As explained earlier, Explicit Congestion Notification [**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)
    improves the detection of congestion by allowing routers to explicitly mark packets
    when they are lightly congested. In theory, a single bit in the packet header
    [[RJ1995]](../bibliography.html#rj1995) is sufficient to support this congestion
    control scheme. When a host receives a marked packet, it returns the congestion
    information to the source that adapts its transmission rate accordingly. Although
    the idea is relatively simple, deploying it on the entire Internet has proven
    to be challenging [[KNT2013]](../bibliography.html#knt2013). It is interesting
    to analyze the different factors that have hindered the deployment of this technique.
  id: totrans-947
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，显式拥塞通知 [**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)
    通过允许路由器在轻微拥塞时明确标记数据包来提高拥塞检测。理论上，数据包头部的一个比特 [[RJ1995]](../bibliography.html#rj1995)
    就足以支持这种拥塞控制方案。当一个主机收到标记的数据包时，它会将拥塞信息返回给源主机，源主机据此调整其传输速率。尽管这个想法相对简单，但在整个互联网上部署它已被证明是具有挑战性的
    [[KNT2013]](../bibliography.html#knt2013)。分析阻碍这种技术部署的不同因素是很有趣的。
- en: The first difficulty in adding Explicit Congestion Notification (ECN) in TCP/IP
    network was to modify the format of the network packet and transport segment headers
    to carry the required information. In the network layer, one bit was required
    to allow the routers to mark the packets they forward during congestion periods.
    In the IP network layer, this bit is called the Congestion Experienced (CE) bit
    and is part of the packet header. However, using a single bit to mark packets
    is not sufficient. Consider a simple scenario with two sources, one congested
    router and one destination. Assume that the first sender and the destination support
    ECN, but not the second sender. If the router is congested it will mark packets
    from both senders. The first sender will react to the packet markings by reducing
    its transmission rate. However since the second sender does not support ECN, it
    will not react to the markings. Furthermore, this sender could continue to increase
    its transmission rate, which would lead to more packets being marked and the first
    source would decrease again its transmission rate, … In the end, the sources that
    implement ECN are penalized compared to the sources that do not implement it.
    This unfairness issue is a major hurdle to widely deploy ECN on the public Internet
    [[8]](#fprivate). The solution proposed in [**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)
    to deal with this problem is to use a second bit in the network packet header.
    This bit, called the ECN-capable transport (ECT) bit, indicates whether the packet
    contains a segment produced by a transport protocol that supports ECN or not.
    Transport protocols that support ECN set the ECT bit in all packets. When a router
    is congested, it first verifies whether the ECT bit is set. In this case, the
    CE bit of the packet is set to indicate congestion. Otherwise, the packet is discarded.
    This eases the deployment of ECN [[9]](#fecnnonce).
  id: totrans-948
  prefs: []
  type: TYPE_NORMAL
  zh: 在 TCP/IP 网络中添加显式拥塞通知 (ECN) 的第一个困难是修改网络数据包和传输段头的格式，以便携带所需的信息。在网络层，需要一个比特位来允许路由器在拥塞期间标记它们转发的数据包。在
    IP 网络层，这个比特位被称为拥塞经历 (CE) 比特位，是数据包头部的一部分。然而，使用单个比特位来标记数据包是不够的。考虑一个有两个源、一个拥塞路由器和目的地的一个简单场景。假设第一个发送器和目的地支持
    ECN，但第二个发送器不支持。如果路由器拥塞，它将标记来自两个发送器的数据包。第一个发送器将通过降低其传输速率来对数据包标记做出反应。然而，由于第二个发送器不支持
    ECN，它不会对标记做出反应。此外，这个发送器可能会继续增加其传输速率，这将导致更多数据包被标记，而第一个源将再次降低其传输速率，……最终，实施 ECN 的源与未实施
    ECN 的源相比会受到惩罚。这个问题的不公平性是广泛部署 ECN 在公共互联网上的主要障碍 [[8]](#fprivate)。在 [**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)
    中提出的解决这个问题的方案是在网络数据包头部使用第二个比特位。这个比特位被称为 ECN 兼容传输 (ECT) 比特位，它指示数据包是否包含由支持 ECN 的传输协议产生的段。支持
    ECN 的传输协议在所有数据包中设置 ECT 比特位。当一个路由器拥塞时，它首先验证 ECT 比特位是否被设置。在这种情况下，数据包的 CE 比特位被设置为指示拥塞。否则，数据包将被丢弃。这简化了
    ECN 的部署 [[9]](#fecnnonce)。
- en: 'The second difficulty is how to allow the receiver to inform the sender of
    the reception of network packets marked with the CE bit. In reliable transport
    protocols like TCP and SCTP, the acknowledgments can be used to provide this feedback.
    For TCP, two options were possible : change some bits in the TCP segment header
    or define a new TCP option to carry this information. The designers of ECN opted
    for reusing spare bits in the TCP header. More precisely, two TCP flags have been
    added in the TCP header to support ECN. The ECN-Echo (ECE) is set in the acknowledgments
    when the CE was set in packets received on the forward path.'
  id: totrans-949
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个困难是如何让接收器通知发送器接收了带有 CE 比特位标记的网络数据包。在像 TCP 和 SCTP 这样的可靠传输协议中，可以通过确认来提供这种反馈。对于
    TCP，有两种可能的选择：更改 TCP 段头中的某些比特位或定义一个新的 TCP 选项来携带此信息。ECN 的设计者选择了重用 TCP 头部中的空闲比特位。更确切地说，在
    TCP 头部中添加了两个 TCP 标志来支持 ECN。ECN 反射 (ECE) 在确认中设置，当在正向路径上接收到的数据包中设置了 CE 时。
- en: '[![../_images/tcp-enc.svg](../Images/0b92b95f1c0dadde63905a28574e87cb.png)](../_images/tcp-enc.svg)'
  id: totrans-950
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/tcp-enc.svg](../Images/0b92b95f1c0dadde63905a28574e87cb.png)'
- en: Fig. 225 The TCP flags[#](#id111 "Link to this image")
  id: totrans-951
  prefs: []
  type: TYPE_NORMAL
  zh: 图 225 TCP 标志[#](#id111 "链接到这张图片")
- en: The third difficulty is to allow an ECN-capable sender to detect whether the
    remote host also supports ECN. This is a classical negotiation of extensions to
    a transport protocol. In TCP, this could have been solved by defining a new TCP
    option used during the three-way handshake. To avoid wasting space in the TCP
    options, the designers of ECN opted in [**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)
    for using the ECN-Echo and CWR bits in the TCP header to perform this negotiation.
    In the end, the result is the same with fewer bits exchanged.
  id: totrans-952
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个困难是允许一个支持 ECN 的发送者检测远程主机是否也支持 ECN。这是一个经典的传输协议扩展协商。在 TCP 中，这可以通过在三次握手期间定义一个新的
    TCP 选项来解决。为了避免在 TCP 选项中浪费空间，ECN 的设计者在 [**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)
    中选择了使用 TCP 头部的 ECN-Echo 和 CWR 位来进行这种协商。最终，结果是相同的，但交换的位数更少。
- en: Thanks to the ECT, CE and ECE, routers can mark packets during congestion and
    receivers can return the congestion information back to the TCP senders. However,
    these three bits are not sufficient to allow a server to reliably send the ECE
    bit to a TCP sender. TCP acknowledgments are not sent reliably. A TCP acknowledgment
    always contains the next expected sequence number. Since TCP acknowledgments are
    cumulative, the loss of one acknowledgment is recovered by the correct reception
    of a subsequent acknowledgment.
  id: totrans-953
  prefs: []
  type: TYPE_NORMAL
  zh: 多亏了 ECT、CE 和 ECE，路由器可以在拥塞期间标记数据包，接收者可以将拥塞信息返回给 TCP 发送者。然而，这三个位不足以允许服务器可靠地将 ECE
    位发送给 TCP 发送者。TCP 确认信息不是可靠发送的。TCP 确认信息总是包含下一个期望的序列号。由于 TCP 确认信息是累积的，一个确认信息的丢失可以通过后续正确接收的确认信息来恢复。
- en: If TCP acknowledgments are overloaded to carry the ECE bit, the situation is
    different. Consider the example shown in the figure below. A client sends packets
    to a server through a router. In the example below, the first packet is marked.
    The server returns an acknowledgment with the ECE bit set. Unfortunately, this
    acknowledgment is lost and never reaches the client. Shortly after, the server
    sends a data segment that also carries a cumulative acknowledgment. This acknowledgment
    confirms the reception of the data to the client, but it did not receive the congestion
    information through the ECE bit.
  id: totrans-954
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 TCP 确认信息超载以携带 ECE 位，情况就不同了。考虑下面图中的示例。一个客户端通过路由器向服务器发送数据包。在下面的示例中，第一个数据包被标记。服务器返回一个设置了
    ECE 位的确认信息。不幸的是，这个确认信息丢失了，并且从未到达客户端。不久之后，服务器发送了一个也携带累积确认信息的数据段。这个确认信息确认了数据已到达客户端，但它没有通过
    ECE 位接收到拥塞信息。
- en: '![msc {'
  id: totrans-955
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![msc {'
- en: client [label="client", linecolour=black],
  id: totrans-956
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 客户端 [标签="客户端", 线颜色=黑色],
- en: router [label="router", linecolour=black],
  id: totrans-957
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 路由器 [标签="路由器", 线颜色=黑色],
- en: server [label="server", linecolour=black];
  id: totrans-958
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 服务器 [标签="server", 线颜色=黑色];
- en: ''
  id: totrans-959
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: client=>router [ label = "data[seq=1,ECT=1,CE=0]", arcskip="1" ];
  id: totrans-960
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 客户端=>路由器 [ 标签 = "数据[seq=1,ECT=1,CE=0]", arcskip="1" ];
- en: router=>server [ label = "data[seq=1,ECT=1,CE=1]", arcskip="1"];
  id: totrans-961
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 路由器=>服务器 [ 标签 = "数据[seq=1,ECT=1,CE=1]", arcskip="1"];
- en: '|||;'
  id: totrans-962
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '|||;'
- en: server=>router [ label = "ack=2,ECE=1", arcskip="1" ];
  id: totrans-963
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 服务器=>路由器 [ 标签 = "ack=2,ECE=1", arcskip="1" ];
- en: router -x client [label="ack=2,ECE=1", arcskip="1" ];
  id: totrans-964
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 路由器配置 -x 客户端 [标签="ack=2,ECE=1", arcskip="1" ];
- en: '|||;'
  id: totrans-965
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '|||;'
- en: server=>router [ label = "data[seq=x,ack=2,ECE=0,ECT=1,CE=0]", arcskip="1" ];
  id: totrans-966
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 服务器=>路由器 [ 标签 = "数据[seq=x,ack=2,ECE=0,ECT=1,CE=0]", arcskip="1" ];
- en: router=>client [ label = "data[seq=x,ack=2,ECE=0,ECT=1,CE=0]", arcskip="1"];
  id: totrans-967
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 路由器=>客户端 [ 标签 = "数据[seq=x,ack=2,ECE=0,ECT=1,CE=0]", arcskip="1"];
- en: '|||;'
  id: totrans-968
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '|||;'
- en: client->server [linecolour=white];
  id: totrans-969
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 客户端->服务器 [线颜色=白色];
- en: '}](../Images/d2ed1589241adeb9e699082587d1916d.png)<map id="700c52eed1dd99ea5abd5216ffd2e044e6fee931"
    name="700c52eed1dd99ea5abd5216ffd2e044e6fee931"></map>'
  id: totrans-970
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '}](../Images/d2ed1589241adeb9e699082587d1916d.png)<map id="700c52eed1dd99ea5abd5216ffd2e044e6fee931"
    name="700c52eed1dd99ea5abd5216ffd2e044e6fee931"></map>'
- en: 'To solve this problem, [**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)
    uses an additional bit in the TCP header : the Congestion Window Reduced (CWR)
    bit.'
  id: totrans-971
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，[**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)
    在 TCP 头部使用了一个额外的位：拥塞窗口减少 (CWR) 位。
- en: '![msc {'
  id: totrans-972
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![msc {'
- en: client [label="client", linecolour=black],
  id: totrans-973
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 客户端 [标签="客户端", 线颜色=黑色],
- en: router [label="router", linecolour=black],
  id: totrans-974
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 路由器 [标签="路由器", 线颜色=黑色],
- en: server [label="server", linecolour=black];
  id: totrans-975
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 服务器 [标签="服务器", 线颜色=黑色];
- en: client=>router [ label = "data[seq=1,ECT=1,CE=0]", arcskip="1" ];
  id: totrans-976
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 客户端=>路由器 [ 标签 = "数据[seq=1,ECT=1,CE=0]", arcskip="1" ];
- en: router=>server [ label = "data[seq=1,ECT=1,CE=1]", arcskip="1"];
  id: totrans-977
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 路由器=>服务器 [ 标签 = "数据[seq=1,ECT=1,CE=1]", arcskip="1"];
- en: '|||;'
  id: totrans-978
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '|||;'
- en: server=>router [ label = "ack=2,ECE=1", arcskip="1" ];
  id: totrans-979
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 服务器=>路由器 [ 标签 = "ack=2,ECE=1", arcskip="1" ];
- en: router -x client [label="ack=2,ECE=1", arcskip="1" ];
  id: totrans-980
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 路由器 -x 客户端 [标签="ack=2,ECE=1", arcskip="1" ];
- en: '|||;'
  id: totrans-981
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '|||;'
- en: server=>router [ label = "data[seq=x,ack=2,ECE=1,ECT=1,CE=0]", arcskip="1" ];
  id: totrans-982
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: server=>router [ label = "data[seq=x,ack=2,ECE=1,ECT=1,CE=0]", arcskip="1" ];
- en: router=>client [ label = "data[seq=x,ack=2,ECE=1,ECT=1,CE=0]", arcskip="1"];
  id: totrans-983
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: router=>client [ label = "data[seq=x,ack=2,ECE=1,ECT=1,CE=0]", arcskip="1"];
- en: '|||;'
  id: totrans-984
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '|||;'
- en: client=>router [ label = "data[seq=1,ECT=1,CE=0,CWR=1]", arcskip="1" ];
  id: totrans-985
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: client=>router [ label = "data[seq=1,ECT=1,CE=0,CWR=1]", arcskip="1" ];
- en: router=>server [ label = "data[seq=1,ECT=1,CE=1,CWR=1]", arcskip="1"];
  id: totrans-986
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: router=>server [ label = "data[seq=1,ECT=1,CE=1,CWR=1]", arcskip="1"];
- en: '|||;'
  id: totrans-987
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '|||;'
- en: client->server [linecolour=white];
  id: totrans-988
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: client->server [linecolour=white];
- en: '}](../Images/36533b7c4d47ba50cac29ebf6ebcc1f1.png)<map id="d60c580a7379dbdd26f90fd2eead54f832ee6ad6"
    name="d60c580a7379dbdd26f90fd2eead54f832ee6ad6"></map>'
  id: totrans-989
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '}](../Images/36533b7c4d47ba50cac29ebf6ebcc1f1.png)<map id="d60c580a7379dbdd26f90fd2eead54f832ee6ad6"
    name="d60c580a7379dbdd26f90fd2eead54f832ee6ad6"></map>'
- en: The CWR bit of the TCP header provides some form of acknowledgment for the ECE
    bit. When a TCP receiver detects a packet marked with the CE bit, it sets the
    ECE bit in all segments that it returns to the sender. Upon reception of an acknowledgment
    with the ECE bit set, the sender reduces its congestion window to reflect a mild
    congestion and sets the CWR bit. This bit remains set as long as the segments
    received contained the ECE bit set. A sender should only react once per round-trip-time
    to marked packets.
  id: totrans-990
  prefs: []
  type: TYPE_NORMAL
  zh: TCP头部的CWR位为ECE位提供了一种形式的确认。当一个TCP接收器检测到一个标记了CE位的包时，它会将其返回给发送者的所有段中的ECE位置位。当收到一个设置了ECE位的确认时，发送器将其拥塞窗口减少以反映轻微的拥塞，并设置CWR位。只要接收到的段中设置了ECE位，此位将保持设置状态。发送器应该只在每个往返时间对标记的包做出一次反应。
- en: 'The last point that needs to be discussed about Explicit Congestion Notification
    is the algorithm that is used by routers to detect congestion. On a router, congestion
    manifests itself by the number of packets that are stored inside the router buffers.
    As explained earlier, we need to distinguish between two types of routers :'
  id: totrans-991
  prefs: []
  type: TYPE_NORMAL
  zh: 关于显式拥塞通知需要讨论的最后一个问题是路由器用来检测拥塞的算法。在路由器上，拥塞通过路由器缓冲区中存储的包的数量来体现。正如之前所解释的，我们需要区分两种类型的路由器：
- en: routers that have a single FIFO queue
  id: totrans-992
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拥有一个单个FIFO队列的路由器
- en: ''
  id: totrans-993
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-994
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: routers that have several queues served by a round-robin scheduler
  id: totrans-995
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由循环调度器服务的多个队列的路由器
- en: Routers that use a single queue measure their buffer occupancy as the number
    of bytes of packets stored in the queue [[10]](#fslot). A first method to detect
    congestion is to measure the instantaneous buffer occupancy and consider the router
    to be congested as soon as this occupancy is above a threshold. Typical values
    of the threshold could be 40% of the total buffer. Measuring the instantaneous
    buffer occupancy is simple since it only requires one counter. However, this value
    is fragile from a control viewpoint since it changes frequently. A better solution
    is to measure the *average* buffer occupancy and consider the router to be congested
    when this average occupancy is too high. Random Early Detection (RED) [[FJ1993]](../bibliography.html#fj1993)
    is an algorithm that was designed to support Explicit Congestion Notification.
    In addition to measuring the average buffer occupancy, it also uses probabilistic
    marking. When the router is congested, the arriving packets are marked with a
    probability that increases with the average buffer occupancy. The main advantage
    of using probabilistic marking instead of marking all arriving packets is that
    flows will be marked in proportion of the number of packets that they transmit.
    If the router marks 10% of the arriving packets when congested, then a large flow
    that sends hundred packets per second will be marked 10 times while a flow that
    only sends one packet per second will not be marked. This probabilistic marking
    allows marking packets in proportion of their usage of the network resources.
  id: totrans-996
  prefs: []
  type: TYPE_NORMAL
  zh: 使用单个队列的路由器将它们的缓冲区占用量测量为队列中存储的数据包字节数 [[10]](#fslot)。检测拥塞的第一种方法是测量瞬时缓冲区占用量，并在占用量超过阈值时立即认为路由器拥塞。阈值的典型值可能是总缓冲区的40%。测量瞬时缓冲区占用量很简单，因为它只需要一个计数器。然而，从控制角度来看，这个值是脆弱的，因为它会频繁变化。一个更好的解决方案是测量*平均*缓冲区占用量，并在平均占用量过高时认为路由器拥塞。随机早期检测（RED）[[FJ1993]](../bibliography.html#fj1993)
    是一种旨在支持显式拥塞通知的算法。除了测量平均缓冲区占用量外，它还使用概率标记。当路由器拥塞时，到达的数据包会以随平均缓冲区占用量增加的概率被标记。与标记所有到达的数据包相比，使用概率标记的主要优点是，流量将被按其传输的数据包数量成比例地标记。如果路由器在拥塞时标记10%的到达数据包，那么每秒发送一百个数据包的大流量将被标记10次，而每秒只发送一个数据包的流量则不会被标记。这种概率标记允许按数据包对网络资源使用的比例进行标记。
- en: If the router uses several queues served by a scheduler, the situation is different.
    If a large and a small flow are competing for bandwidth, the scheduler will already
    favor the small flow that is not using its fair share of the bandwidth. The queue
    for the small flow will be almost empty while the queue for the large flow will
    build up. On routers using such schedulers, a good way of marking the packets
    is to set a threshold on the occupancy of each queue and mark the packets that
    arrive in a particular queue as soon as its occupancy is above the configured
    threshold.
  id: totrans-997
  prefs: []
  type: TYPE_NORMAL
  zh: 如果路由器使用由调度器服务的多个队列，情况就不同了。当大流量和小流量竞争带宽时，调度器会优先考虑未使用其公平份额带宽的小流量。小流量的队列几乎为空，而大流量的队列则会逐渐增加。在采用此类调度器的路由器上，一种标记数据包的好方法是设置每个队列的占用阈值，并在特定队列的占用超过配置阈值时立即标记进入该队列的数据包。
- en: Modeling TCP congestion control[#](#modeling-tcp-congestion-control "Link to
    this heading")
  id: totrans-998
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模型化TCP拥塞控制[#](#modeling-tcp-congestion-control "链接到本标题")
- en: Thanks to its congestion control scheme, TCP adapts its transmission rate to
    the losses that occur in the network. Intuitively, the TCP transmission rate decreases
    when the percentage of losses increases. Researchers have proposed detailed models
    that allow the prediction of the throughput of a TCP connection when losses occur
    [[MSMO1997]](../bibliography.html#msmo1997) . To have some intuition about the
    factors that affect the performance of TCP, let us consider a very simple model.
    Its assumptions are not completely realistic, but it gives us good intuition without
    requiring complex mathematics.
  id: totrans-999
  prefs: []
  type: TYPE_NORMAL
  zh: 多亏了其拥塞控制方案，TCP能够根据网络中发生的损失来调整其传输速率。直观地说，当损失百分比增加时，TCP的传输速率会降低。研究人员已经提出了详细的模型，允许预测TCP连接在发生损失时的吞吐量
    [[MSMO1997]](../bibliography.html#msmo1997)。为了对影响TCP性能的因素有所了解，让我们考虑一个非常简单的模型。它的假设并不完全现实，但它能给我们提供良好的直觉，而不需要复杂的数学。
- en: This model considers a hypothetical TCP connection that suffers from equally
    spaced segment losses. If \(p\) is the segment loss ratio, then the TCP connection
    successfully transfers \(\frac{1}{p}-1\) segments and the next segment is lost.
    If we ignore the slow-start at the beginning of the connection, TCP in this environment
    is always in congestion avoidance as there are only isolated losses that can be
    recovered by using fast retransmit. The evolution of the congestion window is
    thus as shown in the figure below. Note that the x-axis of this figure represents
    time measured in units of one round-trip-time, which is supposed to be constant
    in the model, and the y-axis represents the size of the congestion window measured
    in MSS-sized segments.
  id: totrans-1000
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型考虑了一个假设的TCP连接，该连接遭受均匀间隔的段丢失。如果 \(p\) 是段丢失率，那么TCP连接成功传输 \(\frac{1}{p}-1\)
    个段，下一个段丢失。如果我们忽略连接开始时的慢启动，由于只有可以通过快速重传恢复的孤立丢失，因此在此环境中TCP始终处于拥塞避免状态。因此，拥塞窗口的演变如图所示。请注意，该图的x轴表示以往返时间为单位的测量时间，在模型中应保持恒定，而y轴表示以MSS大小的段为单位的拥塞窗口大小。
- en: '[![../_images/tcp-congestion-regular.png](../Images/aba5ecafe63f482ae07b7a280f8f3275.png)](../_images/tcp-congestion-regular.png)'
  id: totrans-1001
  prefs: []
  type: TYPE_NORMAL
  zh: '[![../_images/tcp-congestion-regular.png](../Images/aba5ecafe63f482ae07b7a280f8f3275.png)](../_images/tcp-congestion-regular.png)'
- en: Fig. 226 Evolution of the congestion window with regular losses[#](#id112 "Link
    to this image")
  id: totrans-1002
  prefs: []
  type: TYPE_NORMAL
  zh: 图226 拥塞窗口在常规丢失下的演变[#](#id112 "链接到这张图片")
- en: 'As the losses are equally spaced, the congestion window always starts at some
    value (\(\frac{W}{2}\)), and is incremented by one MSS every round-trip-time until
    it reaches twice this value (W). At this point, a segment is retransmitted and
    the cycle starts again. If the congestion window is measured in MSS-sized segments,
    a cycle lasts \(\frac{W}{2}\) round-trip-times. The bandwidth of the TCP connection
    is the number of bytes that have been transmitted during a given period of time.
    During a cycle, the number of segments that are sent on the TCP connection is
    equal to the area of the yellow trapeze in the figure. Its area is thus :'
  id: totrans-1003
  prefs: []
  type: TYPE_NORMAL
  zh: 由于丢失是均匀间隔的，拥塞窗口始终从某个值（\(\frac{W}{2}\)）开始，并在每个往返时间内增加一个MSS，直到达到这个值的两倍（W）。此时，一个段被重传，周期再次开始。如果拥塞窗口以MSS大小的段来衡量，一个周期持续
    \(\frac{W}{2}\) 个往返时间。TCP连接的带宽是在给定时间段内已传输的字节数。在一个周期内，TCP连接上发送的段数等于图中黄色梯形的面积。因此，其面积为：
- en: \(area=(\frac{W}{2})^2 + \frac{1}{2} \times (\frac{W}{2})^2 = \frac{3 \times
    W^2}{8}\)
  id: totrans-1004
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: \(面积=(\frac{W}{2})^2 + \frac{1}{2} \times (\frac{W}{2})^2 = \frac{3 \times W^2}{8}\)
- en: 'However, given the regular losses that we consider, the number of segments
    that are sent between two losses (i.e. during a cycle) is by definition equal
    to \(\frac{1}{p}\). Thus, \(W=\sqrt{\frac{8}{3 \times p}}=\frac{k}{\sqrt{p}}\).
    The throughput (in bytes per second) of the TCP connection is equal to the number
    of segments transmitted divided by the duration of the cycle :'
  id: totrans-1005
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，考虑到我们考虑的常规丢失，两个丢失之间的段数（即在周期内）根据定义等于 \(\frac{1}{p}\)。因此，\(W=\sqrt{\frac{8}{3
    \times p}}=\frac{k}{\sqrt{p}}\)。TCP连接的吞吐量（以每秒字节数计）等于传输的段数除以周期的持续时间：
- en: \(Throughput=\frac{area \times MSS}{time} = \frac{ \frac{3 \times W^2}{8}}{\frac{W}{2}
    \times rtt}\) or, after having eliminated W, \(Throughput=\sqrt{\frac{3}{2}} \times
    \frac{MSS}{rtt \times \sqrt{p}}\)
  id: totrans-1006
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: \(Throughput=\frac{面积 \times MSS}{时间} = \frac{ \frac{3 \times W^2}{8}}{\frac{W}{2}
    \times rtt}\) 或者，在消除W之后，\(Throughput=\sqrt{\frac{3}{2}} \times \frac{MSS}{rtt
    \times \sqrt{p}}\)
- en: 'More detailed models and the analysis of simulations have shown that a first
    order model of the TCP throughput when losses occur was \(Throughput \approx \frac{k
    \times MSS}{rtt \times \sqrt{p}}\). This is an important result which shows that
    :'
  id: totrans-1007
  prefs: []
  type: TYPE_NORMAL
  zh: 更详细的模型和模拟分析表明，当发生丢失时，TCP吞吐量的第一阶模型为 \(Throughput \approx \frac{k \times MSS}{rtt
    \times \sqrt{p}}\)。这是一个重要的结果，它表明：
- en: TCP connections with a small round-trip-time can achieve a higher throughput
    than TCP connections having a longer round-trip-time when losses occur. This implies
    that the TCP congestion control scheme is not completely fair since it favors
    the connections that have the shorter round-trip-times.
  id: totrans-1008
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当发生丢失时，具有较短往返时间的TCP连接比具有较长往返时间的TCP连接能实现更高的吞吐量。这表明TCP拥塞控制方案并不完全公平，因为它有利于具有较短的往返时间的连接。
- en: ''
  id: totrans-1009
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1010
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: TCP connections that use a large MSS can achieve a higher throughput that the
    TCP connections that use a shorter MSS. This creates another source of unfairness
    between TCP connections. However, it should be noted that today most hosts are
    using almost the same MSS, roughly 1460 bytes.
  id: totrans-1011
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用较大MSS的TCP连接可以比使用较短MSS的TCP连接实现更高的吞吐量。这为TCP连接之间创造了另一个不公平的来源。然而，应该注意的是，如今大多数主机几乎都使用相同大小的MSS，大约为1460字节。
- en: In general, the maximum throughput that can be achieved by a TCP connection
    depends on its maximum window size and the round-trip-time if there are no losses.
    If there are losses, it depends on the MSS, the round-trip-time and the loss ratio.
  id: totrans-1012
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，在没有损失的情况下，TCP连接能够达到的最大吞吐量取决于其最大窗口大小和往返时间。如果有损失，则取决于MSS、往返时间和损失率。
- en: \(Throughput<\min(\frac{window}{rtt},\frac{k \times MSS}{rtt \times \sqrt{p}})\)
  id: totrans-1013
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: \(Throughput<\min(\frac{window}{rtt},\frac{k \times MSS}{rtt \times \sqrt{p}})\)
- en: Note
  id: totrans-1014
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The TCP congestion control zoo
  id: totrans-1015
  prefs: []
  type: TYPE_NORMAL
  zh: TCP拥塞控制动物园
- en: 'The first TCP congestion control scheme was proposed by [Van Jacobson](https://en.wikipedia.org/wiki/Van_Jacobson)
    in [[Jacobson1988]](../bibliography.html#jacobson1988). In addition to writing
    the scientific paper, [Van Jacobson](https://en.wikipedia.org/wiki/Van_Jacobson)
    also implemented the slow-start and congestion avoidance schemes in release 4.3
    Tahoe of the BSD Unix distributed by the University of Berkeley. Later, he improved
    the congestion control by adding the fast retransmit and the fast recovery mechanisms
    in the Reno release of 4.3 BSD Unix. Since then, many researchers have proposed,
    simulated and implemented modifications to the TCP congestion control scheme.
    Some of these modifications are still used today, e.g. :'
  id: totrans-1016
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个TCP拥塞控制方案是由[Van Jacobson](https://en.wikipedia.org/wiki/Van_Jacobson)提出的
    [[Jacobson1988]](../bibliography.html#jacobson1988)。除了撰写科学论文外，[Van Jacobson](https://en.wikipedia.org/wiki/Van_Jacobson)还在伯克利大学分发的BSD
    Unix的4.3 Tahoe版本中实现了慢启动和拥塞避免方案。后来，他在4.3 BSD Unix的Reno版本中通过添加快速重传和快速恢复机制来改进拥塞控制。从那时起，许多研究人员提出了、模拟并实现了对TCP拥塞控制方案的修改。其中一些修改至今仍在使用，例如：
- en: NewReno ([**RFC 3782**](https://datatracker.ietf.org/doc/html/rfc3782.html)),
    which was proposed as an improvement of the fast recovery mechanism in the Reno
    implementation.
  id: totrans-1017
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: NewReno ([**RFC 3782**](https://datatracker.ietf.org/doc/html/rfc3782.html))，它被提出作为Reno实现中快速恢复机制的改进。
- en: ''
  id: totrans-1018
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1019
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: TCP Vegas, which uses changes in the round-trip-time to estimate congestion
    in order to avoid it [[BOP1994]](../bibliography.html#bop1994). This is one of
    the examples of the delay-based congestion control algorithms. A Vegas sender
    continuously measures the evolution of the round-trip-time and slows down when
    the round-trip-time increases significantly. This enables Vegas to prevent congestion
    when used alone. Unfortunately, if Vegas senders compete with more aggressive
    TCP congestion control schemes that only react to losses, Vegas senders may have
    difficulties to use their fair share of the available bandwidth.
  id: totrans-1020
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: TCP Vegas，它使用往返时间的变化来估计拥塞以避免拥塞 [[BOP1994]](../bibliography.html#bop1994)。这是基于延迟的拥塞控制算法的例子之一。Vegas发送器持续测量往返时间的演变，并在往返时间显著增加时减速。这使得Vegas在单独使用时能够防止拥塞。不幸的是，如果Vegas发送器与仅对损失做出反应的更具侵略性的TCP拥塞控制方案竞争，Vegas发送器可能难以使用其应有的带宽份额。
- en: ''
  id: totrans-1021
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1022
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: CUBIC, which was designed for high bandwidth links and is the default congestion
    control scheme in Linux since the Linux 2.6.19 kernel [[HRX2008]](../bibliography.html#hrx2008).
    It is now used by several operating systems and is becoming the default congestion
    control scheme [**RFC 8312**](https://datatracker.ietf.org/doc/html/rfc8312.html).
    A key difference between CUBIC and the TCP congestion control scheme described
    in this chapter is that CUBIC is much more aggressive when probing the network.
    Instead of relying on additive increase after a fast recovery, a CUBIC sender
    adjusts its congestion by using a cubic function. Thanks to this function, the
    congestion windows grows faster. This is particularly important in high-bandwidth
    delay networks.
  id: totrans-1023
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: CUBIC，它被设计用于高带宽链路，并且自Linux 2.6.19内核以来一直是Linux的默认拥塞控制方案 [[HRX2008]](../bibliography.html#hrx2008)。现在它被几个操作系统使用，并正在成为默认的拥塞控制方案
    [**RFC 8312**](https://datatracker.ietf.org/doc/html/rfc8312.html)。CUBIC与本章中描述的TCP拥塞控制方案的一个关键区别在于，CUBIC在探测网络时更为激进。它不是依赖于快速恢复后的加性增加，而是通过使用立方函数来调整拥塞。多亏了这个函数，拥塞窗口增长得更快。这在高带宽延迟网络中尤为重要。
- en: ''
  id: totrans-1024
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1025
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: BBR, which is being developed by Google researchers and is included in recent
    Linux kernels [[CCG+2016]](../bibliography.html#ccg-2016). BBR periodically estimates
    the available bandwidth and the round-trip-times. To adapt to changes in network
    conditions, BBR regularly tries to send at 1.25 times the current bandwidth. This
    enables BBR senders to probe the network, but can also cause large amount of losses.
    Recent scientific articles indicate that BBR is unfair to other congestion control
    schemes in specific conditions [[WMSS2019]](../bibliography.html#wmss2019).
  id: totrans-1026
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: BBR，由谷歌研究人员开发，并包含在最近的Linux内核中 [[CCG+2016]](../bibliography.html#ccg-2016)。BBR定期估计可用带宽和往返时间。为了适应网络条件的变化，BBR定期尝试以当前带宽的1.25倍发送数据。这使得BBR发送者能够探测网络，但也可能导致大量数据丢失。最近的研究文章表明，在特定条件下，BBR对其他拥塞控制方案是不公平的
    [[WMSS2019]](../bibliography.html#wmss2019)。
- en: A wide range of congestion control schemes have been proposed in the scientific
    literature and several of them have been widely deployed. A detailed comparison
    of these congestion control schemes is outside the scope of this chapter. A recent
    survey paper describing many of the implemented TCP congestion control schemes
    may be found in [[TKU2019]](../bibliography.html#tku2019).
  id: totrans-1027
  prefs: []
  type: TYPE_NORMAL
  zh: 科学文献中已经提出了各种各样的拥塞控制方案，其中一些已经被广泛部署。对这些拥塞控制方案的详细比较超出了本章的范围。一篇最近的研究综述描述了许多已实现的TCP拥塞控制方案，可以在
    [[TKU2019]](../bibliography.html#tku2019) 中找到。
- en: Footnotes
  id: totrans-1028
  prefs: []
  type: TYPE_NORMAL
  zh: 脚注
- en: Footnotes
  id: totrans-1029
  prefs: []
  type: TYPE_NORMAL
  zh: 脚注
- en: Controlling congestion without losing data[#](#controlling-congestion-without-losing-data
    "Link to this heading")
  id: totrans-1030
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 控制拥塞而不丢失数据[#](#controlling-congestion-without-losing-data "链接到这个标题")
- en: In today’s Internet, congestion is controlled by regularly sending packets at
    a higher rate than the network capacity. These packets fill the buffers of the
    routers and are eventually discarded. But shortly after, TCP senders retransmit
    packets containing exactly the same data. This is potentially a waste of resources
    since these successive retransmissions consume resources upstream of the router
    that discards the packets. Packet losses are not the only signal to detect congestion
    inside the network. An alternative is to allow routers to explicitly indicate
    their current level of congestion when forwarding packets. This approach was proposed
    in the late 1980s [[RJ1995]](../bibliography.html#rj1995) and used in some networks.
    Unfortunately, it took almost a decade before the Internet community agreed to
    consider this approach. In the mean time, a large number of TCP implementations
    and routers were deployed on the Internet.
  id: totrans-1031
  prefs: []
  type: TYPE_NORMAL
  zh: 在今天的互联网中，通过定期以高于网络容量的速率发送数据包来控制拥塞。这些数据包填满了路由器的缓冲区，最终被丢弃。但是，在不久之后，TCP发送者会重新发送包含完全相同数据的数据包。这可能导致资源的浪费，因为这些连续的重传消耗了丢弃数据包的路由器上游的资源。数据包丢失并不是检测网络内部拥塞的唯一信号。一种替代方案是允许路由器在转发数据包时明确地指示其当前的拥塞水平。这种方法在20世纪80年代末被提出
    [[RJ1995]](../bibliography.html#rj1995) 并在一些网络中使用。不幸的是，在互联网社区几乎经过十年才同意考虑这种方法。在此期间，大量的TCP实现和路由器被部署在互联网上。
- en: As explained earlier, Explicit Congestion Notification [**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)
    improves the detection of congestion by allowing routers to explicitly mark packets
    when they are lightly congested. In theory, a single bit in the packet header
    [[RJ1995]](../bibliography.html#rj1995) is sufficient to support this congestion
    control scheme. When a host receives a marked packet, it returns the congestion
    information to the source that adapts its transmission rate accordingly. Although
    the idea is relatively simple, deploying it on the entire Internet has proven
    to be challenging [[KNT2013]](../bibliography.html#knt2013). It is interesting
    to analyze the different factors that have hindered the deployment of this technique.
  id: totrans-1032
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，显式拥塞通知 [**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)
    通过允许路由器在数据包轻微拥塞时明确标记数据包来提高拥塞检测。理论上，数据包头部的一个比特 [[RJ1995]](../bibliography.html#rj1995)
    就足以支持这种拥塞控制方案。当一个主机接收到标记的数据包时，它会将拥塞信息返回给源主机，源主机相应地调整其传输速率。尽管这个想法相对简单，但在整个互联网上部署它已被证明是具有挑战性的
    [[KNT2013]](../bibliography.html#knt2013)。分析阻碍这种技术部署的不同因素是很有趣的。
- en: The first difficulty in adding Explicit Congestion Notification (ECN) in TCP/IP
    network was to modify the format of the network packet and transport segment headers
    to carry the required information. In the network layer, one bit was required
    to allow the routers to mark the packets they forward during congestion periods.
    In the IP network layer, this bit is called the Congestion Experienced (CE) bit
    and is part of the packet header. However, using a single bit to mark packets
    is not sufficient. Consider a simple scenario with two sources, one congested
    router and one destination. Assume that the first sender and the destination support
    ECN, but not the second sender. If the router is congested it will mark packets
    from both senders. The first sender will react to the packet markings by reducing
    its transmission rate. However since the second sender does not support ECN, it
    will not react to the markings. Furthermore, this sender could continue to increase
    its transmission rate, which would lead to more packets being marked and the first
    source would decrease again its transmission rate, … In the end, the sources that
    implement ECN are penalized compared to the sources that do not implement it.
    This unfairness issue is a major hurdle to widely deploy ECN on the public Internet
    [[8]](#fprivate). The solution proposed in [**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)
    to deal with this problem is to use a second bit in the network packet header.
    This bit, called the ECN-capable transport (ECT) bit, indicates whether the packet
    contains a segment produced by a transport protocol that supports ECN or not.
    Transport protocols that support ECN set the ECT bit in all packets. When a router
    is congested, it first verifies whether the ECT bit is set. In this case, the
    CE bit of the packet is set to indicate congestion. Otherwise, the packet is discarded.
    This eases the deployment of ECN [[9]](#fecnnonce).
  id: totrans-1033
  prefs: []
  type: TYPE_NORMAL
  zh: 在TCP/IP网络中添加显式拥塞通知（ECN）的第一个困难是修改网络数据包和传输段头的格式以携带所需信息。在网络层，需要一个位允许路由器在拥塞期间标记它们转发的数据包。在IP网络层，这个位被称为拥塞经历（CE）位，是数据包头部的一部分。然而，使用单个位来标记数据包是不够的。考虑一个有两个源、一个拥塞路由器和目标节点的简单场景。假设第一个发送者和目标节点支持ECN，而第二个发送者不支持。如果路由器拥塞，它将标记来自两个发送者的数据包。第一个发送者将通过降低其传输速率来对数据包标记做出反应。然而，由于第二个发送者不支持ECN，它不会对标记做出反应。此外，这个发送者可能会继续增加其传输速率，这将导致更多数据包被标记，而第一个源节点将再次降低其传输速率，……最终，实现ECN的源节点与未实现ECN的源节点相比会受到惩罚。这个不公平问题是在公共互联网上广泛部署ECN的主要障碍[[8](#fprivate)]。在[**RFC
    3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)中提出的解决这个问题的方案是使用网络数据包头部的第二个位。这个位被称为ECN能力传输（ECT）位，表示数据包是否包含由支持ECN的传输协议产生的段。支持ECN的传输协议在所有数据包中设置ECT位。当路由器拥塞时，它首先验证ECT位是否设置。在这种情况下，数据包的CE位被设置为指示拥塞。否则，数据包将被丢弃。这简化了ECN的部署[[9](#fecnnonce)]。
- en: 'The second difficulty is how to allow the receiver to inform the sender of
    the reception of network packets marked with the CE bit. In reliable transport
    protocols like TCP and SCTP, the acknowledgments can be used to provide this feedback.
    For TCP, two options were possible : change some bits in the TCP segment header
    or define a new TCP option to carry this information. The designers of ECN opted
    for reusing spare bits in the TCP header. More precisely, two TCP flags have been
    added in the TCP header to support ECN. The ECN-Echo (ECE) is set in the acknowledgments
    when the CE was set in packets received on the forward path.'
  id: totrans-1034
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个困难是如何让接收方通知发送方已接收带有CE位的网络数据包。在TCP和SCTP等可靠传输协议中，可以通过确认信息提供这种反馈。对于TCP来说，有两种可能的选择：改变TCP段头中的某些位或定义一个新的TCP选项来携带这些信息。ECN的设计者选择了在TCP头中重用空闲位。更确切地说，TCP头中增加了两个标志来支持ECN。当接收到的数据包在正向路径上设置了CE位时，ECN回声（ECE）会在确认信息中设置。
- en: '[![../_images/tcp-enc.svg](../Images/0b92b95f1c0dadde63905a28574e87cb.png)](../_images/tcp-enc.svg)'
  id: totrans-1035
  prefs: []
  type: TYPE_NORMAL
  zh: '![![../_images/tcp-enc.svg](../Images/0b92b95f1c0dadde63905a28574e87cb.png)](../_images/tcp-enc.svg)'
- en: Fig. 225 The TCP flags[#](#id111 "Link to this image")
  id: totrans-1036
  prefs: []
  type: TYPE_NORMAL
  zh: 图225 TCP标志[#](#id111 "链接到这张图片")
- en: The third difficulty is to allow an ECN-capable sender to detect whether the
    remote host also supports ECN. This is a classical negotiation of extensions to
    a transport protocol. In TCP, this could have been solved by defining a new TCP
    option used during the three-way handshake. To avoid wasting space in the TCP
    options, the designers of ECN opted in [**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)
    for using the ECN-Echo and CWR bits in the TCP header to perform this negotiation.
    In the end, the result is the same with fewer bits exchanged.
  id: totrans-1037
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个困难是允许一个ECN（显式拥塞通知）能力的发送者检测远程主机是否也支持ECN。这是一个经典的传输协议扩展的协商。在TCP中，这可以通过在三次握手期间定义一个新的TCP选项来解决。为了避免在TCP选项中浪费空间，ECN的设计者选择了在[**RFC
    3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)中使用TCP头中的ECN-Echo和CWR（拥塞窗口减少）位来进行这种协商。最终，结果是相同的，但交换的位数更少。
- en: Thanks to the ECT, CE and ECE, routers can mark packets during congestion and
    receivers can return the congestion information back to the TCP senders. However,
    these three bits are not sufficient to allow a server to reliably send the ECE
    bit to a TCP sender. TCP acknowledgments are not sent reliably. A TCP acknowledgment
    always contains the next expected sequence number. Since TCP acknowledgments are
    cumulative, the loss of one acknowledgment is recovered by the correct reception
    of a subsequent acknowledgment.
  id: totrans-1038
  prefs: []
  type: TYPE_NORMAL
  zh: 多亏了ECT、CE和ECE，路由器可以在拥塞期间标记数据包，接收者可以将拥塞信息返回给TCP发送者。然而，这三个位不足以允许服务器可靠地将ECE位发送给TCP发送者。TCP确认信息不是可靠发送的。TCP确认信息总是包含下一个期望的序列号。由于TCP确认信息是累积的，一个确认信息的丢失可以通过后续正确接收的确认信息来恢复。
- en: If TCP acknowledgments are overloaded to carry the ECE bit, the situation is
    different. Consider the example shown in the figure below. A client sends packets
    to a server through a router. In the example below, the first packet is marked.
    The server returns an acknowledgment with the ECE bit set. Unfortunately, this
    acknowledgment is lost and never reaches the client. Shortly after, the server
    sends a data segment that also carries a cumulative acknowledgment. This acknowledgment
    confirms the reception of the data to the client, but it did not receive the congestion
    information through the ECE bit.
  id: totrans-1039
  prefs: []
  type: TYPE_NORMAL
  zh: 如果TCP确认信息超载以携带ECE位，情况就不同了。考虑下面图中的示例。一个客户端通过路由器向服务器发送数据包。在下面的示例中，第一个数据包被标记。服务器返回一个设置了ECE位的确认信息。不幸的是，这个确认信息丢失了，并且从未到达客户端。不久之后，服务器发送了一个也携带累积确认信息的数据段。这个确认信息确认了数据已到达客户端，但它没有通过ECE位接收到拥塞信息。
- en: '![msc {'
  id: totrans-1040
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![msc {'
- en: client [label="client", linecolour=black],
  id: totrans-1041
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: client [label="client", linecolour=black],
- en: router [label="router", linecolour=black],
  id: totrans-1042
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: router [label="router", linecolour=black],
- en: server [label="server", linecolour=black];
  id: totrans-1043
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: server [label="server", linecolour=black];
- en: ''
  id: totrans-1044
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: client=>router [ label = "data[seq=1,ECT=1,CE=0]", arcskip="1" ];
  id: totrans-1045
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: client=>router [ label = "data[seq=1,ECT=1,CE=0]", arcskip="1" ];
- en: router=>server [ label = "data[seq=1,ECT=1,CE=1]", arcskip="1"];
  id: totrans-1046
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: router=>server [ label = "data[seq=1,ECT=1,CE=1]", arcskip="1"];
- en: '|||;'
  id: totrans-1047
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '|||;'
- en: server=>router [ label = "ack=2,ECE=1", arcskip="1" ];
  id: totrans-1048
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: server=>router [ label = "ack=2,ECE=1", arcskip="1" ];
- en: router -x client [label="ack=2,ECE=1", arcskip="1" ];
  id: totrans-1049
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: router -x client [label="ack=2,ECE=1", arcskip="1" ];
- en: '|||;'
  id: totrans-1050
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '|||;'
- en: server=>router [ label = "data[seq=x,ack=2,ECE=0,ECT=1,CE=0]", arcskip="1" ];
  id: totrans-1051
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: server=>router [ label = "data[seq=x,ack=2,ECE=0,ECT=1,CE=0]", arcskip="1" ];
- en: router=>client [ label = "data[seq=x,ack=2,ECE=0,ECT=1,CE=0]", arcskip="1"];
  id: totrans-1052
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: router=>client [ label = "data[seq=x,ack=2,ECE=0,ECT=1,CE=0]", arcskip="1"];
- en: '|||;'
  id: totrans-1053
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '|||;'
- en: client->server [linecolour=white];
  id: totrans-1054
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: client->server [linecolour=white];
- en: '}](../Images/d2ed1589241adeb9e699082587d1916d.png)<map id="700c52eed1dd99ea5abd5216ffd2e044e6fee931"
    name="700c52eed1dd99ea5abd5216ffd2e044e6fee931"></map>'
  id: totrans-1055
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '}](../Images/d2ed1589241adeb9e699082587d1916d.png)<map id="700c52eed1dd99ea5abd5216ffd2e044e6fee931"
    name="700c52eed1dd99ea5abd5216ffd2e044e6fee931"></map>'
- en: 'To solve this problem, [**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)
    uses an additional bit in the TCP header : the Congestion Window Reduced (CWR)
    bit.'
  id: totrans-1056
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，[**RFC 3168**](https://datatracker.ietf.org/doc/html/rfc3168.html)在TCP头中使用了额外的位：拥塞窗口减少（CWR）位。
- en: '![msc {'
  id: totrans-1057
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![msc {'
- en: client [label="client", linecolour=black],
  id: totrans-1058
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: client [label="client", linecolour=black],
- en: router [label="router", linecolour=black],
  id: totrans-1059
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: router [label="router", linecolour=black],
- en: server [label="server", linecolour=black];
  id: totrans-1060
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: server [label="server", linecolour=black];
- en: client=>router [ label = "data[seq=1,ECT=1,CE=0]", arcskip="1" ];
  id: totrans-1061
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: client=>router [ label = "data[seq=1,ECT=1,CE=0]", arcskip="1" ];
- en: router=>server [ label = "data[seq=1,ECT=1,CE=1]", arcskip="1"];
  id: totrans-1062
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: router=>server [ label = "data[seq=1,ECT=1,CE=1]", arcskip="1"];
- en: '|||;'
  id: totrans-1063
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '|||;'
- en: server=>router [ label = "ack=2,ECE=1", arcskip="1" ];
  id: totrans-1064
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: server=>router [ label = "ack=2,ECE=1", arcskip="1" ];
- en: router -x client [label="ack=2,ECE=1", arcskip="1" ];
  id: totrans-1065
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: router -x client [label="ack=2,ECE=1", arcskip="1" ];
- en: '|||;'
  id: totrans-1066
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '|||;'
- en: server=>router [ label = "data[seq=x,ack=2,ECE=1,ECT=1,CE=0]", arcskip="1" ];
  id: totrans-1067
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 服务器=>路由器 [标签 = "data[seq=x,ack=2,ECE=1,ECT=1,CE=0]", arcskip="1" ];
- en: router=>client [ label = "data[seq=x,ack=2,ECE=1,ECT=1,CE=0]", arcskip="1"];
  id: totrans-1068
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 路由器=>客户端 [标签 = "data[seq=x,ack=2,ECE=1,ECT=1,CE=0]", arcskip="1"];
- en: '|||;'
  id: totrans-1069
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '|||;'
- en: client=>router [ label = "data[seq=1,ECT=1,CE=0,CWR=1]", arcskip="1" ];
  id: totrans-1070
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 客户端=>路由器 [标签 = "data[seq=1,ECT=1,CE=0,CWR=1]", arcskip="1" ];
- en: router=>server [ label = "data[seq=1,ECT=1,CE=1,CWR=1]", arcskip="1"];
  id: totrans-1071
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 路由器=>服务器 [标签 = "data[seq=1,ECT=1,CE=1,CWR=1]", arcskip="1"];
- en: '|||;'
  id: totrans-1072
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '|||;'
- en: client->server [linecolour=white];
  id: totrans-1073
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 客户端->服务器 [线路颜色=白色];
- en: '}](../Images/36533b7c4d47ba50cac29ebf6ebcc1f1.png)<map id="d60c580a7379dbdd26f90fd2eead54f832ee6ad6"
    name="d60c580a7379dbdd26f90fd2eead54f832ee6ad6"></map>'
  id: totrans-1074
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '}](../Images/36533b7c4d47ba50cac29ebf6ebcc1f1.png)<map id="d60c580a7379dbdd26f90fd2eead54f832ee6ad6"
    name="d60c580a7379dbdd26f90fd2eead54f832ee6ad6"></map>'
- en: The CWR bit of the TCP header provides some form of acknowledgment for the ECE
    bit. When a TCP receiver detects a packet marked with the CE bit, it sets the
    ECE bit in all segments that it returns to the sender. Upon reception of an acknowledgment
    with the ECE bit set, the sender reduces its congestion window to reflect a mild
    congestion and sets the CWR bit. This bit remains set as long as the segments
    received contained the ECE bit set. A sender should only react once per round-trip-time
    to marked packets.
  id: totrans-1075
  prefs: []
  type: TYPE_NORMAL
  zh: TCP头部中的CWR位为ECE位提供了一种确认形式。当TCP接收方检测到标记了CE位的分组时，它会将其返回给发送方的所有段中的ECE位置位。当收到ECE位已置位的确认后，发送方将其拥塞窗口减小以反映轻微的拥塞，并设置CWR位。只要接收到的段包含已置位的ECE位，此位将保持置位状态。发送方应仅在往返时间内对标记的分组做出一次反应。
- en: 'The last point that needs to be discussed about Explicit Congestion Notification
    is the algorithm that is used by routers to detect congestion. On a router, congestion
    manifests itself by the number of packets that are stored inside the router buffers.
    As explained earlier, we need to distinguish between two types of routers :'
  id: totrans-1076
  prefs: []
  type: TYPE_NORMAL
  zh: 需要讨论的最后一个关于显式拥塞通知的问题是路由器用于检测拥塞的算法。在路由器上，拥塞通过路由器缓冲区中存储的分组数量来体现。如前所述，我们需要区分两种类型的路由器：
- en: routers that have a single FIFO queue
  id: totrans-1077
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只有一个FIFO队列的路由器
- en: ''
  id: totrans-1078
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1079
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: routers that have several queues served by a round-robin scheduler
  id: totrans-1080
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由轮询调度器服务的多个队列的路由器
- en: Routers that use a single queue measure their buffer occupancy as the number
    of bytes of packets stored in the queue [[10]](#fslot). A first method to detect
    congestion is to measure the instantaneous buffer occupancy and consider the router
    to be congested as soon as this occupancy is above a threshold. Typical values
    of the threshold could be 40% of the total buffer. Measuring the instantaneous
    buffer occupancy is simple since it only requires one counter. However, this value
    is fragile from a control viewpoint since it changes frequently. A better solution
    is to measure the *average* buffer occupancy and consider the router to be congested
    when this average occupancy is too high. Random Early Detection (RED) [[FJ1993]](../bibliography.html#fj1993)
    is an algorithm that was designed to support Explicit Congestion Notification.
    In addition to measuring the average buffer occupancy, it also uses probabilistic
    marking. When the router is congested, the arriving packets are marked with a
    probability that increases with the average buffer occupancy. The main advantage
    of using probabilistic marking instead of marking all arriving packets is that
    flows will be marked in proportion of the number of packets that they transmit.
    If the router marks 10% of the arriving packets when congested, then a large flow
    that sends hundred packets per second will be marked 10 times while a flow that
    only sends one packet per second will not be marked. This probabilistic marking
    allows marking packets in proportion of their usage of the network resources.
  id: totrans-1081
  prefs: []
  type: TYPE_NORMAL
  zh: 使用单个队列的路由器将它们的缓冲区占用量测量为队列中存储的数据包字节数 [[10]](#fslot)。检测拥塞的一种方法是测量瞬时缓冲区占用量，并在占用量超过阈值时认为路由器处于拥塞状态。阈值的典型值可能是总缓冲区的40%。测量瞬时缓冲区占用量很简单，因为它只需要一个计数器。然而，从控制角度来看，这个值是脆弱的，因为它会频繁变化。一个更好的解决方案是测量*平均*缓冲区占用量，并在平均占用量过高时认为路由器处于拥塞状态。随机早期检测（RED）[[FJ1993]](../bibliography.html#fj1993)
    是一种旨在支持显式拥塞通知的算法。除了测量平均缓冲区占用量外，它还使用概率标记。当路由器拥塞时，到达的数据包会以随平均缓冲区占用量增加的概率被标记。使用概率标记而不是标记所有到达数据包的主要优点是，流量将被按其传输的数据包数量成比例标记。如果路由器在拥塞时标记了10%的到达数据包，那么每秒发送一百个数据包的大流量将被标记10次，而每秒只发送一个数据包的流量则不会被标记。这种概率标记允许按数据包对网络资源的使用比例进行标记。
- en: If the router uses several queues served by a scheduler, the situation is different.
    If a large and a small flow are competing for bandwidth, the scheduler will already
    favor the small flow that is not using its fair share of the bandwidth. The queue
    for the small flow will be almost empty while the queue for the large flow will
    build up. On routers using such schedulers, a good way of marking the packets
    is to set a threshold on the occupancy of each queue and mark the packets that
    arrive in a particular queue as soon as its occupancy is above the configured
    threshold.
  id: totrans-1082
  prefs: []
  type: TYPE_NORMAL
  zh: 如果路由器使用由调度器服务的多个队列，情况就不同了。当大流量和小流量竞争带宽时，调度器会优先考虑未使用其公平份额带宽的小流量。小流量的队列几乎为空，而大流量的队列则会逐渐增加。在采用此类调度器的路由器上，一种标记数据包的好方法是设置每个队列的占用阈值，并在特定队列的占用超过配置阈值时立即标记进入该队列的数据包。
- en: Modeling TCP congestion control[#](#modeling-tcp-congestion-control "Link to
    this heading")
  id: totrans-1083
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模型化TCP拥塞控制[#](#modeling-tcp-congestion-control "链接到本标题")
- en: Thanks to its congestion control scheme, TCP adapts its transmission rate to
    the losses that occur in the network. Intuitively, the TCP transmission rate decreases
    when the percentage of losses increases. Researchers have proposed detailed models
    that allow the prediction of the throughput of a TCP connection when losses occur
    [[MSMO1997]](../bibliography.html#msmo1997) . To have some intuition about the
    factors that affect the performance of TCP, let us consider a very simple model.
    Its assumptions are not completely realistic, but it gives us good intuition without
    requiring complex mathematics.
  id: totrans-1084
  prefs: []
  type: TYPE_NORMAL
  zh: 多亏了其拥塞控制方案，TCP能够根据网络中发生的损失调整其传输速率。直观地说，当损失百分比增加时，TCP的传输速率会降低。研究人员已经提出了详细的模型，可以预测TCP连接在发生损失时的吞吐量
    [[MSMO1997]](../bibliography.html#msmo1997) 。为了对影响TCP性能的因素有所了解，让我们考虑一个非常简单的模型。它的假设并不完全现实，但它能给我们提供良好的直觉，而不需要复杂的数学。
- en: This model considers a hypothetical TCP connection that suffers from equally
    spaced segment losses. If \(p\) is the segment loss ratio, then the TCP connection
    successfully transfers \(\frac{1}{p}-1\) segments and the next segment is lost.
    If we ignore the slow-start at the beginning of the connection, TCP in this environment
    is always in congestion avoidance as there are only isolated losses that can be
    recovered by using fast retransmit. The evolution of the congestion window is
    thus as shown in the figure below. Note that the x-axis of this figure represents
    time measured in units of one round-trip-time, which is supposed to be constant
    in the model, and the y-axis represents the size of the congestion window measured
    in MSS-sized segments.
  id: totrans-1085
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型考虑了一个假设的TCP连接，该连接遭受均匀分布的段丢失。如果 \(p\) 是段丢失率，那么TCP连接成功传输 \(\frac{1}{p}-1\)
    个段，下一个段丢失。如果我们忽略连接开始时的慢启动，在此环境中TCP总是处于拥塞避免状态，因为只有可以通过快速重传恢复的孤立丢包。因此，拥塞窗口的演变如图所示。请注意，此图的x轴表示以一个往返时间为单位的测量时间，在模型中假设是恒定的，y轴表示以MSS大小的段来衡量的拥塞窗口的大小。
- en: '[![../_images/tcp-congestion-regular.png](../Images/aba5ecafe63f482ae07b7a280f8f3275.png)](../_images/tcp-congestion-regular.png)'
  id: totrans-1086
  prefs: []
  type: TYPE_NORMAL
  zh: '![../_images/tcp-congestion-regular.png](../Images/aba5ecafe63f482ae07b7a280f8f3275.png)'
- en: Fig. 226 Evolution of the congestion window with regular losses[#](#id112 "Link
    to this image")
  id: totrans-1087
  prefs: []
  type: TYPE_NORMAL
  zh: 图226：常规丢包下拥塞窗口的演变[#](#id112 "链接到此图像")
- en: 'As the losses are equally spaced, the congestion window always starts at some
    value (\(\frac{W}{2}\)), and is incremented by one MSS every round-trip-time until
    it reaches twice this value (W). At this point, a segment is retransmitted and
    the cycle starts again. If the congestion window is measured in MSS-sized segments,
    a cycle lasts \(\frac{W}{2}\) round-trip-times. The bandwidth of the TCP connection
    is the number of bytes that have been transmitted during a given period of time.
    During a cycle, the number of segments that are sent on the TCP connection is
    equal to the area of the yellow trapeze in the figure. Its area is thus :'
  id: totrans-1088
  prefs: []
  type: TYPE_NORMAL
  zh: 由于丢包均匀分布，拥塞窗口始终从某个值（\(\frac{W}{2}\)）开始，并在每个往返时间增加一个MSS，直到达到这个值的两倍（W）。此时，一个段被重传，周期重新开始。如果拥塞窗口以MSS大小的段来衡量，一个周期持续
    \(\frac{W}{2}\) 个往返时间。TCP连接的带宽是在给定时间段内已传输的字节数。在一个周期内，TCP连接上发送的段数等于图中黄色梯形的面积。因此，其面积为：
- en: \(area=(\frac{W}{2})^2 + \frac{1}{2} \times (\frac{W}{2})^2 = \frac{3 \times
    W^2}{8}\)
  id: totrans-1089
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: \(area=(\frac{W}{2})^2 + \frac{1}{2} \times (\frac{W}{2})^2 = \frac{3 \times
    W^2}{8}\)
- en: 'However, given the regular losses that we consider, the number of segments
    that are sent between two losses (i.e. during a cycle) is by definition equal
    to \(\frac{1}{p}\). Thus, \(W=\sqrt{\frac{8}{3 \times p}}=\frac{k}{\sqrt{p}}\).
    The throughput (in bytes per second) of the TCP connection is equal to the number
    of segments transmitted divided by the duration of the cycle :'
  id: totrans-1090
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，考虑到我们考虑的常规丢包，两个丢包之间发送的段数（即在周期内）根据定义等于 \(\frac{1}{p}\)。因此，\(W=\sqrt{\frac{8}{3
    \times p}}=\frac{k}{\sqrt{p}}\)。TCP连接的吞吐量（以每秒字节数计）等于传输的段数除以周期的持续时间：
- en: \(Throughput=\frac{area \times MSS}{time} = \frac{ \frac{3 \times W^2}{8}}{\frac{W}{2}
    \times rtt}\) or, after having eliminated W, \(Throughput=\sqrt{\frac{3}{2}} \times
    \frac{MSS}{rtt \times \sqrt{p}}\)
  id: totrans-1091
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: \(Throughput=\frac{area \times MSS}{time} = \frac{ \frac{3 \times W^2}{8}}{\frac{W}{2}
    \times rtt}\) 或，在消除W之后，\(Throughput=\sqrt{\frac{3}{2}} \times \frac{MSS}{rtt \times
    \sqrt{p}}\)
- en: 'More detailed models and the analysis of simulations have shown that a first
    order model of the TCP throughput when losses occur was \(Throughput \approx \frac{k
    \times MSS}{rtt \times \sqrt{p}}\). This is an important result which shows that
    :'
  id: totrans-1092
  prefs: []
  type: TYPE_NORMAL
  zh: 更详细的模型和模拟分析表明，当发生丢包时，TCP吞吐量的首阶模型为 \(Throughput \approx \frac{k \times MSS}{rtt
    \times \sqrt{p}}\)。这是一个重要的结果，它表明：
- en: TCP connections with a small round-trip-time can achieve a higher throughput
    than TCP connections having a longer round-trip-time when losses occur. This implies
    that the TCP congestion control scheme is not completely fair since it favors
    the connections that have the shorter round-trip-times.
  id: totrans-1093
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当发生丢包时，具有较短往返时间的TCP连接比具有较长往返时间的TCP连接能实现更高的吞吐量。这意味着TCP拥塞控制方案并不完全公平，因为它有利于具有较短往返时间的连接。
- en: ''
  id: totrans-1094
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1095
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: TCP connections that use a large MSS can achieve a higher throughput that the
    TCP connections that use a shorter MSS. This creates another source of unfairness
    between TCP connections. However, it should be noted that today most hosts are
    using almost the same MSS, roughly 1460 bytes.
  id: totrans-1096
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用较大MSS的TCP连接可以比使用较短MSS的TCP连接实现更高的吞吐量。这为TCP连接之间创造了另一个不公平的来源。然而，需要注意的是，如今大多数主机几乎都使用相同大小的MSS，大约为1460字节。
- en: In general, the maximum throughput that can be achieved by a TCP connection
    depends on its maximum window size and the round-trip-time if there are no losses.
    If there are losses, it depends on the MSS, the round-trip-time and the loss ratio.
  id: totrans-1097
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，TCP连接能够达到的最大吞吐量取决于其最大窗口大小和往返时间，在没有丢包的情况下。如果有丢包，则取决于MSS、往返时间和丢包率。
- en: \(Throughput<\min(\frac{window}{rtt},\frac{k \times MSS}{rtt \times \sqrt{p}})\)
  id: totrans-1098
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: \(Throughput<\min(\frac{window}{rtt},\frac{k \times MSS}{rtt \times \sqrt{p}})\)
- en: Note
  id: totrans-1099
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The TCP congestion control zoo
  id: totrans-1100
  prefs: []
  type: TYPE_NORMAL
  zh: TCP拥塞控制动物园
- en: 'The first TCP congestion control scheme was proposed by [Van Jacobson](https://en.wikipedia.org/wiki/Van_Jacobson)
    in [[Jacobson1988]](../bibliography.html#jacobson1988). In addition to writing
    the scientific paper, [Van Jacobson](https://en.wikipedia.org/wiki/Van_Jacobson)
    also implemented the slow-start and congestion avoidance schemes in release 4.3
    Tahoe of the BSD Unix distributed by the University of Berkeley. Later, he improved
    the congestion control by adding the fast retransmit and the fast recovery mechanisms
    in the Reno release of 4.3 BSD Unix. Since then, many researchers have proposed,
    simulated and implemented modifications to the TCP congestion control scheme.
    Some of these modifications are still used today, e.g. :'
  id: totrans-1101
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个TCP拥塞控制方案是由[Van Jacobson](https://en.wikipedia.org/wiki/Van_Jacobson)提出的
    [[Jacobson1988]](../bibliography.html#jacobson1988)。除了撰写科学论文外，[Van Jacobson](https://en.wikipedia.org/wiki/Van_Jacobson)还在伯克利大学分发的BSD
    Unix的4.3 Tahoe版本中实现了慢启动和拥塞避免方案。后来，他在4.3 BSD Unix的Reno版本中通过添加快速重传和快速恢复机制来改进拥塞控制。从那时起，许多研究人员提出了、模拟了并实现了对TCP拥塞控制方案的修改。其中一些修改至今仍在使用，例如：
- en: NewReno ([**RFC 3782**](https://datatracker.ietf.org/doc/html/rfc3782.html)),
    which was proposed as an improvement of the fast recovery mechanism in the Reno
    implementation.
  id: totrans-1102
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: NewReno（[**RFC 3782**](https://datatracker.ietf.org/doc/html/rfc3782.html)），它被提出作为Reno实现中快速恢复机制的改进。
- en: ''
  id: totrans-1103
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1104
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: TCP Vegas, which uses changes in the round-trip-time to estimate congestion
    in order to avoid it [[BOP1994]](../bibliography.html#bop1994). This is one of
    the examples of the delay-based congestion control algorithms. A Vegas sender
    continuously measures the evolution of the round-trip-time and slows down when
    the round-trip-time increases significantly. This enables Vegas to prevent congestion
    when used alone. Unfortunately, if Vegas senders compete with more aggressive
    TCP congestion control schemes that only react to losses, Vegas senders may have
    difficulties to use their fair share of the available bandwidth.
  id: totrans-1105
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: TCP Vegas，它使用往返时间的变化来估计拥塞，以避免拥塞 [[BOP1994]](../bibliography.html#bop1994)。这是基于延迟的拥塞控制算法的例子之一。Vegas发送器持续测量往返时间的演变，并在往返时间显著增加时减速。这使得Vegas在单独使用时能够防止拥塞。不幸的是，如果Vegas发送器与仅对丢包做出反应的更具侵略性的TCP拥塞控制方案竞争，Vegas发送器可能难以使用其应有的带宽份额。
- en: ''
  id: totrans-1106
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1107
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: CUBIC, which was designed for high bandwidth links and is the default congestion
    control scheme in Linux since the Linux 2.6.19 kernel [[HRX2008]](../bibliography.html#hrx2008).
    It is now used by several operating systems and is becoming the default congestion
    control scheme [**RFC 8312**](https://datatracker.ietf.org/doc/html/rfc8312.html).
    A key difference between CUBIC and the TCP congestion control scheme described
    in this chapter is that CUBIC is much more aggressive when probing the network.
    Instead of relying on additive increase after a fast recovery, a CUBIC sender
    adjusts its congestion by using a cubic function. Thanks to this function, the
    congestion windows grows faster. This is particularly important in high-bandwidth
    delay networks.
  id: totrans-1108
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: CUBIC，它被设计用于高带宽链路，并且自Linux 2.6.19内核以来成为Linux的默认拥塞控制方案 [[HRX2008]](../bibliography.html#hrx2008)。现在它被几个操作系统使用，并正在成为默认的拥塞控制方案
    [**RFC 8312**](https://datatracker.ietf.org/doc/html/rfc8312.html)。CUBIC与本章中描述的TCP拥塞控制方案的一个关键区别在于，CUBIC在探测网络时更为激进。它不是在快速恢复后依赖于增量增加，而是通过使用立方函数来调整拥塞。多亏了这个函数，拥塞窗口增长得更快。这在高带宽延迟网络中尤为重要。
- en: ''
  id: totrans-1109
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-1110
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: BBR, which is being developed by Google researchers and is included in recent
    Linux kernels [[CCG+2016]](../bibliography.html#ccg-2016). BBR periodically estimates
    the available bandwidth and the round-trip-times. To adapt to changes in network
    conditions, BBR regularly tries to send at 1.25 times the current bandwidth. This
    enables BBR senders to probe the network, but can also cause large amount of losses.
    Recent scientific articles indicate that BBR is unfair to other congestion control
    schemes in specific conditions [[WMSS2019]](../bibliography.html#wmss2019).
  id: totrans-1111
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: BBR，由谷歌研究人员开发，并包含在最近的Linux内核中[[CCG+2016]](../bibliography.html#ccg-2016)。BBR定期估计可用带宽和往返时间。为了适应网络条件的变化，BBR定期尝试以当前带宽的1.25倍发送数据。这使得BBR发送者能够探测网络，但也可能导致大量损失。最近的研究文章表明，在特定条件下，BBR对其他拥塞控制方案是不公平的[[WMSS2019]](../bibliography.html#wmss2019)。
- en: A wide range of congestion control schemes have been proposed in the scientific
    literature and several of them have been widely deployed. A detailed comparison
    of these congestion control schemes is outside the scope of this chapter. A recent
    survey paper describing many of the implemented TCP congestion control schemes
    may be found in [[TKU2019]](../bibliography.html#tku2019).
  id: totrans-1112
  prefs: []
  type: TYPE_NORMAL
  zh: 在科学文献中已经提出了多种拥塞控制方案，其中一些已经被广泛部署。对这些拥塞控制方案的详细比较超出了本章的范围。一篇最近的研究综述论文描述了许多已实现的TCP拥塞控制方案，可以在[[TKU2019]](../bibliography.html#tku2019)中找到。
- en: Footnotes
  id: totrans-1113
  prefs: []
  type: TYPE_NORMAL
  zh: 脚注
- en: Footnotes
  id: totrans-1114
  prefs: []
  type: TYPE_NORMAL
  zh: 脚注
