# 可量测性

> 原文:[https://LinkedIn . github . io/school-of-sre/level 101/systems _ design/scalability/](https://linkedin.github.io/school-of-sre/level101/systems_design/scalability/)

可伸缩性对一个系统/服务意味着什么？一个系统由服务/组件组成，每个服务/组件的可伸缩性需要单独处理，而系统的可伸缩性作为一个整体。

如果随着资源被添加到系统中，服务的性能以与添加的资源成比例的方式提高，则称该服务是可伸缩的

如果添加资源以促进冗余不会导致性能损失，则称永远在线服务是可伸缩的

## 参考

*   [https://www . all things distributed . com/2006/03/a _ word _ on _ scalability . html](https://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html)

## 可扩展性- AKF 规模的立方体

[Scale Cube](https://akfpartners.com/growth-blog/scale-cube) 是一个用于细分服务、定义微服务和扩展产品的模型。它还为团队在设计解决方案时讨论与规模相关的选项创造了一种通用语言。下一节根据我们对 AKF 立方体的推断来讨论某些扩展模式

## 可扩展性-水平扩展

水平伸缩代表应用程序或服务的克隆，这样工作就可以毫无偏见地轻松分配到不同的实例中。

让我们看看我们的单片应用程序如何利用这一原则进行改进

![Horizontal Scaling](../Images/7a889526d0403c1e0799eecb7c91a1cc.png)

这里，DB 与应用程序分开缩放。这是为了让您知道每个组件的扩展能力可能是不同的。通常，web 应用程序可以通过添加资源来扩展，除非应用程序中存储了状态。但是，通过添加更多的跟随者，数据库只能针对读取进行扩展，但写入必须只针对一个领导者，以确保数据的一致性。有一些数据库支持多领导写，但我们在这一点上把它们排除在范围之外。

应用程序应该能够区分读取和写入，以选择合适的数据库服务器。负载平衡器可以透明地在相同的服务器之间分割流量。

**什么:**复制服务或数据库以分散事务负载。

**何时使用:**读写比率非常高的数据库(5:1 或更高—越高越好)。因为只能缩放数据库的读取副本，而不能缩放主数据库。

**使用方法:**简单地克隆服务，实现一个负载均衡器。对于数据库，确保访问代码理解读和写之间的区别。

**原因:**允许以复制数据和功能为代价快速扩展交易。

**关键要点:**这实现起来很快，从开发人员的角度来看成本很低，并且可以很好地扩展交易量。但是，从数据运营成本的角度来看，它们往往成本较高。这里的成本意味着，如果我们有 3 个追随者和 1 个领导者数据库，相同的数据库将作为 4 个副本存储在 4 个服务器。因此增加了存储成本

### 参考

*   [https://learning . oreilly . com/library/view/the-art-of/9780134031408/ch23 . html](https://learning.oreilly.com/library/view/the-art-of/9780134031408/ch23.html)

### 可伸缩性模式-负载平衡

改善多种计算资源(如计算机、计算机集群、网络链接、中央处理器或磁盘驱动器)之间的工作负载分配。一种常用的技术是在相同的服务器集群之间负载平衡流量。类似的原理被用于通过 [ECMP](https://en.wikipedia.org/wiki/Equal-cost_multi-path_routing) ，磁盘驱动器通过 [RAID](https://en.wikipedia.org/wiki/RAID) 等来平衡网络链路上的流量

旨在优化资源使用，最大化吞吐量，最小化响应时间，并避免任何单个资源过载。使用具有负载平衡的多个组件而不是单个组件可以通过冗余提高可靠性和可用性。在我们更新的架构图中，我们有 4 台服务器来处理应用流量，而不是一台服务器

执行负载平衡的设备或系统称为负载平衡器，缩写为 LB。

#### 参考

*   [https://en . Wikipedia . org/wiki/Load _ balancing _(计算)](https://en.wikipedia.org/wiki/Load_balancing_(computing))
*   [https://blog . envoy proxy . io/introduction-to-modern-network-load-balancing-and-proxy-a57f 6 ff 80236](https://blog.envoyproxy.io/introduction-to-modern-network-load-balancing-and-proxying-a57f6ff80236)
*   [https://learning . oreilly . com/library/view/load-balancing-in/9781492038009/](https://learning.oreilly.com/library/view/load-balancing-in/9781492038009/)
*   [https://learning . oreilly . com/library/view/practical-load-balancing/9781430236801/](https://learning.oreilly.com/library/view/practical-load-balancing/9781430236801/)
*   [http://shop.oreilly.com/product/9780596000509.do](http://shop.oreilly.com/product/9780596000509.do)

### 可伸缩性模式- LB 任务

LB 是做什么的？

#### 服务发现:

系统中有哪些后端可用？在我们的架构中，有 4 台服务器可用于服务应用流量。LB 充当单个端点，客户端可以透明地使用它来访问 4 个服务器中的一个。

#### 健康检查:

哪些后端目前是健康的，可以接受请求？如果 4 个应用服务器中有一个坏了，LB 会自动缩短路径，这样客户端就不会感觉到任何应用宕机

#### 负载平衡:

应该使用什么算法来平衡健康后端的各个请求？有许多算法可以在四台服务器之间分配流量。基于观察/经验，SRE 可以选择适合他们模式的算法

### 可伸缩性模式- LB 方法

常见的负载平衡方法

#### 最少联系方法

将流量定向到活动连接最少的服务器。当在服务器之间不均匀分布的流量中有大量持久连接时最有用。如果客户端保持长期连接，则有效

#### 最短响应时间法

将流量定向到具有最少活动连接和最低平均响应时间的服务器。这里，响应时间用于提供服务器健康状况的反馈

#### 循环法

通过将流量定向到第一个可用的服务器来轮换服务器，然后将该服务器移动到队列的底部。当服务器规格相同并且没有很多持久连接时最有用。

#### IP 哈希

客户端的 IP 地址决定了哪个服务器接收请求。这有时会导致分布偏斜，但如果应用程序在本地存储一些状态并需要一些粘性，这是有用的

更高级的客户端/服务器端示例技术-https://docs.nginx.com/nginx/admin-guide/load-balancer/-http://cbonte.github.io/haproxy-dconv/2.2/intro.html#3.3.5-https://Twitter . github . io/finagle/guide/clients . html #负载平衡

### 可扩展性模式-缓存-内容交付网络(CDN)

cdn 被添加到离客户位置更近的地方。如果应用程序有静态数据，如图像、Javascript、CSS，它们不会经常改变，它们可以被缓存。由于我们的例子是一个内容共享网站，静态内容可以缓存在 cdn 中，并有一个合适的有效期。

![CDN block diagram](../Images/ce5239929685874e2714df3a1f606581.png)

**什么:**使用 cdn(内容交付网络)来减少你网站的流量。

**何时使用:**当速度提高和规模保证额外成本时。

**如何使用:**大多数 cdn 利用 DNs 为您的网站提供内容。因此，您可能需要对 DNS 进行微小的更改或添加，并将内容从新的子域名转移到其他域名。

media-exp1.licdn.com 是 Linkedin 用来提供静态内容的一个域名

这里，CNAME 将域指向 CDN 提供商的 DNS

挖 media-exp1.licdn.com+做空

2-01-2c3e-005c.cdx .雪松. net。

**原因:**cdn 有助于减轻流量高峰，通常是扩展网站部分流量的经济方式。它们通常还会大大缩短页面下载时间。

**要点:**cdn 是一种快速、简单的方法，可以抵消流量峰值和总体流量增长。确保执行成本效益分析并监控 CDN 的使用情况。如果 CDN 有很多缓存未命中，那么我们不会从 CDN 中获得太多，并且仍然使用我们的计算资源来服务请求。

## 可扩展性-微服务

这种模式代表了应用程序中服务或功能的工作分离。微服务旨在解决与代码库和数据集中的增长和复杂性相关的问题。目的是创建故障隔离并减少响应时间。

微服务可以扩展事务、数据大小和代码库大小。它们在扩展代码库的规模和复杂性方面最为有效。因为工程团队需要重写服务，或者至少需要将服务从最初的单一应用程序中分离出来，所以它们的成本往往比水平扩展要高一些。

![Microservices block diagram](../Images/cc71a1d7ea3b511b252d6a56bfc8f3ff.png)

**WHAT:** 该规则有时被称为通过服务或资源进行扩展，它侧重于通过沿着动词(服务)或名词(资源)的边界划分数据集、事务和工程团队来进行扩展。

**何时使用:**不需要数据间关系的超大型数据集。大型复杂系统，其中扩展工程资源需要专业化。

如何使用:用动词拆分动作，用名词拆分资源，或者混合使用。按照动词/名词方法定义的路线来划分服务和数据。

**原因:**不仅允许高效扩展事务，还允许扩展与这些事务相关的超大型数据集。它还允许团队的有效扩展。

**要点:**微服务支持高效扩展事务、大型数据集，并有助于故障隔离。它有助于减少团队的通信开销。代码库变得不那么复杂，因为不相交的功能被解耦并作为新的服务旋转，从而让每个服务根据其需求独立扩展。

### 参考

*   https://learning.oreilly.com/library/view/the-art-of/9780134031408/ch23.html

## 可伸缩性-分片

该模式表示基于在事务时查找或确定的属性的工作分离。最常见的是，这些被实现为由请求者、顾客或客户进行的分割。

通常，需要为这些类型的拆分编写查找服务或确定性算法。

分片有助于扩展事务增长、扩展指令集和减少处理时间(最后一点是通过限制执行任何事务所需的数据)。这对于扩大顾客或客户的增长更有效。它可以帮助灾难恢复工作，并将事件的影响限制在特定的客户群。

![Sharding-block-1](../Images/d94887c547b10c3fd7599c53f7363707.png)

在这里，auth 数据基于用户名进行分片，这样数据库可以更快地响应，因为数据库在查询期间必须处理的数据量已经大大减少。

还可以有其他的分割方式

![Sharding-block-2](../Images/8d9c685ae13fdc7b7f0e728f3e49ed72.png)

在这里，整个数据中心被分割和复制，客户端根据其地理位置被定向到数据中心。这有助于提高性能，因为客户端被定向到最近的数据中心，并且随着我们添加更多的数据中心，性能也会提高。这种方法需要注意一些复制和一致性开销。这还通过将测试特性推广到一个站点并在对该地理区域有影响时回滚来提供容错

**WHAT:** 这通常是根据客户的某些独特方面进行的划分，如客户 ID、姓名、地理位置等。

**何时使用:**非常大、相似的数据集，例如大型且快速增长的客户群，或者当地理上分散的客户群的响应时间很重要时。

**使用方法:**识别您所知道的关于客户的一些信息，例如客户 ID、姓氏、地理位置或设备，并根据该属性拆分或划分数据和服务。

**原因:**客户的快速增长超过了其他形式的数据增长，或者您需要在扩展时在某些客户群之间执行故障隔离。

**关键要点:**碎片可以有效地帮助您扩展客户群，但也可以应用于无法使用微服务方法分离的其他超大型数据集。

### 参考

*   https://learning.oreilly.com/library/view/the-art-of/9780134031408/ch23.html

## SRE 角色中的应用

1.  SREs 与网络团队合作，研究如何将用户流量映射到特定站点。https://engineering.linkedin.com/blog/2017/05/trafficshift 负荷测试规模
2.  SREs 与开发团队紧密合作，将 monoliths 拆分为多个易于运行和管理的微服务
3.  SREs 致力于提高负载平衡器的可靠性、服务发现和性能
4.  sre 紧密合作，将数据分割成碎片，并管理数据的完整性和一致性。https://engineering . LinkedIn . com/espresso/introducing-espresso-linkedins-hot-new-distributed-document-store
5.  sre 负责设置、配置和提高 CDN 缓存命中率。